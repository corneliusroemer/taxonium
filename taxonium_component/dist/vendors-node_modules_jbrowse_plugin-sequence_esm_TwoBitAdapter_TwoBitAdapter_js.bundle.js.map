{"version":3,"file":"vendors-node_modules_jbrowse_plugin-sequence_esm_TwoBitAdapter_TwoBitAdapter_js.bundle.js","mappings":";;;;;;;;;;;;;;AAAsC;AAChB;AACtB;;;;;;;;;;;;;;;;;;;ACFwB;AACuB;AACF;AAC7C;AACA;AACA;AACA,kCAAkC,WAAW;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACe;AACf;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,YAAY;AAC3B;AACA;AACA,kBAAkB,mBAAmB;AACrC;AACA;AACA;AACA;AACA,kCAAkC,yDAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,MAAM;AAC5C;AACA;AACA;AACA;AACA,+CAA+C,MAAM;AACrD,gBAAgB,SAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,uDAAM;AACzC;AACA;AACA,8BAA8B,sBAAsB;AACpD;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,2BAA2B,uDAAM;AACjC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,uBAAuB,uDAAM;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,yBAAyB,uDAAM;AAC/B;AACA;AACA;AACA,yBAAyB,uDAAM;AAC/B;AACA;AACA;AACA;AACA,+BAA+B,KAAK;AACpC,aAAa;AACb;AACA;AACA,+BAA+B,KAAK;AACpC,aAAa;AACb;AACA,yBAAyB,uDAAM;AAC/B;AACA;AACA;AACA;AACA,+BAA+B,KAAK;AACpC,aAAa;AACb;AACA;AACA,+BAA+B,KAAK;AACpC,aAAa;AACb;AACA,sCAAsC,mBAAmB;AACzD;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B,WAAW,+DAA+D;AAC1E;AACA;AACA;AACA,gBAAgB,SAAS,6BAA6B,MAAM;AAC5D;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS,qDAAqD,yBAAyB;AACxG;AACA;AACA;AACA;AACA,gBAAgB,SAAS,6BAA6B,MAAM;AAC5D;AACA;AACA;AACA;AACA,iCAAiC,mBAAmB;AACpD,6BAA6B,qDAAc;AAC3C;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,iCAAiC,cAAc;AAC/C;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,SAAS,0DAA0D,qBAAqB;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,qBAAqB;AAC7C;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,oDAAoD;AAC3E,0BAA0B,0DAA0D;AACpF;AACA;AACA;AACA;AACA;AACA,gBAAgB,SAAS,6BAA6B,MAAM;AAC5D;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,MAAM;AAChC;AACA,gBAAgB,SAAS;AACzB;AACA,gDAAgD,6BAA6B;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,oEAAoE;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,wBAAwB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,qBAAqB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACpV8E;AACzB;AACM;AACE;AACnB;AACmB;AAC9C,4BAA4B,wFAAmB;AAC9D;AACA;AACA;AACA,0BAA0B,oDAAU;AACpC,wBAAwB,mEAAY,CAAC,2EAAc;AACnD,SAAS;AACT;AACA;AACA,qBAAqB,2EAAc;AACnC;AACA;AACA;AACA;AACA,yBAAyB,mEAAY;AACrC;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,qBAAqB;AACvC,eAAe,yEAAgB;AAC/B;AACA;AACA;AACA;AACA,kCAAkC,wEAAa;AAC/C,2BAA2B,SAAS,EAAE,MAAM,GAAG,UAAU;AACzD,4BAA4B,qCAAqC;AACjE,iBAAiB;AACjB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,SAAS;AACjC;AACA;;;;;;;;;;;;;;;AC9EgC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,6BAA6B,+CAAW;AACxC;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,SAAS;AAC9D;AACA;AACA,eAAe,+CAAW;AAC1B;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC5FU;;;;;;;;;;;;;;;;;;;;;;;;ACA0B;AACE;AACJ;AACL;AAC7B,kCAAkC;AAClC,eAAe,mDAAU;AACzB;AACA,6DAA6D;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mDAAS;AAC5B;AACA;AACA;AAC0D;;;;;;;;;;;;;;;;;;;ACnB1B;AACQ;AACV;AAC9B;AACA;AACA;AACA;AACA,YAAY;AACG;AACf,iCAAiC;AACjC;AACA;AACA;AACA;AACA,yBAAyB,uDAAQ;AACjC;AACA;AACA;AACA,kCAAkC,wCAAS;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,+CAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,EAAE;AACrB;AACA;AACA;AACA;AACA,+DAA+D,OAAO;AACtE;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE;AAClE,gBAAgB,YAAY,2BAA2B;AACvD;AACA,qCAAqC,SAAS,GAAG,kBAAkB;AACnE;AACA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,iBAAiB,EAAE,qBAAqB,EAAE,SAAS;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA,qBAAqB;AACrB;AACA;AACA,+BAA+B,UAAU;AACzC;AACA;AACA,gCAAgC,iBAAiB,WAAW,SAAS;AACrE;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,YAAY,2BAA2B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,iBAAiB,WAAW,SAAS;AACvF;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qDAAqD,SAAS;AAC9D;AACA;AACA;AACA;AACA;AACA,wBAAwB,sDAAkB;AAC1C;AACA;AACA,uEAAuE,SAAS;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://taxonium/./node_modules/@gmod/twobit/esm/index.js","webpack://taxonium/./node_modules/@gmod/twobit/esm/twoBitFile.js","webpack://taxonium/./node_modules/@jbrowse/plugin-sequence/esm/TwoBitAdapter/TwoBitAdapter.js","webpack://taxonium/./node_modules/generic-filehandle/esm/blobFile.js","webpack://taxonium/./node_modules/generic-filehandle/esm/filehandle.js","webpack://taxonium/./node_modules/generic-filehandle/esm/index.js","webpack://taxonium/./node_modules/generic-filehandle/esm/remoteFile.js"],"sourcesContent":["import TwoBitFile from './twoBitFile';\nexport { TwoBitFile };\n//# sourceMappingURL=index.js.map","import Long from 'long';\nimport { LocalFile } from 'generic-filehandle';\nimport { Parser } from '@gmod/binary-parser';\nconst TWOBIT_MAGIC = 0x1a412743;\nfunction tinyMemoize(_class, methodName) {\n    const method = _class.prototype[methodName];\n    const memoAttrName = `_memo_${methodName}`;\n    _class.prototype[methodName] = function _tinyMemoized() {\n        if (!(memoAttrName in this)) {\n            this[memoAttrName] = method.call(this);\n        }\n        return this[memoAttrName];\n    };\n}\nconst twoBit = ['T', 'C', 'A', 'G'];\n// byteTo4Bases is an array of byteValue -> 'ACTG'\n// the weird `...keys()` incantation generates an array of numbers 0 to 255\nconst byteTo4Bases = [];\nfor (let i = 0; i < 256; i++) {\n    byteTo4Bases.push(twoBit[(i >> 6) & 3] +\n        twoBit[(i >> 4) & 3] +\n        twoBit[(i >> 2) & 3] +\n        twoBit[i & 3]);\n}\nconst maskedByteTo4Bases = byteTo4Bases.map(bases => bases.toLowerCase());\nexport default class TwoBitFile {\n    /**\n     * @param {object} args\n     * @param {string} [args.path] filesystem path for the .2bit file to open\n     * @param {Filehandle} [args.filehandle] node fs.promises-like filehandle for the .2bit file.\n     *  Only needs to support `filehandle.read(buffer, offset, length, position)`\n     */\n    constructor({ filehandle, path, }) {\n        if (filehandle) {\n            this.filehandle = filehandle;\n        }\n        else if (path) {\n            this.filehandle = new LocalFile(path);\n        }\n        else {\n            throw new Error('must supply path or filehandle');\n        }\n        this.isBigEndian = undefined;\n    }\n    async _getParser(name) {\n        const parser = (await this._getParsers())[name];\n        if (!parser) {\n            throw new Error(`parser ${name} not found`);\n        }\n        return parser;\n    }\n    async _detectEndianness() {\n        const ret = await this.filehandle.read(Buffer.allocUnsafe(8), 0, 8, 0);\n        const { buffer } = ret;\n        if (buffer.readInt32LE(0) === TWOBIT_MAGIC) {\n            this.isBigEndian = false;\n            this.version = buffer.readInt32LE(4);\n        }\n        else if (buffer.readInt32BE(0) === TWOBIT_MAGIC) {\n            this.isBigEndian = true;\n            this.version = buffer.readInt32BE(4);\n        }\n        else {\n            throw new Error('not a 2bit file');\n        }\n    }\n    // memoize\n    /**\n     * @private\n     * detects the file's endianness and instantiates our binary parsers accordingly\n     */\n    async _getParsers() {\n        await this._detectEndianness();\n        const endianess = this.isBigEndian ? 'big' : 'little';\n        const lebe = this.isBigEndian ? 'be' : 'le';\n        let indexEntryParser = new Parser()\n            .endianess(endianess)\n            .uint8('nameLength')\n            .string('name', { length: 'nameLength' });\n        if (this.version === 1) {\n            indexEntryParser = indexEntryParser.buffer('offsetBytes', {\n                length: 8,\n            });\n        }\n        else {\n            indexEntryParser = indexEntryParser.uint32('offset');\n        }\n        /* istanbul ignore next */\n        const header = new Parser()\n            .endianess(endianess)\n            .int32('magic', {\n            assert: (m) => m === 0x1a412743,\n        })\n            .int32('version', {\n            /* istanbul ignore next */\n            assert: (v) => v === 0 || v === 1,\n        })\n            .uint32('sequenceCount', {\n            /* istanbul ignore next */\n            assert: (v) => v >= 0,\n        })\n            .uint32('reserved');\n        return {\n            header,\n            index: new Parser()\n                .endianess(endianess)\n                .uint32('sequenceCount')\n                .uint32('reserved')\n                .array('index', {\n                length: 'sequenceCount',\n                type: indexEntryParser,\n            }),\n            record1: new Parser()\n                .endianess(endianess)\n                .uint32('dnaSize')\n                .uint32('nBlockCount'),\n            record2: new Parser()\n                .endianess(endianess)\n                .uint32('nBlockCount')\n                .array('nBlockStarts', {\n                length: 'nBlockCount',\n                type: `uint32${lebe}`,\n            })\n                .array('nBlockSizes', {\n                length: 'nBlockCount',\n                type: `uint32${lebe}`,\n            })\n                .uint32('maskBlockCount'),\n            record3: new Parser()\n                .endianess(endianess)\n                .uint32('maskBlockCount')\n                .array('maskBlockStarts', {\n                length: 'maskBlockCount',\n                type: `uint32${lebe}`,\n            })\n                .array('maskBlockSizes', {\n                length: 'maskBlockCount',\n                type: `uint32${lebe}`,\n            })\n                .int32('reserved'),\n            // .buffer('packedDna', { length: 'dnaSize' }),\n        };\n    }\n    // memoize\n    /**\n     * @returns {Promise} for object with the file's header information, like\n     *  `{ magic: 0x1a412743, version: 0, sequenceCount: 42, reserved: 0 }`\n     */\n    async getHeader() {\n        await this._detectEndianness();\n        const { buffer } = await this.filehandle.read(Buffer.allocUnsafe(16), 0, 16, 0);\n        const headerParser = await this._getParser('header');\n        return headerParser.parse(buffer).result;\n    }\n    // memoize\n    /**\n     * @returns {Promise} for object with the file's index of offsets, like `{ seqName: fileOffset, ...}`\n     */\n    async getIndex() {\n        const header = await this.getHeader();\n        const maxIndexLength = 8 + header.sequenceCount * (1 + 256 + (this.version === 1 ? 8 : 4));\n        const { buffer } = await this.filehandle.read(Buffer.allocUnsafe(maxIndexLength), 0, maxIndexLength, 8);\n        const indexParser = await this._getParser('index');\n        const indexData = indexParser.parse(buffer).result.index;\n        const index = {};\n        if (this.version === 1) {\n            indexData.forEach(({ name, offsetBytes }) => {\n                const long = Long.fromBytes(offsetBytes, true, !this.isBigEndian);\n                if (long.greaterThan(Number.MAX_SAFE_INTEGER)) {\n                    throw new Error('integer overflow. File offset greater than 2^53-1 encountered. This library can only handle offsets up to 2^53-1.');\n                }\n                index[name] = long.toNumber();\n            });\n        }\n        else {\n            indexData.forEach(({ name, offset }) => {\n                index[name] = offset;\n            });\n        }\n        return index;\n    }\n    /**\n     * @returns {Promise} for an array of string sequence names that are found in the file\n     */\n    async getSequenceNames() {\n        const index = await this.getIndex();\n        return Object.keys(index);\n    }\n    /**\n     * @returns {Promise} for an object listing the lengths of all sequences like `{seqName: length, ...}`\n     */\n    async getSequenceSizes() {\n        const index = await this.getIndex();\n        const seqNames = Object.keys(index);\n        const sizePromises = Object.values(index).map(offset => this._getSequenceSize(offset));\n        const sizes = await Promise.all(sizePromises);\n        const returnObject = {};\n        for (let i = 0; i < seqNames.length; i += 1) {\n            returnObject[seqNames[i]] = sizes[i];\n        }\n        return returnObject;\n    }\n    /**\n     * @param {string} seqName name of the sequence\n     * @returns {Promise} for the sequence's length, or undefined if it is not in the file\n     */\n    async getSequenceSize(seqName) {\n        const index = await this.getIndex();\n        const offset = index[seqName];\n        if (!offset) {\n            return undefined;\n        }\n        return this._getSequenceSize(offset);\n    }\n    async _getSequenceSize(offset) {\n        // we have to parse the sequence record in 3 parts, because we have to buffer 3 fixed-length file reads\n        if (offset === undefined || offset < 0) {\n            throw new Error('invalid offset');\n        }\n        const rec1 = await this._parseItem(offset, 8, 'record1');\n        return rec1.dnaSize;\n    }\n    async _getSequenceRecord(offset) {\n        // we have to parse the sequence record in 3 parts, because we have to buffer 3 fixed-length file reads\n        if (offset === undefined || offset < 0) {\n            throw new Error('invalid offset');\n        }\n        const rec1 = await this._parseItem(offset, 8, 'record1');\n        const rec2DataLength = rec1.nBlockCount * 8 + 8;\n        const rec2 = await this._parseItem(offset + 4, rec2DataLength, 'record2');\n        const rec3DataLength = rec2.maskBlockCount * 8 + 8;\n        const rec3 = await this._parseItem(offset + 4 + rec2DataLength - 4, rec3DataLength, 'record3');\n        const rec = {\n            dnaSize: rec1.dnaSize,\n            nBlocks: { starts: rec2.nBlockStarts, sizes: rec2.nBlockSizes },\n            maskBlocks: { starts: rec3.maskBlockStarts, sizes: rec3.maskBlockSizes },\n            dnaPosition: offset + 4 + rec2DataLength - 4 + rec3DataLength,\n        };\n        return rec;\n    }\n    async _parseItem(offset, length, parserName) {\n        const { buffer } = await this.filehandle.read(Buffer.allocUnsafe(length), 0, length, offset);\n        const parser = await this._getParser(parserName);\n        return parser.parse(buffer).result;\n    }\n    /**\n     * @param {string} seqName name of the sequence you want\n     * @param {number} [regionStart] optional 0-based half-open start of the sequence region to fetch.\n     * @param {number} [regionEnd] optional 0-based half-open end of the sequence region to fetch. defaults to end of the sequence\n     * @returns {Promise} for a string of sequence bases\n     */\n    async getSequence(seqName, regionStart = 0, regionEnd) {\n        const index = await this.getIndex();\n        const offset = index[seqName];\n        if (!offset) {\n            return undefined;\n        }\n        // fetch the record for the seq\n        const record = await this._getSequenceRecord(offset);\n        if (regionStart < 0) {\n            throw new TypeError('regionStart cannot be less than 0');\n        }\n        // end defaults to the end of the sequence\n        if (regionEnd === undefined || regionEnd > record.dnaSize) {\n            regionEnd = record.dnaSize;\n        }\n        const nBlocks = this._getOverlappingBlocks(regionStart, regionEnd, record.nBlocks.starts, record.nBlocks.sizes);\n        const maskBlocks = this._getOverlappingBlocks(regionStart, regionEnd, record.maskBlocks.starts, record.maskBlocks.sizes);\n        const baseBytes = Buffer.allocUnsafe(Math.ceil((regionEnd - regionStart) / 4) + 1);\n        const baseBytesOffset = Math.floor(regionStart / 4);\n        const { buffer } = await this.filehandle.read(baseBytes, 0, baseBytes.length, record.dnaPosition + baseBytesOffset);\n        let sequenceBases = '';\n        for (let genomicPosition = regionStart; genomicPosition < regionEnd; genomicPosition += 1) {\n            // check whether we are currently masked\n            while (maskBlocks.length && maskBlocks[0].end <= genomicPosition) {\n                maskBlocks.shift();\n            }\n            const baseIsMasked = maskBlocks[0] &&\n                maskBlocks[0].start <= genomicPosition &&\n                maskBlocks[0].end > genomicPosition;\n            // process the N block if we have one\n            if (nBlocks[0] &&\n                genomicPosition >= nBlocks[0].start &&\n                genomicPosition < nBlocks[0].end) {\n                const currentNBlock = nBlocks.shift();\n                for (; genomicPosition < currentNBlock.end && genomicPosition < regionEnd; genomicPosition += 1) {\n                    sequenceBases += baseIsMasked ? 'n' : 'N';\n                }\n                genomicPosition -= 1;\n            }\n            else {\n                const bytePosition = Math.floor(genomicPosition / 4) - baseBytesOffset;\n                const subPosition = genomicPosition % 4;\n                const byte = buffer[bytePosition];\n                sequenceBases += baseIsMasked\n                    ? maskedByteTo4Bases[byte][subPosition]\n                    : byteTo4Bases[byte][subPosition];\n            }\n        }\n        return sequenceBases;\n    }\n    _getOverlappingBlocks(regionStart, regionEnd, blockStarts, blockSizes) {\n        // find the start and end indexes of the blocks that match\n        let startIndex;\n        let endIndex;\n        for (let i = 0; i < blockStarts.length; i += 1) {\n            const blockStart = blockStarts[i];\n            const blockSize = blockSizes[i];\n            if (regionStart >= blockStart + blockSize || regionEnd <= blockStart) {\n                // block does not overlap the region\n                if (startIndex !== undefined) {\n                    endIndex = i;\n                    break;\n                }\n            }\n            else if (startIndex === undefined) {\n                startIndex = i;\n            } // block does overlap the region, record this if it is the first\n        }\n        if (startIndex === undefined) {\n            return [];\n        }\n        // now format some block objects to return\n        if (endIndex === undefined) {\n            endIndex = blockStarts.length;\n        }\n        const blocks = new Array(endIndex - startIndex);\n        for (let blockNum = startIndex; blockNum < endIndex; blockNum += 1) {\n            blocks[blockNum - startIndex] = {\n                start: blockStarts[blockNum],\n                end: blockStarts[blockNum] + blockSizes[blockNum],\n                size: blockSizes[blockNum],\n            };\n        }\n        return blocks;\n    }\n}\ntinyMemoize(TwoBitFile, '_getParsers');\ntinyMemoize(TwoBitFile, 'getIndex');\ntinyMemoize(TwoBitFile, 'getHeader');\n//# sourceMappingURL=twoBitFile.js.map","import { BaseSequenceAdapter } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { openLocation } from '@jbrowse/core/util/io';\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs';\nimport SimpleFeature from '@jbrowse/core/util/simpleFeature';\nimport { TwoBitFile } from '@gmod/twobit';\nimport { readConfObject } from '@jbrowse/core/configuration';\nexport default class TwoBitAdapter extends BaseSequenceAdapter {\n    constructor(config, getSubAdapter, pluginManager) {\n        super(config, getSubAdapter, pluginManager);\n        this.chromSizesData = this.initChromSizes();\n        this.twobit = new TwoBitFile({\n            filehandle: openLocation(readConfObject(config, 'twoBitLocation'), this.pluginManager),\n        });\n    }\n    async initChromSizes() {\n        const conf = readConfObject(this.config, 'chromSizesLocation');\n        // check against default and empty in case someone makes the field blank in\n        // config editor, may want better way to check \"optional config slots\" in\n        // future\n        if (conf.uri !== '/path/to/default.chrom.sizes' && conf.uri !== '') {\n            const file = openLocation(conf, this.pluginManager);\n            const data = await file.readFile('utf8');\n            return Object.fromEntries(data === null || data === void 0 ? void 0 : data.split('\\n').filter(line => !!line.trim()).map(line => {\n                const [name, length] = line.split('\\t');\n                return [name, +length];\n            }));\n        }\n        return undefined;\n    }\n    async getRefNames() {\n        const chromSizesData = await this.chromSizesData;\n        if (chromSizesData) {\n            return Object.keys(chromSizesData);\n        }\n        return this.twobit.getSequenceNames();\n    }\n    async getRegions() {\n        const chromSizesData = await this.chromSizesData;\n        if (chromSizesData) {\n            return Object.keys(chromSizesData).map(refName => ({\n                refName,\n                start: 0,\n                end: chromSizesData[refName],\n            }));\n        }\n        const refSizes = await this.twobit.getSequenceSizes();\n        return Object.keys(refSizes).map(refName => ({\n            refName,\n            start: 0,\n            end: refSizes[refName],\n        }));\n    }\n    /**\n     * Fetch features for a certain region\n     * @param param -\n     * @returns Observable of Feature objects in the region\n     */\n    getFeatures({ refName, start, end }) {\n        return ObservableCreate(async (observer) => {\n            const size = await this.twobit.getSequenceSize(refName);\n            const regionEnd = size !== undefined ? Math.min(size, end) : end;\n            const seq = await this.twobit.getSequence(refName, start, regionEnd);\n            if (seq) {\n                observer.next(new SimpleFeature({\n                    id: `${refName} ${start}-${regionEnd}`,\n                    data: { refName, start, end: regionEnd, seq },\n                }));\n            }\n            observer.complete();\n        });\n    }\n    /**\n     * called to provide a hint that data tied to a certain region\n     * will not be needed for the forseeable future and can be purged\n     * from caches, etc\n     */\n    freeResources( /* { region } */) { }\n}\n//# sourceMappingURL=TwoBitAdapter.js.map","import { Buffer } from 'buffer';\n// Using this you can \"await\" the file like a normal promise\n// https://blog.shovonhasan.com/using-promises-with-filereader/\nfunction readBlobAsArrayBuffer(blob) {\n    const fileReader = new FileReader();\n    return new Promise((resolve, reject) => {\n        fileReader.onerror = () => {\n            fileReader.abort();\n            reject(new Error('problem reading blob'));\n        };\n        fileReader.onabort = () => {\n            reject(new Error('blob reading was aborted'));\n        };\n        fileReader.onload = () => {\n            if (fileReader.result && typeof fileReader.result !== 'string') {\n                resolve(fileReader.result);\n            }\n            else {\n                reject(new Error('unknown error reading blob'));\n            }\n        };\n        fileReader.readAsArrayBuffer(blob);\n    });\n}\nfunction readBlobAsText(blob) {\n    const fileReader = new FileReader();\n    return new Promise((resolve, reject) => {\n        fileReader.onerror = () => {\n            fileReader.abort();\n            reject(new Error('problem reading blob'));\n        };\n        fileReader.onabort = () => {\n            reject(new Error('blob reading was aborted'));\n        };\n        fileReader.onload = () => {\n            if (fileReader.result && typeof fileReader.result === 'string') {\n                resolve(fileReader.result);\n            }\n            else {\n                reject(new Error('unknown error reading blob'));\n            }\n        };\n        fileReader.readAsText(blob);\n    });\n}\n/**\n * Blob of binary data fetched from a local file (with FileReader).\n *\n * Adapted by Robert Buels and Garrett Stevens from the BlobFetchable object in\n * the Dalliance Genome Explorer, which is copyright Thomas Down 2006-2011.\n */\nexport default class BlobFile {\n    constructor(blob) {\n        this.blob = blob;\n        this.size = blob.size;\n    }\n    async read(buffer, offset = 0, length, position = 0) {\n        // short-circuit a read of 0 bytes here, because browsers actually sometimes\n        // crash if you try to read 0 bytes from a local file!\n        if (!length) {\n            return { bytesRead: 0, buffer };\n        }\n        const start = position;\n        const end = start + length;\n        const result = await readBlobAsArrayBuffer(this.blob.slice(start, end));\n        const resultBuffer = Buffer.from(result);\n        const bytesCopied = resultBuffer.copy(buffer, offset);\n        return { bytesRead: bytesCopied, buffer: resultBuffer };\n    }\n    async readFile(options) {\n        let encoding;\n        if (typeof options === 'string') {\n            encoding = options;\n        }\n        else {\n            encoding = options && options.encoding;\n        }\n        if (encoding === 'utf8') {\n            return readBlobAsText(this.blob);\n        }\n        if (encoding) {\n            throw new Error(`unsupported encoding: ${encoding}`);\n        }\n        const result = await readBlobAsArrayBuffer(this.blob);\n        return Buffer.from(result);\n    }\n    async stat() {\n        return { size: this.size };\n    }\n    async close() {\n        return;\n    }\n}\n","export {};\n","import LocalFile from './localFile';\nimport RemoteFile from './remoteFile';\nimport BlobFile from './blobFile';\nexport * from './filehandle';\nfunction fromUrl(source, opts = {}) {\n    return new RemoteFile(source, opts);\n}\nfunction open(maybeUrl, maybePath, maybeFilehandle, opts = {}) {\n    if (maybeFilehandle !== undefined) {\n        return maybeFilehandle;\n    }\n    if (maybeUrl !== undefined) {\n        return fromUrl(maybeUrl, opts);\n    }\n    if (maybePath !== undefined) {\n        return new LocalFile(maybePath, opts);\n    }\n    throw new Error('no url, path, or filehandle provided, cannot open');\n}\nexport { open, fromUrl, RemoteFile, LocalFile, BlobFile };\n","import { Buffer } from 'buffer';\nimport uri2path from 'file-uri-to-path';\nimport { LocalFile } from '.';\nconst myGlobal = typeof window !== 'undefined'\n    ? window\n    : typeof self !== 'undefined'\n        ? self\n        : { fetch: undefined };\nexport default class RemoteFile {\n    constructor(source, opts = {}) {\n        this.baseOverrides = {};\n        this.url = source;\n        // if it is a file URL, monkey-patch ourselves to act like a LocalFile\n        if (source.startsWith('file://')) {\n            const path = uri2path(source);\n            if (!path) {\n                throw new TypeError('invalid file url');\n            }\n            const localFile = new LocalFile(path);\n            this.read = localFile.read.bind(localFile);\n            this.readFile = localFile.readFile.bind(localFile);\n            this.stat = localFile.stat.bind(localFile);\n            // @ts-ignore\n            this.fetchImplementation = () => {\n                /* intentionally blank */\n            };\n            return;\n        }\n        const fetch = opts.fetch || (myGlobal.fetch && myGlobal.fetch.bind(myGlobal));\n        if (!fetch) {\n            throw new TypeError(`no fetch function supplied, and none found in global environment`);\n        }\n        if (opts.overrides) {\n            this.baseOverrides = opts.overrides;\n        }\n        this.fetchImplementation = fetch;\n    }\n    async getBufferFromResponse(response) {\n        if (typeof response.buffer === 'function') {\n            return response.buffer();\n        }\n        else if (typeof response.arrayBuffer === 'function') {\n            const resp = await response.arrayBuffer();\n            return Buffer.from(resp);\n        }\n        else {\n            throw new TypeError('invalid HTTP response object, has no buffer method, and no arrayBuffer method');\n        }\n    }\n    async fetch(input, init) {\n        let response;\n        try {\n            response = await this.fetchImplementation(input, init);\n        }\n        catch (e) {\n            if (`${e}`.includes('Failed to fetch')) {\n                // refetch to to help work around a chrome bug (discussed in\n                // generic-filehandle issue #72) in which the chrome cache returns a\n                // CORS error for content in its cache.  see also\n                // https://github.com/GMOD/jbrowse-components/pull/1511\n                console.warn(`generic-filehandle: refetching ${input} to attempt to work around chrome CORS header caching bug`);\n                response = await this.fetchImplementation(input, {\n                    ...init,\n                    cache: 'reload',\n                });\n            }\n            else {\n                throw e;\n            }\n        }\n        return response;\n    }\n    async read(buffer, offset = 0, length, position = 0, opts = {}) {\n        const { headers = {}, signal, overrides = {} } = opts;\n        if (length < Infinity) {\n            headers.range = `bytes=${position}-${position + length}`;\n        }\n        else if (length === Infinity && position !== 0) {\n            headers.range = `bytes=${position}-`;\n        }\n        const args = {\n            ...this.baseOverrides,\n            ...overrides,\n            headers: {\n                ...headers,\n                ...overrides.headers,\n                ...this.baseOverrides.headers,\n            },\n            method: 'GET',\n            redirect: 'follow',\n            mode: 'cors',\n            signal,\n        };\n        const response = await this.fetch(this.url, args);\n        if (!response.ok) {\n            throw new Error(`HTTP ${response.status} ${response.statusText} ${this.url}`);\n        }\n        if ((response.status === 200 && position === 0) ||\n            response.status === 206) {\n            const responseData = await this.getBufferFromResponse(response);\n            const bytesCopied = responseData.copy(buffer, offset, 0, Math.min(length, responseData.length));\n            // try to parse out the size of the remote file\n            const res = response.headers.get('content-range');\n            const sizeMatch = /\\/(\\d+)$/.exec(res || '');\n            if (sizeMatch && sizeMatch[1]) {\n                this._stat = { size: parseInt(sizeMatch[1], 10) };\n            }\n            return { bytesRead: bytesCopied, buffer };\n        }\n        if (response.status === 200) {\n            throw new Error('${this.url} fetch returned status 200, expected 206');\n        }\n        // TODO: try harder here to gather more information about what the problem is\n        throw new Error(`HTTP ${response.status} fetching ${this.url}`);\n    }\n    async readFile(options = {}) {\n        let encoding;\n        let opts;\n        if (typeof options === 'string') {\n            encoding = options;\n            opts = {};\n        }\n        else {\n            encoding = options.encoding;\n            opts = options;\n            delete opts.encoding;\n        }\n        const { headers = {}, signal, overrides = {} } = opts;\n        const args = {\n            headers,\n            method: 'GET',\n            redirect: 'follow',\n            mode: 'cors',\n            signal,\n            ...this.baseOverrides,\n            ...overrides,\n        };\n        const response = await this.fetch(this.url, args);\n        if (!response) {\n            throw new Error('generic-filehandle failed to fetch');\n        }\n        if (response.status !== 200) {\n            throw Object.assign(new Error(`HTTP ${response.status} fetching ${this.url}`), {\n                status: response.status,\n            });\n        }\n        if (encoding === 'utf8') {\n            return response.text();\n        }\n        if (encoding) {\n            throw new Error(`unsupported encoding: ${encoding}`);\n        }\n        return this.getBufferFromResponse(response);\n    }\n    async stat() {\n        if (!this._stat) {\n            const buf = Buffer.allocUnsafe(10);\n            await this.read(buf, 0, 10, 0);\n            if (!this._stat) {\n                throw new Error(`unable to determine size of file at ${this.url}`);\n            }\n        }\n        return this._stat;\n    }\n    async close() {\n        return;\n    }\n}\n"],"names":[],"sourceRoot":""}
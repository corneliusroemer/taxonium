{"version":3,"file":"vendors-node_modules_gmod_bbi_esm_index_js.bundle.js","mappings":";;;;;;;;;;;;;;;;;;;AAAuC;AACoB;AACzB;AACM;AACA;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iDAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,iDAAM;AACxB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,mCAAmC,iDAAM;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,iDAAM;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,iDAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B,gBAAgB,gDAAgD;AAChE;AACA;AACA;AACA;AACA;AACA,2BAA2B,0DAAU;AACrC;AACA;AACA,2BAA2B,yDAAS;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB,8CAA8C,eAAe;AAC7D;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,gBAAgB,SAAS,sBAAsB,MAAM;AACrD;AACA;AACA;AACA,gBAAgB,sCAAsC;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,SAAS,sBAAsB,MAAM;AACrD;AACA,gBAAgB,UAAU;AAC1B,mCAAmC,iDAAM;AACzC;AACA,6BAA6B,kCAAkC;AAC/D;AACA;AACA;AACA,sCAAsC,iDAAM;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,kBAAkB;AACtC;AACA;AACA,gCAAgC,SAAS;AACzC;AACA;AACA,4BAA4B,sBAAsB;AAClD,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,SAAS;AACzC;AACA,4BAA4B,cAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,6EAA6E;AAC7F,mBAAmB,iDAAS;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,4CAAU;AAC7B;AACA,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,kBAAkB,sDAAM;AACxB;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;AC9PuC;AACE;AACI;AACe;AAC3B;AACL;AACrB;AACP;AACA;AACO,qBAAqB,qCAAG;AAC/B;AACA;AACA,oCAAoC,gEAAqB;AACzD,uBAAuB,kDAAQ,GAAG,YAAY;AAC9C;AACA,2CAA2C,iBAAiB;AAC5D,aAAa;AACb,SAAS;AACT;AACA,yBAAyB;AACzB,8CAA8C,eAAe;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,+BAA+B;AAC/C,gBAAgB,eAAe,sBAAsB,MAAM;AAC3D;AACA,wBAAwB,iDAAM;AAC9B;AACA;AACA;AACA;AACA;AACA,gBAAgB,gBAAgB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,SAAS,sBAAsB,MAAM;AACrD,8BAA8B,iDAAM;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD,gBAAgB,cAAc;AAC9B;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC,oBAAoB,eAAe,sBAAsB,MAAM;AAC/D;AACA,0BAA0B,iDAAM;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,8BAA8B;AAClD,4BAA4B,0BAA0B;AACtD,4BAA4B,iDAAM;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,iDAAM;AACjC;AACA,kCAAkC,iDAAM;AACxC;AACA,6CAA6C,kCAAkC;AAC/E;AACA,qBAAqB;AACrB,2BAA2B,iDAAM;AACjC;AACA,kCAAkC,iDAAM;AACxC;AACA,6CAA6C,kCAAkC;AAC/E;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA,wBAAwB,SAAS,sBAAsB,MAAM;AAC7D;AACA;AACA;AACA,oCAAoC,0BAA0B;AAC9D,gCAAgC,MAAM;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,sBAAsB;AACtD;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,4CAAU;AACjC;AACA,aAAa,OAAO,sDAAM,mCAAmC,mDAAG;AAChE,gCAAgC,cAAc;AAC9C;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT,0BAA0B,2CAAK;AAC/B,iCAAiC,QAAQ,0GAA0G;AACnJ;AACA;AACA;;;;;;;;;;;;;;;;ACjLwC;AACZ;AACrB,qBAAqB,qCAAG;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,mEAAmE;AACnF;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,QAAQ;AACvC;AACA;AACA;AACA,2BAA2B,iDAAS;AACpC;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AC3BuC;AACqB;AAC3B;AACjC;AAC4B;AACI;AACuB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,iDAAM;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,iDAAM;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,iDAAM;AACzB;AACA,0BAA0B,iDAAM;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,mBAAmB,iDAAM;AACzB;AACA,0BAA0B,iDAAM;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT,KAAK;AACL,6BAA6B,iDAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,6BAA6B,iDAAM;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,iDAAM;AAC5C;AACA,0BAA0B,iDAAM;AAChC,aAAa;AACb,sCAAsC,iDAAM;AAC5C;AACA,0BAA0B,iDAAM;AAChC,aAAa;AACb,sCAAsC,iDAAM;AAC5C;AACA,0BAA0B,iDAAM;AAChC;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gEAAqB;AACrD,uBAAuB,kDAAQ,GAAG,eAAe;AACjD;AACA;AACA;AACA,wBAAwB,SAAS,sBAAsB,MAAM;AAC7D;AACA,iBAAiB;AACjB;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,8CAA8C;AAClE;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,+CAA+C,MAAM;AACrD;AACA,oBAAoB,SAAS;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,2CAA2C;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,OAAO,GAAG,OAAO,KAAK,gBAAgB;AAC9G,oCAAoC,gBAAgB;AACpD;AACA;AACA;AACA;AACA,6EAA6E,kBAAkB;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E;AAC3E,oCAAoC,8CAAK;AACzC,oCAAoC,mBAAmB;AACvD,8CAA8C,8CAAK;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,wBAAwB,oBAAoB,GAAG;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,eAAe;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA,gCAAgC,eAAe;AAC/C;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA,gCAAgC,eAAe;AAC/C;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA,oBAAoB,0BAA0B;AAC9C,oBAAoB,kBAAkB;AACtC,uCAAuC,kDAAW;AAClD,YAAY,uDAAgB;AAC5B;AACA,gBAAgB,uDAAgB;AAChC,wBAAwB,iBAAiB;AACzC,4DAA4D,OAAO,GAAG,OAAO;AAC7E;AACA,oBAAoB,uDAAgB;AACpC;AACA;AACA;AACA,qCAAqC,6CAAK;AAC1C;AACA;AACA,oBAAoB,uDAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,UAAU;AACjF;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AClXkC;AACA;AAClC;;;;;;;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACe;AACf;AACA;AACA;AACA,qBAAqB,sBAAsB;AAC3C;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,wBAAwB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,MAAM,GAAG,MAAM;AACzD;AACA;AACA;AACA;AACA;AACA,wBAAwB,mBAAmB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,gBAAgB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC5HkC;AAC3B;AACP,WAAW,gDAAU;AACrB;AACA;;;;;;;;;;;;;;;;;ACJA,kCAAkC,gBAAgB;AAC3C;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,oBAAoB,mBAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,aAAa;AACxB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,aAAa;AACxB;AACO;AACP;AACA;AACA;AACA;;;;;;;;;;;;;;;ACxEgC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,6BAA6B,+CAAW;AACxC;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,SAAS;AAC9D;AACA;AACA,eAAe,+CAAW;AAC1B;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC5FU;;;;;;;;;;;;;;;;;;;;;;;;ACA0B;AACE;AACJ;AACL;AAC7B,kCAAkC;AAClC,eAAe,mDAAU;AACzB;AACA,6DAA6D;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mDAAS;AAC5B;AACA;AACA;AAC0D;;;;;;;;;;;;;;;;ACnB1B;AAChC;AACA;AACA;AACA;AACA,YAAY;AACG;AACf,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,+CAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,EAAE;AACrB;AACA;AACA;AACA;AACA,+DAA+D,OAAO;AACtE;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE;AAClE,gBAAgB,YAAY,2BAA2B;AACvD;AACA,qCAAqC,SAAS,GAAG,kBAAkB;AACnE;AACA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,iBAAiB,EAAE,qBAAqB,EAAE,SAAS;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA,qBAAqB;AACrB;AACA;AACA,+BAA+B,UAAU;AACzC;AACA;AACA,gCAAgC,iBAAiB,WAAW,SAAS;AACrE;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,YAAY,2BAA2B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,iBAAiB,WAAW,SAAS;AACvF;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qDAAqD,SAAS;AAC9D;AACA;AACA;AACA;AACA;AACA,wBAAwB,sDAAkB;AAC1C;AACA;AACA,uEAAuE,SAAS;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;ACrJa;;AAEb;AACA,yBAAyB;AACzB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,oBAAoB,QAAQ,wBAAwB;AAC9E;AACA;AACA;AACA,yCAAyC,IAAI,EAAE;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,GAAG;AAC1B;AACA;AACA;AACA;AACA;AACA,kBAAkB,gBAAgB,GAAG,GAAG;AACxC;AACA;AACA;AACA,yCAAyC,mCAAmC;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oCAAoC,gBAAgB,SAAS,WAAW,aAAa,EAAE;AAC/G,kCAAkC,uBAAuB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,gCAAgC;AAChC;AACA;AACA,kCAAkC;AAClC;AACA;AACA,kCAAkC;AAClC;AACA;AACA,gCAAgC;AAChC;AACA;AACA,kCAAkC;AAClC;AACA;AACA,kCAAkC;AAClC;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,iCAAiC;AACjC;AACA;AACA,iCAAiC;AACjC;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,iCAAiC;AACjC;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA,gCAAgC;AAChC;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,iCAAiC;AACjC;AACA;AACA,kCAAkC;AAClC;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,gCAAgC;AAChC;AACA;AACA;AACA,gDAAgD,mBAAmB;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,aAAa;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,UAAU;AACzD;AACA;AACA;AACA;AACA,gDAAgD,MAAM;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,aAAa;AAC1D;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mGAAmG;AACnG;AACA;AACA;AACA;AACA;AACA,mCAAmC,6BAA6B,WAAW;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC,mCAAmC,gDAAgD,GAAG;AACtF,0CAA0C;AAC1C,wCAAwC;AACxC;AACA;AACA,0CAA0C;AAC1C,wCAAwC;AACxC,kCAAkC;AAClC;AACA;AACA,iCAAiC,6BAA6B,mBAAmB;AACjF,mCAAmC,gDAAgD,GAAG;AACtF,+CAA+C,2BAA2B,eAAe,EAAE;AAC3F,sDAAsD;AACtD;AACA;AACA;AACA,iEAAiE,oBAAoB,EAAE;AACvF,+BAA+B,+BAA+B;AAC9D,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,2GAA2G,EAAE,YAAY;AACzH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC,KAAK,cAAc,QAAQ,IAAI;AACxE;AACA;AACA;AACA,oCAAoC,qBAAqB,MAAM,QAAQ,GAAG;AAC1E;AACA;AACA,oCAAoC,qCAAqC,MAAM,QAAQ,GAAG;AAC1F;AACA;AACA;AACA;AACA,+CAA+C,SAAS,SAAS,+CAA+C;AAChH,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,KAAK,IAAI;AACzC;AACA;AACA,mCAAmC,0BAA0B;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,KAAK,4BAA4B;AACrE;AACA;AACA;AACA,oCAAoC,KAAK,6BAA6B;AACtE;AACA;AACA;AACA,oCAAoC,KAAK,oEAAoE;AAC7G;AACA;AACA;AACA,oCAAoC,KAAK,6BAA6B;AACtE;AACA;AACA,0CAA0C,SAAS;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,gBAAgB,KAAK,KAAK,MAAM,kBAAkB,OAAO,cAAc;AAC/G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,gBAAgB,EAAE,6CAA6C,EAAE,KAAK,KAAK,QAAQ,MAAM,mBAAmB;AAC5I;AACA;AACA,oCAAoC,gBAAgB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,kCAAkC,QAAQ;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,OAAO,SAAS;AAChD,gFAAgF,OAAO,IAAI,IAAI,EAAE;AACjG,oCAAoC,OAAO,IAAI,KAAK;AACpD;AACA,qBAAqB,MAAM,+BAA+B,MAAM,IAAI,IAAI,KAAK,MAAM,WAAW;AAC9F,qBAAqB,MAAM,qBAAqB,SAAS,4BAA4B,MAAM,IAAI,IAAI,GAAG;AACtG;AACA;AACA;AACA;AACA,qBAAqB,MAAM,gDAAgD,IAAI,KAAK,MAAM,WAAW;AACrG,qBAAqB,MAAM,qBAAqB,SAAS,6CAA6C,IAAI,GAAG;AAC7G,sCAAsC,KAAK;AAC3C;AACA;AACA,gCAAgC,OAAO,SAAS;AAChD,mEAAmE;AACnE;AACA,qBAAqB,MAAM,+BAA+B,MAAM,iBAAiB,MAAM,WAAW;AAClG,qBAAqB,MAAM,qBAAqB,SAAS,4BAA4B,MAAM,eAAe;AAC1G;AACA;AACA,gCAAgC,OAAO,SAAS;AAChD,0DAA0D;AAC1D;AACA,qBAAqB,MAAM,+BAA+B,MAAM,aAAa,MAAM,WAAW;AAC9F,qBAAqB,MAAM,qBAAqB,SAAS,4BAA4B,MAAM,WAAW;AACtG;AACA;AACA,4BAA4B,MAAM,IAAI,KAAK;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,OAAO,SAAS;AAChD,gCAAgC,KAAK,IAAI;AACzC,0DAA0D;AAC1D,4BAA4B,KAAK,4BAA4B;AAC7D;AACA,gCAAgC,KAAK,QAAQ,uBAAuB,IAAI,IAAI,kCAAkC;AAC9G,sCAAsC;AACtC,2BAA2B;AAC3B,4BAA4B,SAAS,oBAAoB,MAAM,UAAU;AACzE;AACA;AACA,4BAA4B,SAAS,0BAA0B;AAC/D;AACA;AACA;AACA,4BAA4B,SAAS,qCAAqC,IAAI,EAAE;AAChF,sCAAsC,KAAK;AAC3C;AACA;AACA,4BAA4B,SAAS,4BAA4B,QAAQ,EAAE;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,KAAK,KAAK;AACtC;AACA;AACA,4BAA4B,KAAK,KAAK;AACtC;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,qCAAqC,SAAS,KAAK,wBAAwB,EAAE,QAAQ,KAAK;AAC1F;AACA;AACA,qCAAqC,SAAS,aAAa,gBAAgB,WAAW,UAAU,GAAG;AACnG;AACA;AACA,qCAAqC,SAAS,IAAI,SAAS,EAAE,SAAS,KAAK,EAAE,QAAQ,KAAK;AAC1F;AACA;AACA;AACA;AACA;AACA,oCAAoC,MAAM,gBAAgB,SAAS,WAAW,aAAa,EAAE;AAC7F,0CAA0C,uBAAuB;AACjE;AACA;AACA;AACA,oCAAoC,SAAS,IAAI,uBAAuB,UAAU;AAClF;AACA;AACA,6CAA6C,UAAU;AACvD,2CAA2C,UAAU;AACrD;AACA,gDAAgD,QAAQ,IAAI,QAAQ;AACpE;AACA;AACA,+BAA+B,EAAE;AACjC,oCAAoC,MAAM,IAAI,QAAQ,SAAS,WAAW,QAAQ,QAAQ;AAC1F;AACA;AACA;AACA;AACA;AACA,gCAAgC,MAAM,KAAK;AAC3C;AACA;AACA;AACA,gCAAgC,KAAK,aAAa,WAAW;AAC7D,gCAAgC,KAAK,WAAW,UAAU,OAAO;AACjE;AACA,oCAAoC,KAAK,YAAY,QAAQ,IAAI,SAAS;AAC1E;AACA;AACA;AACA;AACA,uCAAuC,KAAK,SAAS;AACrD,uCAAuC,KAAK,OAAO;AACnD,uCAAuC,KAAK,QAAQ;AACpD;AACA;AACA;AACA;AACA,4BAA4B,IAAI,GAAG,KAAK,GAAG,IAAI,MAAM,MAAM;AAC3D;AACA;AACA,4BAA4B,IAAI,QAAQ,KAAK,EAAE;AAC/C;AACA,uBAAuB;AACvB;AACA;AACA;AACA,oCAAoC,KAAK,QAAQ,uBAAuB,IAAI,KAAK,4BAA4B;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,SAAS,gBAAgB,SAAS,WAAW,aAAa,EAAE;AAC5F,0CAA0C,sBAAsB;AAChE;AACA;AACA;AACA,oCAAoC,SAAS,IAAI,uBAAuB,UAAU;AAClF;AACA,6CAA6C,QAAQ;AACrD,2CAA2C,QAAQ;AACnD;AACA,+BAA+B,EAAE;AACjC,gCAAgC,SAAS,IAAI,QAAQ,SAAS,WAAW,QAAQ,QAAQ;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,SAAS,KAAK;AAC1C;AACA;AACA,gCAAgC,QAAQ,aAAa,WAAW;AAChE,gCAAgC,QAAQ,WAAW,UAAU,OAAO;AACpE;AACA;AACA,+BAA+B,IAAI,GAAG;AACtC;AACA;AACA;AACA,iCAAiC,IAAI;AACrC;AACA,gCAAgC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,KAAK;AACnE;AACA,uBAAuB;AACvB;AACA,mCAAmC,QAAQ,SAAS;AACpD,mCAAmC,QAAQ,OAAO;AAClD;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,SAAS,KAAK;AAC9C;AACA;AACA,oCAAoC,QAAQ,aAAa,WAAW;AACpE,oCAAoC,QAAQ,WAAW,UAAU,OAAO;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,QAAQ,SAAS;AAC5D,2CAA2C,QAAQ,OAAO;AAC1D;AACA;AACA;AACA;AACA;AACA,gCAAgC,SAAS,IAAI,oCAAoC,UAAU;AAC3F;AACA;AACA,yCAAyC,UAAU;AACnD,uCAAuC,UAAU;AACjD;AACA,2BAA2B,EAAE;AAC7B,4BAA4B,SAAS,IAAI,QAAQ,SAAS,WAAW,QAAQ,QAAQ;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,OAAO,SAAS;AAChD,gCAAgC,KAAK,IAAI;AACzC,0DAA0D;AAC1D,4BAA4B,KAAK,4BAA4B;AAC7D;AACA,gCAAgC,KAAK,QAAQ,uBAAuB,IAAI,IAAI,kCAAkC;AAC9G,sCAAsC;AACtC,2BAA2B;AAC3B,4BAA4B,YAAY,oBAAoB,MAAM,UAAU;AAC5E;AACA;AACA,4BAA4B,YAAY,0BAA0B;AAClE;AACA;AACA;AACA,4BAA4B,YAAY,qCAAqC,IAAI,EAAE;AACnF,sCAAsC,KAAK;AAC3C;AACA;AACA,4BAA4B,YAAY,4BAA4B,WAAW,EAAE;AACjF;AACA;AACA;AACA;AACA;AACA,wBAAwB,YAAY,IAAI,KAAK,cAAc,WAAW,cAAc;AACpF,4BAA4B,SAAS,SAAS;AAC9C,4BAA4B,SAAS,SAAS;AAC9C,4BAA4B,UAAU,WAAW;AACjD,iCAAiC,YAAY;AAC7C,iCAAiC;AACjC,+FAA+F;AAC/F;AACA;AACA,gCAAgC,YAAY,KAAK;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,SAAS,IAAI,oCAAoC,IAAI;AACrF,4BAA4B,YAAY,IAAI,QAAQ,QAAQ;AAC5D;AACA;AACA;AACA;AACA,iCAAiC,SAAS;AAC1C,mCAAmC,UAAU;AAC7C,iCAAiC,SAAS;AAC1C;AACA;AACA;AACA;AACA,4BAA4B,SAAS,IAAI,KAAK,QAAQ,uBAAuB,IAAI,QAAQ,EAAE;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,SAAS,SAAS;AAC9C;AACA,iCAAiC,QAAQ;AACzC;AACA,4BAA4B,SAAS,KAAK;AAC1C;AACA;AACA,gCAAgC,QAAQ,aAAa,WAAW;AAChE,gCAAgC,QAAQ,WAAW,UAAU,OAAO;AACpE;AACA;AACA;AACA;AACA;AACA,uCAAuC,QAAQ,SAAS;AACxD,uCAAuC,QAAQ,OAAO;AACtD;AACA;AACA;AACA;AACA,gCAAgC,SAAS,IAAI,oCAAoC,UAAU;AAC3F;AACA;AACA,yCAAyC,UAAU;AACnD,uCAAuC,UAAU;AACjD;AACA,2BAA2B,EAAE;AAC7B,4BAA4B,SAAS,IAAI,QAAQ,SAAS,WAAW,QAAQ,QAAQ;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,SAAS,gBAAgB,SAAS,WAAW,aAAa,EAAE;AACxF,sCAAsC,uBAAuB;AAC7D;AACA;AACA,iCAAiC,SAAS;AAC1C;AACA;AACA;AACA,wBAAwB,SAAS;AACjC;AACA;AACA","sources":["webpack://taxonium/./node_modules/@gmod/bbi/esm/bbi.js","webpack://taxonium/./node_modules/@gmod/bbi/esm/bigbed.js","webpack://taxonium/./node_modules/@gmod/bbi/esm/bigwig.js","webpack://taxonium/./node_modules/@gmod/bbi/esm/blockView.js","webpack://taxonium/./node_modules/@gmod/bbi/esm/index.js","webpack://taxonium/./node_modules/@gmod/bbi/esm/range.js","webpack://taxonium/./node_modules/@gmod/bbi/esm/unzip-pako.js","webpack://taxonium/./node_modules/@gmod/bbi/esm/util.js","webpack://taxonium/./node_modules/@gmod/bbi/node_modules/generic-filehandle/esm/blobFile.js","webpack://taxonium/./node_modules/@gmod/bbi/node_modules/generic-filehandle/esm/filehandle.js","webpack://taxonium/./node_modules/@gmod/bbi/node_modules/generic-filehandle/esm/index.js","webpack://taxonium/./node_modules/@gmod/bbi/node_modules/generic-filehandle/esm/remoteFile.js","webpack://taxonium/./node_modules/@gmod/bbi/node_modules/quick-lru/index.js","webpack://taxonium/./node_modules/binary-parser/dist/esm/binary_parser.mjs"],"sourcesContent":["import { Parser } from 'binary-parser';\nimport { LocalFile, RemoteFile } from 'generic-filehandle';\nimport { Observable } from 'rxjs';\nimport { reduce } from 'rxjs/operators';\nimport { BlockView } from './blockView';\nconst BIG_WIG_MAGIC = -2003829722;\nconst BIG_BED_MAGIC = -2021002517;\n/* get the compiled parsers for different sections of the bigwig file\n *\n * @param isBE - is big endian, typically false\n * @return an object with compiled parsers\n */\nfunction getParsers(isBE) {\n    const le = isBE ? 'big' : 'little';\n    const headerParser = new Parser()\n        .endianess(le)\n        .int32('magic')\n        .uint16('version')\n        .uint16('numZoomLevels')\n        .uint64('chromTreeOffset')\n        .uint64('unzoomedDataOffset')\n        .uint64('unzoomedIndexOffset')\n        .uint16('fieldCount')\n        .uint16('definedFieldCount')\n        .uint64('asOffset') // autoSql offset, used in bigbed\n        .uint64('totalSummaryOffset')\n        .uint32('uncompressBufSize')\n        .uint64('extHeaderOffset') // name index offset, used in bigbed\n        .array('zoomLevels', {\n        length: 'numZoomLevels',\n        type: new Parser()\n            .endianess(le)\n            .uint32('reductionLevel')\n            .uint32('reserved')\n            .uint64('dataOffset')\n            .uint64('indexOffset'),\n    });\n    const totalSummaryParser = new Parser()\n        .endianess(le)\n        .uint64('basesCovered')\n        .doublele('scoreMin')\n        .doublele('scoreMax')\n        .doublele('scoreSum')\n        .doublele('scoreSumSquares');\n    const chromTreeParser = new Parser()\n        .endianess(le)\n        .uint32('magic')\n        .uint32('blockSize')\n        .uint32('keySize')\n        .uint32('valSize')\n        .uint64('itemCount');\n    const isLeafNode = new Parser()\n        .endianess(le)\n        .uint8('isLeafNode')\n        .skip(1)\n        .uint16('cnt')\n        .saveOffset('offset');\n    return {\n        chromTreeParser,\n        totalSummaryParser,\n        headerParser,\n        isLeafNode,\n    };\n}\nexport class BBI {\n    /*\n     * @param filehandle - a filehandle from generic-filehandle or implementing something similar to the node10 fs.promises API\n     * @param path - a Local file path as a string\n     * @param url - a URL string\n     * @param renameRefSeqs - an optional method to rename the internal reference sequences using a mapping function\n     */\n    constructor(options = {}) {\n        const { filehandle, renameRefSeqs = s => s, path, url } = options;\n        this.renameRefSeqs = renameRefSeqs;\n        if (filehandle) {\n            this.bbi = filehandle;\n        }\n        else if (url) {\n            this.bbi = new RemoteFile(url);\n        }\n        else if (path) {\n            this.bbi = new LocalFile(path);\n        }\n        else {\n            throw new Error('no file given');\n        }\n    }\n    /* fetch and parse header information from a bigwig or bigbed file\n     * @param abortSignal - abort the operation, can be null\n     * @return a Header object\n     */\n    getHeader(opts = {}) {\n        const options = 'aborted' in opts ? { signal: opts } : opts;\n        if (!this.headerP) {\n            this.headerP = this._getHeader(options).catch(e => {\n                this.headerP = undefined;\n                throw e;\n            });\n        }\n        return this.headerP;\n    }\n    async _getHeader(opts) {\n        const header = await this._getMainHeader(opts);\n        const chroms = await this._readChromTree(header, opts);\n        return { ...header, ...chroms };\n    }\n    async _getMainHeader(opts, requestSize = 2000) {\n        const { buffer } = await this.bbi.read(Buffer.alloc(requestSize), 0, requestSize, 0, opts);\n        const isBigEndian = this._isBigEndian(buffer);\n        const ret = getParsers(isBigEndian);\n        const header = ret.headerParser.parse(buffer);\n        const { magic, asOffset, totalSummaryOffset } = header;\n        header.fileType = magic === BIG_BED_MAGIC ? 'bigbed' : 'bigwig';\n        if (asOffset > requestSize || totalSummaryOffset > requestSize) {\n            return this._getMainHeader(opts, requestSize * 2);\n        }\n        if (asOffset) {\n            const off = Number(header.asOffset);\n            header.autoSql = buffer\n                .subarray(off, buffer.indexOf(0, off))\n                .toString('utf8');\n        }\n        if (header.totalSummaryOffset > requestSize) {\n            return this._getMainHeader(opts, requestSize * 2);\n        }\n        if (header.totalSummaryOffset) {\n            const tail = buffer.subarray(Number(header.totalSummaryOffset));\n            const sum = ret.totalSummaryParser.parse(tail);\n            header.totalSummary = { ...sum, basesCovered: Number(sum.basesCovered) };\n        }\n        return { ...header, isBigEndian };\n    }\n    _isBigEndian(buffer) {\n        let ret = buffer.readInt32LE(0);\n        if (ret === BIG_WIG_MAGIC || ret === BIG_BED_MAGIC) {\n            return false;\n        }\n        ret = buffer.readInt32BE(0);\n        if (ret === BIG_WIG_MAGIC || ret === BIG_BED_MAGIC) {\n            return true;\n        }\n        throw new Error('not a BigWig/BigBed file');\n    }\n    // todo: add progress if long running\n    async _readChromTree(header, opts) {\n        const isBE = header.isBigEndian;\n        const le = isBE ? 'big' : 'little';\n        const refsByNumber = [];\n        const refsByName = {};\n        let unzoomedDataOffset = Number(header.unzoomedDataOffset);\n        const chromTreeOffset = Number(header.chromTreeOffset);\n        while (unzoomedDataOffset % 4 !== 0) {\n            unzoomedDataOffset += 1;\n        }\n        const off = unzoomedDataOffset - chromTreeOffset;\n        const { buffer } = await this.bbi.read(Buffer.alloc(off), 0, off, Number(chromTreeOffset), opts);\n        const p = getParsers(isBE);\n        const { keySize } = p.chromTreeParser.parse(buffer);\n        const leafNodeParser = new Parser()\n            .endianess(le)\n            .string('key', { stripNull: true, length: keySize })\n            .uint32('refId')\n            .uint32('refSize')\n            .saveOffset('offset');\n        const nonleafNodeParser = new Parser()\n            .endianess(le)\n            .skip(keySize)\n            .uint64('childOffset')\n            .saveOffset('offset');\n        const rootNodeOffset = 32;\n        const bptReadNode = async (currentOffset) => {\n            let offset = currentOffset;\n            if (offset >= buffer.length) {\n                throw new Error('reading beyond end of buffer');\n            }\n            const ret = p.isLeafNode.parse(buffer.subarray(offset));\n            const { isLeafNode, cnt } = ret;\n            offset += ret.offset;\n            if (isLeafNode) {\n                for (let n = 0; n < cnt; n += 1) {\n                    const leafRet = leafNodeParser.parse(buffer.subarray(offset));\n                    offset += leafRet.offset;\n                    const { key, refId, refSize } = leafRet;\n                    const refRec = { name: key, id: refId, length: refSize };\n                    refsByName[this.renameRefSeqs(key)] = refId;\n                    refsByNumber[refId] = refRec;\n                }\n            }\n            else {\n                // parse index node\n                const nextNodes = [];\n                for (let n = 0; n < cnt; n += 1) {\n                    const nonleafRet = nonleafNodeParser.parse(buffer.subarray(offset));\n                    const { childOffset } = nonleafRet;\n                    offset += nonleafRet.offset;\n                    nextNodes.push(bptReadNode(Number(childOffset) - Number(chromTreeOffset)));\n                }\n                await Promise.all(nextNodes);\n            }\n        };\n        await bptReadNode(rootNodeOffset);\n        return {\n            refsByName,\n            refsByNumber,\n        };\n    }\n    /*\n     * fetches the \"unzoomed\" view of the bigwig data. this is the default for bigbed\n     * @param abortSignal - a signal to optionally abort this operation\n     */\n    async getUnzoomedView(opts) {\n        const { unzoomedIndexOffset, refsByName, uncompressBufSize, isBigEndian, fileType, } = await this.getHeader(opts);\n        return new BlockView(this.bbi, refsByName, unzoomedIndexOffset, isBigEndian, uncompressBufSize > 0, fileType);\n    }\n    /**\n     * Gets features from a BigWig file\n     *\n     * @param refName - The chromosome name\n     * @param start - The start of a region\n     * @param end - The end of a region\n     * @param opts - An object containing basesPerSpan (e.g. pixels per basepair) or scale used to infer the zoomLevel to use\n     */\n    async getFeatureStream(refName, start, end, opts = {\n        scale: 1,\n    }) {\n        await this.getHeader(opts);\n        const chrName = this.renameRefSeqs(refName);\n        let view;\n        if (opts.basesPerSpan) {\n            view = await this.getView(1 / opts.basesPerSpan, opts);\n        }\n        else if (opts.scale) {\n            view = await this.getView(opts.scale, opts);\n        }\n        else {\n            view = await this.getView(1, opts);\n        }\n        if (!view) {\n            throw new Error('unable to get block view for data');\n        }\n        return new Observable((observer) => {\n            view.readWigData(chrName, start, end, observer, opts);\n        });\n    }\n    async getFeatures(refName, start, end, opts = {\n        scale: 1,\n    }) {\n        const ob = await this.getFeatureStream(refName, start, end, opts);\n        const ret = await ob\n            .pipe(reduce((acc, curr) => acc.concat(curr)))\n            .toPromise();\n        return ret || [];\n    }\n}\n//# sourceMappingURL=bbi.js.map","import { Parser } from 'binary-parser';\nimport { Observable, merge } from 'rxjs';\nimport { map, reduce } from 'rxjs/operators';\nimport AbortablePromiseCache from 'abortable-promise-cache';\nimport QuickLRU from 'quick-lru';\nimport { BBI } from './bbi';\nexport function filterUndef(ts) {\n    return ts.filter((t) => !!t);\n}\nexport class BigBed extends BBI {\n    constructor() {\n        super(...arguments);\n        this.readIndicesCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: 1 }),\n            fill: async (args, signal) => {\n                return this._readIndices({ ...args, signal });\n            },\n        });\n    }\n    readIndices(opts = {}) {\n        const options = 'aborted' in opts ? { signal: opts } : opts;\n        return this.readIndicesCache.get(JSON.stringify(options), options, options.signal);\n    }\n    /*\n     * retrieve unzoomed view for any scale\n     * @param scale - unused\n     * @param abortSignal - an optional AbortSignal to kill operation\n     * @return promise for a BlockView\n     */\n    async getView(_scale, opts) {\n        return this.getUnzoomedView(opts);\n    }\n    /*\n     * parse the bigbed extraIndex fields\n     * @param abortSignal to abort operation\n     * @return a Promise for an array of Index data structure since there can be multiple extraIndexes in a bigbed, see bedToBigBed documentation\n     */\n    async _readIndices(opts) {\n        const { extHeaderOffset, isBigEndian } = await this.getHeader(opts);\n        const { buffer: data } = await this.bbi.read(Buffer.alloc(64), 0, 64, Number(extHeaderOffset));\n        const le = isBigEndian ? 'big' : 'little';\n        const ret = new Parser()\n            .endianess(le)\n            .uint16('size')\n            .uint16('count')\n            .uint64('offset')\n            .parse(data);\n        const { count, offset } = ret;\n        // no extra index is defined if count==0\n        if (count === 0) {\n            return [];\n        }\n        const blocklen = 20;\n        const len = blocklen * count;\n        const { buffer } = await this.bbi.read(Buffer.alloc(len), 0, len, Number(offset));\n        const extParser = new Parser()\n            .endianess(le)\n            .int16('type')\n            .int16('fieldcount')\n            .uint64('offset')\n            .skip(4)\n            .int16('field');\n        const indices = [];\n        for (let i = 0; i < count; i += 1) {\n            indices.push(extParser.parse(buffer.subarray(i * blocklen)));\n        }\n        return indices;\n    }\n    /*\n     * perform a search in the bigbed extraIndex to find which blocks in the bigbed data to look for the\n     * actual feature data\n     *\n     * @param name - the name to search for\n     * @param opts - a SearchOptions argument with optional signal\n     * @return a Promise for an array of bigbed block Loc entries\n     */\n    async searchExtraIndexBlocks(name, opts = {}) {\n        const { isBigEndian } = await this.getHeader(opts);\n        const indices = await this.readIndices(opts);\n        if (!indices.length) {\n            return [];\n        }\n        const locs = indices.map(async (index) => {\n            const { offset, field } = index;\n            const { buffer: data } = await this.bbi.read(Buffer.alloc(32), 0, 32, Number(offset), opts);\n            const le = isBigEndian ? 'big' : 'little';\n            const p = new Parser()\n                .endianess(le)\n                .int32('magic')\n                .int32('blockSize')\n                .int32('keySize')\n                .int32('valSize')\n                .uint64('itemCount');\n            const { blockSize, keySize, valSize } = p.parse(data);\n            // console.log({blockSize,keySize,valSize})\n            const bpt = new Parser()\n                .endianess(le)\n                .int8('nodeType')\n                .skip(1)\n                .int16('cnt')\n                .choice({\n                tag: 'nodeType',\n                choices: {\n                    0: new Parser().array('leafkeys', {\n                        length: 'cnt',\n                        type: new Parser()\n                            .endianess(le)\n                            .string('key', { length: keySize, stripNull: true })\n                            .uint64('offset'),\n                    }),\n                    1: new Parser().array('keys', {\n                        length: 'cnt',\n                        type: new Parser()\n                            .endianess(le)\n                            .string('key', { length: keySize, stripNull: true })\n                            .uint64('offset')\n                            .uint32('length')\n                            .uint32('reserved'),\n                    }),\n                },\n            });\n            const bptReadNode = async (nodeOffset) => {\n                const val = Number(nodeOffset);\n                const len = 4 + blockSize * (keySize + valSize);\n                const { buffer } = await this.bbi.read(Buffer.alloc(len), 0, len, val, opts);\n                const node = bpt.parse(buffer);\n                if (node.leafkeys) {\n                    let lastOffset;\n                    for (let i = 0; i < node.leafkeys.length; i += 1) {\n                        const { key } = node.leafkeys[i];\n                        if (name.localeCompare(key) < 0 && lastOffset) {\n                            return bptReadNode(lastOffset);\n                        }\n                        lastOffset = node.leafkeys[i].offset;\n                    }\n                    return bptReadNode(lastOffset);\n                }\n                for (let i = 0; i < node.keys.length; i += 1) {\n                    if (node.keys[i].key === name) {\n                        return { ...node.keys[i], field };\n                    }\n                }\n                return undefined;\n            };\n            const rootNodeOffset = 32;\n            return bptReadNode(Number(offset) + rootNodeOffset);\n        });\n        return filterUndef(await Promise.all(locs));\n    }\n    /*\n     * retrieve the features from the bigbed data that were found through the lookup of the extraIndex\n     * note that there can be multiple extraIndex, see the BigBed specification and the -extraIndex argument to bedToBigBed\n     *\n     * @param name - the name to search for\n     * @param opts - a SearchOptions argument with optional signal\n     * @return a Promise for an array of Feature\n     */\n    async searchExtraIndex(name, opts = {}) {\n        const blocks = await this.searchExtraIndexBlocks(name, opts);\n        if (!blocks.length) {\n            return [];\n        }\n        const view = await this.getUnzoomedView(opts);\n        const res = blocks.map(block => {\n            return new Observable(observer => {\n                view.readFeatures(observer, [block], opts);\n            }).pipe(reduce((acc, curr) => acc.concat(curr)), map(x => {\n                for (let i = 0; i < x.length; i += 1) {\n                    x[i].field = block.field;\n                }\n                return x;\n            }));\n        });\n        const ret = await merge(...res).toPromise();\n        return ret.filter(f => { var _a; return ((_a = f.rest) === null || _a === void 0 ? void 0 : _a.split('\\t')[(f.field || 0) - 3]) === name; });\n    }\n}\n//# sourceMappingURL=bigbed.js.map","import { BlockView } from './blockView';\nimport { BBI } from './bbi';\nexport class BigWig extends BBI {\n    /**\n     * Retrieves a BlockView of a specific zoomLevel\n     *\n     * @param scale - number\n     * @param opts - An object containing basesPerSpan (e.g. pixels per basepair) or scale used to infer the zoomLevel to use\n     */\n    async getView(scale, opts) {\n        const { zoomLevels, refsByName, fileSize, isBigEndian, uncompressBufSize } = await this.getHeader(opts);\n        const basesPerPx = 1 / scale;\n        let maxLevel = zoomLevels.length;\n        if (!fileSize) {\n            // if we don't know the file size, we can't fetch the highest zoom level :-(\n            maxLevel -= 1;\n        }\n        for (let i = maxLevel; i >= 0; i -= 1) {\n            const zh = zoomLevels[i];\n            if (zh && zh.reductionLevel <= 2 * basesPerPx) {\n                const indexOffset = Number(zh.indexOffset);\n                return new BlockView(this.bbi, refsByName, indexOffset, isBigEndian, uncompressBufSize > 0, 'summary');\n            }\n        }\n        return this.getUnzoomedView(opts);\n    }\n}\n//# sourceMappingURL=bigwig.js.map","import { Parser } from 'binary-parser';\nimport AbortablePromiseCache from 'abortable-promise-cache';\nimport QuickLRU from 'quick-lru';\n// locals\nimport Range from './range';\nimport { unzip } from './unzip';\nimport { groupBlocks, checkAbortSignal } from './util';\nconst BIG_WIG_TYPE_GRAPH = 1;\nconst BIG_WIG_TYPE_VSTEP = 2;\nconst BIG_WIG_TYPE_FSTEP = 3;\nfunction coordFilter(s1, e1, s2, e2) {\n    return s1 < e2 && e1 >= s2;\n}\nfunction getParsers(isBigEndian) {\n    const le = isBigEndian ? 'big' : 'little';\n    const summaryParser = new Parser()\n        .endianess(le)\n        .uint32('chromId')\n        .uint32('start')\n        .uint32('end')\n        .uint32('validCnt')\n        .floatle('minScore')\n        .floatle('maxScore')\n        .floatle('sumData')\n        .floatle('sumSqData')\n        .saveOffset('offset');\n    const leafParser = new Parser()\n        .endianess(le)\n        .uint8('isLeaf')\n        .skip(1)\n        .uint16('cnt')\n        .choice({\n        tag: 'isLeaf',\n        choices: {\n            1: new Parser().endianess(le).array('blocksToFetch', {\n                length: 'cnt',\n                type: new Parser()\n                    .endianess(le)\n                    .uint32('startChrom')\n                    .uint32('startBase')\n                    .uint32('endChrom')\n                    .uint32('endBase')\n                    .uint64('blockOffset')\n                    .uint64('blockSize')\n                    .saveOffset('offset'),\n            }),\n            0: new Parser().array('recurOffsets', {\n                length: 'cnt',\n                type: new Parser()\n                    .endianess(le)\n                    .uint32('startChrom')\n                    .uint32('startBase')\n                    .uint32('endChrom')\n                    .uint32('endBase')\n                    .uint64('blockOffset')\n                    .saveOffset('offset'),\n            }),\n        },\n    });\n    const bigBedParser = new Parser()\n        .endianess(le)\n        .uint32('chromId')\n        .int32('start')\n        .int32('end')\n        .string('rest', {\n        zeroTerminated: true,\n    })\n        .saveOffset('offset');\n    const bigWigParser = new Parser()\n        .endianess(le)\n        .skip(4)\n        .int32('blockStart')\n        .skip(4)\n        .uint32('itemStep')\n        .uint32('itemSpan')\n        .uint8('blockType')\n        .skip(1)\n        .uint16('itemCount')\n        .choice({\n        tag: 'blockType',\n        choices: {\n            [BIG_WIG_TYPE_FSTEP]: new Parser().array('items', {\n                length: 'itemCount',\n                type: new Parser().floatle('score'),\n            }),\n            [BIG_WIG_TYPE_VSTEP]: new Parser().array('items', {\n                length: 'itemCount',\n                type: new Parser().endianess(le).int32('start').floatle('score'),\n            }),\n            [BIG_WIG_TYPE_GRAPH]: new Parser().array('items', {\n                length: 'itemCount',\n                type: new Parser()\n                    .endianess(le)\n                    .int32('start')\n                    .int32('end')\n                    .floatle('score'),\n            }),\n        },\n    });\n    return {\n        bigWigParser,\n        bigBedParser,\n        summaryParser,\n        leafParser,\n    };\n}\n/**\n * View into a subset of the data in a BigWig file.\n *\n * Adapted by Robert Buels and Colin Diesh from bigwig.js in the Dalliance Genome\n * Explorer by Thomas Down.\n * @constructs\n */\nexport class BlockView {\n    constructor(bbi, refsByName, cirTreeOffset, isBigEndian, isCompressed, blockType) {\n        this.bbi = bbi;\n        this.refsByName = refsByName;\n        this.cirTreeOffset = cirTreeOffset;\n        this.isBigEndian = isBigEndian;\n        this.isCompressed = isCompressed;\n        this.blockType = blockType;\n        this.featureCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: 1000 }),\n            fill: async (requestData, signal) => {\n                const len = Number(requestData.length);\n                const off = Number(requestData.offset);\n                const { buffer } = await this.bbi.read(Buffer.alloc(len), 0, len, off, {\n                    signal,\n                });\n                return buffer;\n            },\n        });\n        if (!(cirTreeOffset >= 0)) {\n            throw new Error('invalid cirTreeOffset!');\n        }\n        const parsers = getParsers(isBigEndian);\n        this.leafParser = parsers.leafParser;\n        this.bigBedParser = parsers.bigBedParser;\n    }\n    async readWigData(chrName, start, end, observer, opts) {\n        try {\n            const { refsByName, bbi, cirTreeOffset, isBigEndian } = this;\n            const chrId = refsByName[chrName];\n            if (chrId === undefined) {\n                observer.complete();\n            }\n            const request = { chrId, start, end };\n            if (!this.cirTreePromise) {\n                const off = Number(cirTreeOffset);\n                this.cirTreePromise = bbi.read(Buffer.alloc(48), 0, 48, off, opts);\n            }\n            const { buffer } = await this.cirTreePromise;\n            const cirBlockSize = isBigEndian\n                ? buffer.readUInt32BE(4)\n                : buffer.readUInt32LE(4);\n            let blocksToFetch = [];\n            let outstanding = 0;\n            const cirFobRecur2 = (cirBlockData, offset, level) => {\n                try {\n                    const data = cirBlockData.subarray(offset);\n                    const p = this.leafParser.parse(data);\n                    if (p.blocksToFetch) {\n                        blocksToFetch = blocksToFetch.concat(p.blocksToFetch\n                            .filter(filterFeats)\n                            .map((l) => ({\n                            offset: l.blockOffset,\n                            length: l.blockSize,\n                        })));\n                    }\n                    if (p.recurOffsets) {\n                        const recurOffsets = p.recurOffsets\n                            .filter(filterFeats)\n                            .map((l) => Number(l.blockOffset));\n                        if (recurOffsets.length > 0) {\n                            cirFobRecur(recurOffsets, level + 1);\n                        }\n                    }\n                }\n                catch (e) {\n                    observer.error(e);\n                }\n            };\n            const filterFeats = (b) => {\n                const { startChrom, startBase, endChrom, endBase } = b;\n                return ((startChrom < chrId || (startChrom === chrId && startBase <= end)) &&\n                    (endChrom > chrId || (endChrom === chrId && endBase >= start)));\n            };\n            const cirFobStartFetch = async (off, fr, level) => {\n                try {\n                    const length = fr.max() - fr.min();\n                    const offset = fr.min();\n                    const resultBuffer = await this.featureCache.get(`${length}_${offset}`, { length, offset }, opts.signal);\n                    for (let i = 0; i < off.length; i += 1) {\n                        if (fr.contains(off[i])) {\n                            cirFobRecur2(resultBuffer, off[i] - offset, level);\n                            outstanding -= 1;\n                            if (outstanding === 0) {\n                                this.readFeatures(observer, blocksToFetch, { ...opts, request });\n                            }\n                        }\n                    }\n                }\n                catch (e) {\n                    observer.error(e);\n                }\n            };\n            const cirFobRecur = (offset, level) => {\n                try {\n                    outstanding += offset.length;\n                    const maxCirBlockSpan = 4 + Number(cirBlockSize) * 32; // Upper bound on size, based on a completely full leaf node.\n                    let spans = new Range(offset[0], offset[0] + maxCirBlockSpan);\n                    for (let i = 1; i < offset.length; i += 1) {\n                        const blockSpan = new Range(offset[i], offset[i] + maxCirBlockSpan);\n                        spans = spans.union(blockSpan);\n                    }\n                    spans.getRanges().map(fr => cirFobStartFetch(offset, fr, level));\n                }\n                catch (e) {\n                    observer.error(e);\n                }\n            };\n            return cirFobRecur([Number(cirTreeOffset) + 48], 1);\n        }\n        catch (e) {\n            observer.error(e);\n        }\n    }\n    parseSummaryBlock(buffer, startOffset, request) {\n        const features = [];\n        let offset = startOffset;\n        const dataView = new DataView(buffer.buffer, buffer.byteOffset, buffer.length);\n        while (offset < buffer.byteLength) {\n            // this was extracted from looking at the runtime code generated by\n            // binary-parser\n            const chromId = dataView.getUint32(offset, true);\n            offset += 4;\n            const start = dataView.getUint32(offset, true);\n            offset += 4;\n            const end = dataView.getUint32(offset, true);\n            offset += 4;\n            const validCnt = dataView.getUint32(offset, true);\n            offset += 4;\n            const minScore = dataView.getFloat32(offset, true);\n            offset += 4;\n            const maxScore = dataView.getFloat32(offset, true);\n            offset += 4;\n            const sumData = dataView.getFloat32(offset, true);\n            offset += 4;\n            // unused\n            // const sumSqData = dataView.getFloat32(offset, true)\n            offset += 4;\n            if (request\n                ? chromId === request.chrId &&\n                    coordFilter(start, end, request.start, request.end)\n                : true) {\n                features.push({\n                    start,\n                    end,\n                    maxScore,\n                    minScore,\n                    summary: true,\n                    score: sumData / (validCnt || 1),\n                });\n            }\n        }\n        return features;\n    }\n    parseBigBedBlock(data, startOffset, offset, request) {\n        const items = [];\n        let currOffset = startOffset;\n        while (currOffset < data.byteLength) {\n            const res = this.bigBedParser.parse(data.subarray(currOffset));\n            items.push({ ...res, uniqueId: `bb-${offset + currOffset}` });\n            currOffset += res.offset;\n        }\n        return request\n            ? items.filter((f) => coordFilter(f.start, f.end, request.start, request.end))\n            : items;\n    }\n    parseBigWigBlock(buffer, startOffset, request) {\n        const b = buffer.subarray(startOffset);\n        const dataView = new DataView(b.buffer, b.byteOffset, b.length);\n        let offset = 0;\n        offset += 4;\n        const blockStart = dataView.getInt32(offset, true);\n        offset += 8;\n        const itemStep = dataView.getUint32(offset, true);\n        offset += 4;\n        const itemSpan = dataView.getUint32(offset, true);\n        offset += 4;\n        const blockType = dataView.getUint8(offset);\n        offset += 2;\n        const itemCount = dataView.getUint16(offset, true);\n        offset += 2;\n        const items = new Array(itemCount);\n        switch (blockType) {\n            case 1:\n                for (let i = 0; i < itemCount; i++) {\n                    const start = dataView.getInt32(offset, true);\n                    offset += 4;\n                    const end = dataView.getInt32(offset, true);\n                    offset += 4;\n                    const score = dataView.getFloat32(offset, true);\n                    offset += 4;\n                    items[i] = { start, end, score };\n                }\n                break;\n            case 2:\n                for (let i = 0; i < itemCount; i++) {\n                    const start = dataView.getInt32(offset, true);\n                    offset += 4;\n                    const score = dataView.getFloat32(offset, true);\n                    offset += 4;\n                    items[i] = { score, start, end: start + itemSpan };\n                }\n                break;\n            case 3:\n                for (let i = 0; i < itemCount; i++) {\n                    const score = dataView.getFloat32(offset, true);\n                    offset += 4;\n                    const start = blockStart + i * itemStep;\n                    items[i] = { score, start, end: start + itemSpan };\n                }\n                break;\n        }\n        return request\n            ? items.filter((f) => coordFilter(f.start, f.end, request.start, request.end))\n            : items;\n    }\n    async readFeatures(observer, blocks, opts = {}) {\n        try {\n            const { blockType, isCompressed } = this;\n            const { signal, request } = opts;\n            const blockGroupsToFetch = groupBlocks(blocks);\n            checkAbortSignal(signal);\n            await Promise.all(blockGroupsToFetch.map(async (blockGroup) => {\n                checkAbortSignal(signal);\n                const { length, offset } = blockGroup;\n                const data = await this.featureCache.get(`${length}_${offset}`, blockGroup, signal);\n                blockGroup.blocks.forEach(block => {\n                    checkAbortSignal(signal);\n                    let blockOffset = Number(block.offset) - Number(blockGroup.offset);\n                    let resultData = data;\n                    if (isCompressed) {\n                        resultData = unzip(data.subarray(blockOffset));\n                        blockOffset = 0;\n                    }\n                    checkAbortSignal(signal);\n                    switch (blockType) {\n                        case 'summary':\n                            observer.next(this.parseSummaryBlock(resultData, blockOffset, request));\n                            break;\n                        case 'bigwig':\n                            observer.next(this.parseBigWigBlock(resultData, blockOffset, request));\n                            break;\n                        case 'bigbed':\n                            observer.next(this.parseBigBedBlock(resultData, blockOffset, Number(block.offset) * (1 << 8), request));\n                            break;\n                        default:\n                            console.warn(`Don't know what to do with ${blockType}`);\n                    }\n                });\n            }));\n            observer.complete();\n        }\n        catch (e) {\n            observer.error(e);\n        }\n    }\n}\n//# sourceMappingURL=blockView.js.map","export { BigWig } from './bigwig';\nexport { BigBed } from './bigbed';\n//# sourceMappingURL=index.js.map","/* eslint prefer-rest-params:0, no-nested-ternary:0 */\n/**\n * Adapted from a combination of Range and _Compound in the\n * Dalliance Genome Explorer, (c) Thomas Down 2006-2010.\n */\nexport default class Range {\n    constructor(arg1, arg2) {\n        this.ranges =\n            arguments.length === 2\n                ? [{ min: arg1, max: arg2 }]\n                : 0 in arg1\n                    ? Object.assign({}, arg1)\n                    : [arg1];\n    }\n    min() {\n        return this.ranges[0].min;\n    }\n    max() {\n        return this.ranges[this.ranges.length - 1].max;\n    }\n    contains(pos) {\n        for (let s = 0; s < this.ranges.length; s += 1) {\n            const r = this.ranges[s];\n            if (r.min <= pos && r.max >= pos) {\n                return true;\n            }\n        }\n        return false;\n    }\n    isContiguous() {\n        return this.ranges.length > 1;\n    }\n    getRanges() {\n        return this.ranges.map((r) => new Range(r.min, r.max));\n    }\n    toString() {\n        return this.ranges.map((r) => `[${r.min}-${r.max}]`).join(',');\n    }\n    union(s1) {\n        const ranges = this.getRanges().concat(s1.getRanges()).sort(this.rangeOrder);\n        const oranges = [];\n        let current = ranges[0];\n        for (let i = 1; i < ranges.length; i += 1) {\n            const nxt = ranges[i];\n            if (nxt.min() > current.max() + 1) {\n                oranges.push(current);\n                current = nxt;\n            }\n            else if (nxt.max() > current.max()) {\n                current = new Range(current.min(), nxt.max());\n            }\n        }\n        oranges.push(current);\n        if (oranges.length === 1) {\n            return oranges[0];\n        }\n        return new Range(oranges);\n    }\n    intersection(arg) {\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        let s0 = this;\n        let s1 = arg;\n        const r0 = this.ranges();\n        const r1 = s1.ranges();\n        const l0 = r0.length;\n        const l1 = r1.length;\n        let i0 = 0;\n        let i1 = 0;\n        const or = [];\n        while (i0 < l0 && i1 < l1) {\n            s0 = r0[i0];\n            s1 = r1[i1];\n            const lapMin = Math.max(s0.min(), s1.min());\n            const lapMax = Math.min(s0.max(), s1.max());\n            if (lapMax >= lapMin) {\n                or.push(new Range(lapMin, lapMax));\n            }\n            if (s0.max() > s1.max()) {\n                i1 += 1;\n            }\n            else {\n                i0 += 1;\n            }\n        }\n        if (or.length === 0) {\n            throw new Error('found range of length 0');\n        }\n        if (or.length === 1) {\n            return or[0];\n        }\n        return new Range(or);\n    }\n    coverage() {\n        let tot = 0;\n        const rl = this.ranges();\n        for (let ri = 0; ri < rl.length; ri += 1) {\n            const r = rl[ri];\n            tot += r.max() - r.min() + 1;\n        }\n        return tot;\n    }\n    rangeOrder(tmpa, tmpb) {\n        let a = tmpa;\n        let b = tmpb;\n        if (arguments.length < 2) {\n            b = a;\n            // eslint-disable-next-line @typescript-eslint/no-this-alias\n            a = this;\n        }\n        if (a.min() < b.min()) {\n            return -1;\n        }\n        if (a.min() > b.min()) {\n            return 1;\n        }\n        if (a.max() < b.max()) {\n            return -1;\n        }\n        if (b.max() > a.max()) {\n            return 1;\n        }\n        return 0;\n    }\n}\n//# sourceMappingURL=range.js.map","import { inflateRaw } from 'pako';\nexport function unzip(input) {\n    return inflateRaw(input.subarray(2));\n}\n//# sourceMappingURL=unzip-pako.js.map","/* eslint no-bitwise: [\"error\", { \"allow\": [\"|\"] }] */\nexport class AbortError extends Error {\n    constructor(message) {\n        super(message);\n        this.code = 'ERR_ABORTED';\n    }\n}\n// sort blocks by file offset and\n// group blocks that are within 2KB of eachother\nexport function groupBlocks(blocks) {\n    blocks.sort((b0, b1) => Number(b0.offset) - Number(b1.offset));\n    const blockGroups = [];\n    let lastBlock;\n    let lastBlockEnd;\n    for (let i = 0; i < blocks.length; i += 1) {\n        if (lastBlock &&\n            lastBlockEnd &&\n            Number(blocks[i].offset) - lastBlockEnd <= 2000) {\n            lastBlock.length = BigInt(Number(lastBlock.length) +\n                Number(blocks[i].length) -\n                lastBlockEnd +\n                Number(blocks[i].offset));\n            lastBlock.blocks.push(blocks[i]);\n        }\n        else {\n            blockGroups.push((lastBlock = {\n                blocks: [blocks[i]],\n                length: blocks[i].length,\n                offset: blocks[i].offset,\n            }));\n        }\n        lastBlockEnd = Number(lastBlock.offset) + Number(lastBlock.length);\n    }\n    return blockGroups;\n}\n/**\n * Properly check if the given AbortSignal is aborted.\n * Per the standard, if the signal reads as aborted,\n * this function throws either a DOMException AbortError, or a regular error\n * with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nexport function checkAbortSignal(signal) {\n    if (!signal) {\n        return;\n    }\n    if (signal.aborted) {\n        // console.log('bam aborted!')\n        if (typeof DOMException !== 'undefined') {\n            throw new DOMException('aborted', 'AbortError');\n        }\n        else {\n            const e = new AbortError('aborted');\n            e.code = 'ERR_ABORTED';\n            throw e;\n        }\n    }\n}\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal) {\n    await Promise.resolve();\n    checkAbortSignal(signal);\n}\n//# sourceMappingURL=util.js.map","import { Buffer } from 'buffer';\n// Using this you can \"await\" the file like a normal promise\n// https://blog.shovonhasan.com/using-promises-with-filereader/\nfunction readBlobAsArrayBuffer(blob) {\n    const fileReader = new FileReader();\n    return new Promise((resolve, reject) => {\n        fileReader.onerror = () => {\n            fileReader.abort();\n            reject(new Error('problem reading blob'));\n        };\n        fileReader.onabort = () => {\n            reject(new Error('blob reading was aborted'));\n        };\n        fileReader.onload = () => {\n            if (fileReader.result && typeof fileReader.result !== 'string') {\n                resolve(fileReader.result);\n            }\n            else {\n                reject(new Error('unknown error reading blob'));\n            }\n        };\n        fileReader.readAsArrayBuffer(blob);\n    });\n}\nfunction readBlobAsText(blob) {\n    const fileReader = new FileReader();\n    return new Promise((resolve, reject) => {\n        fileReader.onerror = () => {\n            fileReader.abort();\n            reject(new Error('problem reading blob'));\n        };\n        fileReader.onabort = () => {\n            reject(new Error('blob reading was aborted'));\n        };\n        fileReader.onload = () => {\n            if (fileReader.result && typeof fileReader.result === 'string') {\n                resolve(fileReader.result);\n            }\n            else {\n                reject(new Error('unknown error reading blob'));\n            }\n        };\n        fileReader.readAsText(blob);\n    });\n}\n/**\n * Blob of binary data fetched from a local file (with FileReader).\n *\n * Adapted by Robert Buels and Garrett Stevens from the BlobFetchable object in\n * the Dalliance Genome Explorer, which is copyright Thomas Down 2006-2011.\n */\nexport default class BlobFile {\n    constructor(blob) {\n        this.blob = blob;\n        this.size = blob.size;\n    }\n    async read(buffer, offset = 0, length, position = 0) {\n        // short-circuit a read of 0 bytes here, because browsers actually sometimes\n        // crash if you try to read 0 bytes from a local file!\n        if (!length) {\n            return { bytesRead: 0, buffer };\n        }\n        const start = position;\n        const end = start + length;\n        const result = await readBlobAsArrayBuffer(this.blob.slice(start, end));\n        const resultBuffer = Buffer.from(result);\n        const bytesCopied = resultBuffer.copy(buffer, offset);\n        return { bytesRead: bytesCopied, buffer: resultBuffer };\n    }\n    async readFile(options) {\n        let encoding;\n        if (typeof options === 'string') {\n            encoding = options;\n        }\n        else {\n            encoding = options && options.encoding;\n        }\n        if (encoding === 'utf8') {\n            return readBlobAsText(this.blob);\n        }\n        if (encoding) {\n            throw new Error(`unsupported encoding: ${encoding}`);\n        }\n        const result = await readBlobAsArrayBuffer(this.blob);\n        return Buffer.from(result);\n    }\n    async stat() {\n        return { size: this.size };\n    }\n    async close() {\n        return;\n    }\n}\n","export {};\n","import LocalFile from './localFile';\nimport RemoteFile from './remoteFile';\nimport BlobFile from './blobFile';\nexport * from './filehandle';\nfunction fromUrl(source, opts = {}) {\n    return new RemoteFile(source, opts);\n}\nfunction open(maybeUrl, maybePath, maybeFilehandle, opts = {}) {\n    if (maybeFilehandle !== undefined) {\n        return maybeFilehandle;\n    }\n    if (maybeUrl !== undefined) {\n        return fromUrl(maybeUrl, opts);\n    }\n    if (maybePath !== undefined) {\n        return new LocalFile(maybePath, opts);\n    }\n    throw new Error('no url, path, or filehandle provided, cannot open');\n}\nexport { open, fromUrl, RemoteFile, LocalFile, BlobFile };\n","import { Buffer } from 'buffer';\nconst myGlobal = typeof window !== 'undefined'\n    ? window\n    : typeof self !== 'undefined'\n        ? self\n        : { fetch: undefined };\nexport default class RemoteFile {\n    constructor(source, opts = {}) {\n        this.baseOverrides = {};\n        this.url = source;\n        const fetch = opts.fetch || (myGlobal.fetch && myGlobal.fetch.bind(myGlobal));\n        if (!fetch) {\n            throw new TypeError(`no fetch function supplied, and none found in global environment`);\n        }\n        if (opts.overrides) {\n            this.baseOverrides = opts.overrides;\n        }\n        this.fetchImplementation = fetch;\n    }\n    async getBufferFromResponse(response) {\n        if (typeof response.buffer === 'function') {\n            return response.buffer();\n        }\n        else if (typeof response.arrayBuffer === 'function') {\n            const resp = await response.arrayBuffer();\n            return Buffer.from(resp);\n        }\n        else {\n            throw new TypeError('invalid HTTP response object, has no buffer method, and no arrayBuffer method');\n        }\n    }\n    async fetch(input, init) {\n        let response;\n        try {\n            response = await this.fetchImplementation(input, init);\n        }\n        catch (e) {\n            if (`${e}`.includes('Failed to fetch')) {\n                // refetch to to help work around a chrome bug (discussed in\n                // generic-filehandle issue #72) in which the chrome cache returns a\n                // CORS error for content in its cache.  see also\n                // https://github.com/GMOD/jbrowse-components/pull/1511\n                console.warn(`generic-filehandle: refetching ${input} to attempt to work around chrome CORS header caching bug`);\n                response = await this.fetchImplementation(input, {\n                    ...init,\n                    cache: 'reload',\n                });\n            }\n            else {\n                throw e;\n            }\n        }\n        return response;\n    }\n    async read(buffer, offset = 0, length, position = 0, opts = {}) {\n        const { headers = {}, signal, overrides = {} } = opts;\n        if (length < Infinity) {\n            headers.range = `bytes=${position}-${position + length}`;\n        }\n        else if (length === Infinity && position !== 0) {\n            headers.range = `bytes=${position}-`;\n        }\n        const args = {\n            ...this.baseOverrides,\n            ...overrides,\n            headers: {\n                ...headers,\n                ...overrides.headers,\n                ...this.baseOverrides.headers,\n            },\n            method: 'GET',\n            redirect: 'follow',\n            mode: 'cors',\n            signal,\n        };\n        const response = await this.fetch(this.url, args);\n        if (!response.ok) {\n            throw new Error(`HTTP ${response.status} ${response.statusText} ${this.url}`);\n        }\n        if ((response.status === 200 && position === 0) ||\n            response.status === 206) {\n            const responseData = await this.getBufferFromResponse(response);\n            const bytesCopied = responseData.copy(buffer, offset, 0, Math.min(length, responseData.length));\n            // try to parse out the size of the remote file\n            const res = response.headers.get('content-range');\n            const sizeMatch = /\\/(\\d+)$/.exec(res || '');\n            if (sizeMatch && sizeMatch[1]) {\n                this._stat = { size: parseInt(sizeMatch[1], 10) };\n            }\n            return { bytesRead: bytesCopied, buffer };\n        }\n        if (response.status === 200) {\n            throw new Error('${this.url} fetch returned status 200, expected 206');\n        }\n        // TODO: try harder here to gather more information about what the problem is\n        throw new Error(`HTTP ${response.status} fetching ${this.url}`);\n    }\n    async readFile(options = {}) {\n        let encoding;\n        let opts;\n        if (typeof options === 'string') {\n            encoding = options;\n            opts = {};\n        }\n        else {\n            encoding = options.encoding;\n            opts = options;\n            delete opts.encoding;\n        }\n        const { headers = {}, signal, overrides = {} } = opts;\n        const args = {\n            headers,\n            method: 'GET',\n            redirect: 'follow',\n            mode: 'cors',\n            signal,\n            ...this.baseOverrides,\n            ...overrides,\n        };\n        const response = await this.fetch(this.url, args);\n        if (!response) {\n            throw new Error('generic-filehandle failed to fetch');\n        }\n        if (response.status !== 200) {\n            throw Object.assign(new Error(`HTTP ${response.status} fetching ${this.url}`), {\n                status: response.status,\n            });\n        }\n        if (encoding === 'utf8') {\n            return response.text();\n        }\n        if (encoding) {\n            throw new Error(`unsupported encoding: ${encoding}`);\n        }\n        return this.getBufferFromResponse(response);\n    }\n    async stat() {\n        if (!this._stat) {\n            const buf = Buffer.allocUnsafe(10);\n            await this.read(buf, 0, 10, 0);\n            if (!this._stat) {\n                throw new Error(`unable to determine size of file at ${this.url}`);\n            }\n        }\n        return this._stat;\n    }\n    async close() {\n        return;\n    }\n}\n","'use strict';\n\nclass QuickLRU {\n\tconstructor(options = {}) {\n\t\tif (!(options.maxSize && options.maxSize > 0)) {\n\t\t\tthrow new TypeError('`maxSize` must be a number greater than 0');\n\t\t}\n\n\t\tthis.maxSize = options.maxSize;\n\t\tthis.cache = new Map();\n\t\tthis.oldCache = new Map();\n\t\tthis._size = 0;\n\t}\n\n\t_set(key, value) {\n\t\tthis.cache.set(key, value);\n\t\tthis._size++;\n\n\t\tif (this._size >= this.maxSize) {\n\t\t\tthis._size = 0;\n\t\t\tthis.oldCache = this.cache;\n\t\t\tthis.cache = new Map();\n\t\t}\n\t}\n\n\tget(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\treturn this.cache.get(key);\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\tconst value = this.oldCache.get(key);\n\t\t\tthis.oldCache.delete(key);\n\t\t\tthis._set(key, value);\n\t\t\treturn value;\n\t\t}\n\t}\n\n\tset(key, value) {\n\t\tif (this.cache.has(key)) {\n\t\t\tthis.cache.set(key, value);\n\t\t} else {\n\t\t\tthis._set(key, value);\n\t\t}\n\n\t\treturn this;\n\t}\n\n\thas(key) {\n\t\treturn this.cache.has(key) || this.oldCache.has(key);\n\t}\n\n\tpeek(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\treturn this.cache.get(key);\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\treturn this.oldCache.get(key);\n\t\t}\n\t}\n\n\tdelete(key) {\n\t\tconst deleted = this.cache.delete(key);\n\t\tif (deleted) {\n\t\t\tthis._size--;\n\t\t}\n\n\t\treturn this.oldCache.delete(key) || deleted;\n\t}\n\n\tclear() {\n\t\tthis.cache.clear();\n\t\tthis.oldCache.clear();\n\t\tthis._size = 0;\n\t}\n\n\t* keys() {\n\t\tfor (const [key] of this) {\n\t\t\tyield key;\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const [, value] of this) {\n\t\t\tyield value;\n\t\t}\n\t}\n\n\t* [Symbol.iterator]() {\n\t\tfor (const item of this.cache) {\n\t\t\tyield item;\n\t\t}\n\n\t\tfor (const item of this.oldCache) {\n\t\t\tconst [key] = item;\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\tyield item;\n\t\t\t}\n\t\t}\n\t}\n\n\tget size() {\n\t\tlet oldCacheSize = 0;\n\t\tfor (const key of this.oldCache.keys()) {\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\toldCacheSize++;\n\t\t\t}\n\t\t}\n\n\t\treturn this._size + oldCacheSize;\n\t}\n}\n\nmodule.exports = QuickLRU;\n","class Context {\n    constructor(importPath, useContextVariables) {\n        this.code = \"\";\n        this.scopes = [[\"vars\"]];\n        this.bitFields = [];\n        this.tmpVariableCount = 0;\n        this.references = new Map();\n        this.imports = [];\n        this.reverseImports = new Map();\n        this.useContextVariables = false;\n        this.importPath = importPath;\n        this.useContextVariables = useContextVariables;\n    }\n    generateVariable(name) {\n        const scopes = [...this.scopes[this.scopes.length - 1]];\n        if (name) {\n            scopes.push(name);\n        }\n        return scopes.join(\".\");\n    }\n    generateOption(val) {\n        switch (typeof val) {\n            case \"number\":\n                return val.toString();\n            case \"string\":\n                return this.generateVariable(val);\n            case \"function\":\n                return `${this.addImport(val)}.call(${this.generateVariable()}, vars)`;\n        }\n    }\n    generateError(err) {\n        this.pushCode(`throw new Error(${err});`);\n    }\n    generateTmpVariable() {\n        return \"$tmp\" + this.tmpVariableCount++;\n    }\n    pushCode(code) {\n        this.code += code + \"\\n\";\n    }\n    pushPath(name) {\n        if (name) {\n            this.scopes[this.scopes.length - 1].push(name);\n        }\n    }\n    popPath(name) {\n        if (name) {\n            this.scopes[this.scopes.length - 1].pop();\n        }\n    }\n    pushScope(name) {\n        this.scopes.push([name]);\n    }\n    popScope() {\n        this.scopes.pop();\n    }\n    addImport(im) {\n        if (!this.importPath)\n            return `(${im})`;\n        let id = this.reverseImports.get(im);\n        if (!id) {\n            id = this.imports.push(im) - 1;\n            this.reverseImports.set(im, id);\n        }\n        return `${this.importPath}[${id}]`;\n    }\n    addReference(alias) {\n        if (!this.references.has(alias)) {\n            this.references.set(alias, { resolved: false, requested: false });\n        }\n    }\n    markResolved(alias) {\n        const reference = this.references.get(alias);\n        if (reference) {\n            reference.resolved = true;\n        }\n    }\n    markRequested(aliasList) {\n        aliasList.forEach((alias) => {\n            const reference = this.references.get(alias);\n            if (reference) {\n                reference.requested = true;\n            }\n        });\n    }\n    getUnresolvedReferences() {\n        return Array.from(this.references)\n            .filter(([_, reference]) => !reference.resolved && !reference.requested)\n            .map(([alias, _]) => alias);\n    }\n}\nconst aliasRegistry = new Map();\nconst FUNCTION_PREFIX = \"___parser_\";\nconst PRIMITIVE_SIZES = {\n    uint8: 1,\n    uint16le: 2,\n    uint16be: 2,\n    uint32le: 4,\n    uint32be: 4,\n    int8: 1,\n    int16le: 2,\n    int16be: 2,\n    int32le: 4,\n    int32be: 4,\n    int64be: 8,\n    int64le: 8,\n    uint64be: 8,\n    uint64le: 8,\n    floatle: 4,\n    floatbe: 4,\n    doublele: 8,\n    doublebe: 8,\n};\nconst PRIMITIVE_NAMES = {\n    uint8: \"Uint8\",\n    uint16le: \"Uint16\",\n    uint16be: \"Uint16\",\n    uint32le: \"Uint32\",\n    uint32be: \"Uint32\",\n    int8: \"Int8\",\n    int16le: \"Int16\",\n    int16be: \"Int16\",\n    int32le: \"Int32\",\n    int32be: \"Int32\",\n    int64be: \"BigInt64\",\n    int64le: \"BigInt64\",\n    uint64be: \"BigUint64\",\n    uint64le: \"BigUint64\",\n    floatle: \"Float32\",\n    floatbe: \"Float32\",\n    doublele: \"Float64\",\n    doublebe: \"Float64\",\n};\nconst PRIMITIVE_LITTLE_ENDIANS = {\n    uint8: false,\n    uint16le: true,\n    uint16be: false,\n    uint32le: true,\n    uint32be: false,\n    int8: false,\n    int16le: true,\n    int16be: false,\n    int32le: true,\n    int32be: false,\n    int64be: false,\n    int64le: true,\n    uint64be: false,\n    uint64le: true,\n    floatle: true,\n    floatbe: false,\n    doublele: true,\n    doublebe: false,\n};\nexport class Parser {\n    constructor() {\n        this.varName = \"\";\n        this.type = \"\";\n        this.options = {};\n        this.endian = \"be\";\n        this.useContextVariables = false;\n    }\n    static start() {\n        return new Parser();\n    }\n    primitiveGenerateN(type, ctx) {\n        const typeName = PRIMITIVE_NAMES[type];\n        const littleEndian = PRIMITIVE_LITTLE_ENDIANS[type];\n        ctx.pushCode(`${ctx.generateVariable(this.varName)} = dataView.get${typeName}(offset, ${littleEndian});`);\n        ctx.pushCode(`offset += ${PRIMITIVE_SIZES[type]};`);\n    }\n    primitiveN(type, varName, options) {\n        return this.setNextParser(type, varName, options);\n    }\n    useThisEndian(type) {\n        return (type + this.endian.toLowerCase());\n    }\n    uint8(varName, options = {}) {\n        return this.primitiveN(\"uint8\", varName, options);\n    }\n    uint16(varName, options = {}) {\n        return this.primitiveN(this.useThisEndian(\"uint16\"), varName, options);\n    }\n    uint16le(varName, options = {}) {\n        return this.primitiveN(\"uint16le\", varName, options);\n    }\n    uint16be(varName, options = {}) {\n        return this.primitiveN(\"uint16be\", varName, options);\n    }\n    uint32(varName, options = {}) {\n        return this.primitiveN(this.useThisEndian(\"uint32\"), varName, options);\n    }\n    uint32le(varName, options = {}) {\n        return this.primitiveN(\"uint32le\", varName, options);\n    }\n    uint32be(varName, options = {}) {\n        return this.primitiveN(\"uint32be\", varName, options);\n    }\n    int8(varName, options = {}) {\n        return this.primitiveN(\"int8\", varName, options);\n    }\n    int16(varName, options = {}) {\n        return this.primitiveN(this.useThisEndian(\"int16\"), varName, options);\n    }\n    int16le(varName, options = {}) {\n        return this.primitiveN(\"int16le\", varName, options);\n    }\n    int16be(varName, options = {}) {\n        return this.primitiveN(\"int16be\", varName, options);\n    }\n    int32(varName, options = {}) {\n        return this.primitiveN(this.useThisEndian(\"int32\"), varName, options);\n    }\n    int32le(varName, options = {}) {\n        return this.primitiveN(\"int32le\", varName, options);\n    }\n    int32be(varName, options = {}) {\n        return this.primitiveN(\"int32be\", varName, options);\n    }\n    bigIntVersionCheck() {\n        if (!DataView.prototype.getBigInt64)\n            throw new Error(\"BigInt64 is unsupported on this runtime\");\n    }\n    int64(varName, options = {}) {\n        this.bigIntVersionCheck();\n        return this.primitiveN(this.useThisEndian(\"int64\"), varName, options);\n    }\n    int64be(varName, options = {}) {\n        this.bigIntVersionCheck();\n        return this.primitiveN(\"int64be\", varName, options);\n    }\n    int64le(varName, options = {}) {\n        this.bigIntVersionCheck();\n        return this.primitiveN(\"int64le\", varName, options);\n    }\n    uint64(varName, options = {}) {\n        this.bigIntVersionCheck();\n        return this.primitiveN(this.useThisEndian(\"uint64\"), varName, options);\n    }\n    uint64be(varName, options = {}) {\n        this.bigIntVersionCheck();\n        return this.primitiveN(\"uint64be\", varName, options);\n    }\n    uint64le(varName, options = {}) {\n        this.bigIntVersionCheck();\n        return this.primitiveN(\"uint64le\", varName, options);\n    }\n    floatle(varName, options = {}) {\n        return this.primitiveN(\"floatle\", varName, options);\n    }\n    floatbe(varName, options = {}) {\n        return this.primitiveN(\"floatbe\", varName, options);\n    }\n    doublele(varName, options = {}) {\n        return this.primitiveN(\"doublele\", varName, options);\n    }\n    doublebe(varName, options = {}) {\n        return this.primitiveN(\"doublebe\", varName, options);\n    }\n    bitN(size, varName, options) {\n        options.length = size;\n        return this.setNextParser(\"bit\", varName, options);\n    }\n    bit1(varName, options = {}) {\n        return this.bitN(1, varName, options);\n    }\n    bit2(varName, options = {}) {\n        return this.bitN(2, varName, options);\n    }\n    bit3(varName, options = {}) {\n        return this.bitN(3, varName, options);\n    }\n    bit4(varName, options = {}) {\n        return this.bitN(4, varName, options);\n    }\n    bit5(varName, options = {}) {\n        return this.bitN(5, varName, options);\n    }\n    bit6(varName, options = {}) {\n        return this.bitN(6, varName, options);\n    }\n    bit7(varName, options = {}) {\n        return this.bitN(7, varName, options);\n    }\n    bit8(varName, options = {}) {\n        return this.bitN(8, varName, options);\n    }\n    bit9(varName, options = {}) {\n        return this.bitN(9, varName, options);\n    }\n    bit10(varName, options = {}) {\n        return this.bitN(10, varName, options);\n    }\n    bit11(varName, options = {}) {\n        return this.bitN(11, varName, options);\n    }\n    bit12(varName, options = {}) {\n        return this.bitN(12, varName, options);\n    }\n    bit13(varName, options = {}) {\n        return this.bitN(13, varName, options);\n    }\n    bit14(varName, options = {}) {\n        return this.bitN(14, varName, options);\n    }\n    bit15(varName, options = {}) {\n        return this.bitN(15, varName, options);\n    }\n    bit16(varName, options = {}) {\n        return this.bitN(16, varName, options);\n    }\n    bit17(varName, options = {}) {\n        return this.bitN(17, varName, options);\n    }\n    bit18(varName, options = {}) {\n        return this.bitN(18, varName, options);\n    }\n    bit19(varName, options = {}) {\n        return this.bitN(19, varName, options);\n    }\n    bit20(varName, options = {}) {\n        return this.bitN(20, varName, options);\n    }\n    bit21(varName, options = {}) {\n        return this.bitN(21, varName, options);\n    }\n    bit22(varName, options = {}) {\n        return this.bitN(22, varName, options);\n    }\n    bit23(varName, options = {}) {\n        return this.bitN(23, varName, options);\n    }\n    bit24(varName, options = {}) {\n        return this.bitN(24, varName, options);\n    }\n    bit25(varName, options = {}) {\n        return this.bitN(25, varName, options);\n    }\n    bit26(varName, options = {}) {\n        return this.bitN(26, varName, options);\n    }\n    bit27(varName, options = {}) {\n        return this.bitN(27, varName, options);\n    }\n    bit28(varName, options = {}) {\n        return this.bitN(28, varName, options);\n    }\n    bit29(varName, options = {}) {\n        return this.bitN(29, varName, options);\n    }\n    bit30(varName, options = {}) {\n        return this.bitN(30, varName, options);\n    }\n    bit31(varName, options = {}) {\n        return this.bitN(31, varName, options);\n    }\n    bit32(varName, options = {}) {\n        return this.bitN(32, varName, options);\n    }\n    namely(alias) {\n        aliasRegistry.set(alias, this);\n        this.alias = alias;\n        return this;\n    }\n    skip(length, options = {}) {\n        return this.seek(length, options);\n    }\n    seek(relOffset, options = {}) {\n        if (options.assert) {\n            throw new Error(\"assert option on seek is not allowed.\");\n        }\n        return this.setNextParser(\"seek\", \"\", { length: relOffset });\n    }\n    string(varName, options) {\n        if (!options.zeroTerminated && !options.length && !options.greedy) {\n            throw new Error(\"One of length, zeroTerminated, or greedy must be defined for string.\");\n        }\n        if ((options.zeroTerminated || options.length) && options.greedy) {\n            throw new Error(\"greedy is mutually exclusive with length and zeroTerminated for string.\");\n        }\n        if (options.stripNull && !(options.length || options.greedy)) {\n            throw new Error(\"length or greedy must be defined if stripNull is enabled.\");\n        }\n        options.encoding = options.encoding || \"utf8\";\n        return this.setNextParser(\"string\", varName, options);\n    }\n    buffer(varName, options) {\n        if (!options.length && !options.readUntil) {\n            throw new Error(\"length or readUntil must be defined for buffer.\");\n        }\n        return this.setNextParser(\"buffer\", varName, options);\n    }\n    wrapped(varName, options) {\n        if (!options.length && !options.readUntil) {\n            throw new Error(\"length or readUntil must be defined for wrapped.\");\n        }\n        if (!options.wrapper || !options.type) {\n            throw new Error(\"Both wrapper and type must be defined for wrapped.\");\n        }\n        return this.setNextParser(\"wrapper\", varName, options);\n    }\n    array(varName, options) {\n        if (!options.readUntil && !options.length && !options.lengthInBytes) {\n            throw new Error(\"One of readUntil, length and lengthInBytes must be defined for array.\");\n        }\n        if (!options.type) {\n            throw new Error(\"type is required for array.\");\n        }\n        if (typeof options.type === \"string\" &&\n            !aliasRegistry.has(options.type) &&\n            !(options.type in PRIMITIVE_SIZES)) {\n            throw new Error(`Array element type \"${options.type}\" is unkown.`);\n        }\n        return this.setNextParser(\"array\", varName, options);\n    }\n    choice(varName, options) {\n        if (typeof options !== \"object\" && typeof varName === \"object\") {\n            options = varName;\n            varName = \"\";\n        }\n        if (!options) {\n            throw new Error(\"tag and choices are are required for choice.\");\n        }\n        if (!options.tag) {\n            throw new Error(\"tag is requird for choice.\");\n        }\n        if (!options.choices) {\n            throw new Error(\"choices is required for choice.\");\n        }\n        for (const keyString in options.choices) {\n            const key = parseInt(keyString, 10);\n            const value = options.choices[key];\n            if (isNaN(key)) {\n                throw new Error(`Choice key \"${keyString}\" is not a number.`);\n            }\n            if (typeof value === \"string\" &&\n                !aliasRegistry.has(value) &&\n                !(value in PRIMITIVE_SIZES)) {\n                throw new Error(`Choice type \"${value}\" is unkown.`);\n            }\n        }\n        return this.setNextParser(\"choice\", varName, options);\n    }\n    nest(varName, options) {\n        if (typeof options !== \"object\" && typeof varName === \"object\") {\n            options = varName;\n            varName = \"\";\n        }\n        if (!options || !options.type) {\n            throw new Error(\"type is required for nest.\");\n        }\n        if (!(options.type instanceof Parser) && !aliasRegistry.has(options.type)) {\n            throw new Error(\"type must be a known parser name or a Parser object.\");\n        }\n        if (!(options.type instanceof Parser) && !varName) {\n            throw new Error(\"type must be a Parser object if the variable name is omitted.\");\n        }\n        return this.setNextParser(\"nest\", varName, options || {});\n    }\n    pointer(varName, options) {\n        if (!options.offset) {\n            throw new Error(\"offset is required for pointer.\");\n        }\n        if (!options.type) {\n            throw new Error(\"type is required for pointer.\");\n        }\n        if (typeof options.type === \"string\" &&\n            !(options.type in PRIMITIVE_SIZES) &&\n            !aliasRegistry.has(options.type)) {\n            throw new Error(`Pointer type \"${options.type}\" is unkown.`);\n        }\n        return this.setNextParser(\"pointer\", varName, options);\n    }\n    saveOffset(varName, options = {}) {\n        return this.setNextParser(\"saveOffset\", varName, options);\n    }\n    endianness(endianness) {\n        switch (endianness.toLowerCase()) {\n            case \"little\":\n                this.endian = \"le\";\n                break;\n            case \"big\":\n                this.endian = \"be\";\n                break;\n            default:\n                throw new Error('endianness must be one of \"little\" or \"big\"');\n        }\n        return this;\n    }\n    endianess(endianess) {\n        return this.endianness(endianess);\n    }\n    useContextVars(useContextVariables = true) {\n        this.useContextVariables = useContextVariables;\n        return this;\n    }\n    create(constructorFn) {\n        if (!(constructorFn instanceof Function)) {\n            throw new Error(\"Constructor must be a Function object.\");\n        }\n        this.constructorFn = constructorFn;\n        return this;\n    }\n    getContext(importPath) {\n        const ctx = new Context(importPath, this.useContextVariables);\n        ctx.pushCode(\"var dataView = new DataView(buffer.buffer, buffer.byteOffset, buffer.length);\");\n        if (!this.alias) {\n            this.addRawCode(ctx);\n        }\n        else {\n            this.addAliasedCode(ctx);\n            ctx.pushCode(`return ${FUNCTION_PREFIX + this.alias}(0).result;`);\n        }\n        return ctx;\n    }\n    getCode() {\n        const importPath = \"imports\";\n        return this.getContext(importPath).code;\n    }\n    addRawCode(ctx) {\n        ctx.pushCode(\"var offset = 0;\");\n        ctx.pushCode(`var vars = ${this.constructorFn ? \"new constructorFn()\" : \"{}\"};`);\n        ctx.pushCode(\"vars.$parent = null;\");\n        ctx.pushCode(\"vars.$root = vars;\");\n        this.generate(ctx);\n        this.resolveReferences(ctx);\n        ctx.pushCode(\"delete vars.$parent;\");\n        ctx.pushCode(\"delete vars.$root;\");\n        ctx.pushCode(\"return vars;\");\n    }\n    addAliasedCode(ctx) {\n        ctx.pushCode(`function ${FUNCTION_PREFIX + this.alias}(offset, context) {`);\n        ctx.pushCode(`var vars = ${this.constructorFn ? \"new constructorFn()\" : \"{}\"};`);\n        ctx.pushCode(\"var ctx = Object.assign({$parent: null, $root: vars}, context || {});\");\n        ctx.pushCode(`vars = Object.assign(vars, ctx);`);\n        this.generate(ctx);\n        ctx.markResolved(this.alias);\n        this.resolveReferences(ctx);\n        ctx.pushCode(\"Object.keys(ctx).forEach(function (item) { delete vars[item]; });\");\n        ctx.pushCode(\"return { offset: offset, result: vars };\");\n        ctx.pushCode(\"}\");\n        return ctx;\n    }\n    resolveReferences(ctx) {\n        const references = ctx.getUnresolvedReferences();\n        ctx.markRequested(references);\n        references.forEach((alias) => {\n            var _a;\n            (_a = aliasRegistry.get(alias)) === null || _a === void 0 ? void 0 : _a.addAliasedCode(ctx);\n        });\n    }\n    compile() {\n        const importPath = \"imports\";\n        const ctx = this.getContext(importPath);\n        this.compiled = new Function(importPath, \"TextDecoder\", `return function (buffer, constructorFn) { ${ctx.code} };`)(ctx.imports, TextDecoder);\n    }\n    sizeOf() {\n        let size = NaN;\n        if (Object.keys(PRIMITIVE_SIZES).indexOf(this.type) >= 0) {\n            size = PRIMITIVE_SIZES[this.type];\n            // if this is a fixed length string\n        }\n        else if (this.type === \"string\" &&\n            typeof this.options.length === \"number\") {\n            size = this.options.length;\n            // if this is a fixed length buffer\n        }\n        else if (this.type === \"buffer\" &&\n            typeof this.options.length === \"number\") {\n            size = this.options.length;\n            // if this is a fixed length array\n        }\n        else if (this.type === \"array\" &&\n            typeof this.options.length === \"number\") {\n            let elementSize = NaN;\n            if (typeof this.options.type === \"string\") {\n                elementSize = PRIMITIVE_SIZES[this.options.type];\n            }\n            else if (this.options.type instanceof Parser) {\n                elementSize = this.options.type.sizeOf();\n            }\n            size = this.options.length * elementSize;\n            // if this a skip\n        }\n        else if (this.type === \"seek\") {\n            size = this.options.length;\n            // if this is a nested parser\n        }\n        else if (this.type === \"nest\") {\n            size = this.options.type.sizeOf();\n        }\n        else if (!this.type) {\n            size = 0;\n        }\n        if (this.next) {\n            size += this.next.sizeOf();\n        }\n        return size;\n    }\n    // Follow the parser chain till the root and start parsing from there\n    parse(buffer) {\n        if (!this.compiled) {\n            this.compile();\n        }\n        return this.compiled(buffer, this.constructorFn);\n    }\n    setNextParser(type, varName, options) {\n        const parser = new Parser();\n        parser.type = type;\n        parser.varName = varName;\n        parser.options = options;\n        parser.endian = this.endian;\n        if (this.head) {\n            this.head.next = parser;\n        }\n        else {\n            this.next = parser;\n        }\n        this.head = parser;\n        return this;\n    }\n    // Call code generator for this parser\n    generate(ctx) {\n        if (this.type) {\n            switch (this.type) {\n                case \"uint8\":\n                case \"uint16le\":\n                case \"uint16be\":\n                case \"uint32le\":\n                case \"uint32be\":\n                case \"int8\":\n                case \"int16le\":\n                case \"int16be\":\n                case \"int32le\":\n                case \"int32be\":\n                case \"int64be\":\n                case \"int64le\":\n                case \"uint64be\":\n                case \"uint64le\":\n                case \"floatle\":\n                case \"floatbe\":\n                case \"doublele\":\n                case \"doublebe\":\n                    this.primitiveGenerateN(this.type, ctx);\n                    break;\n                case \"bit\":\n                    this.generateBit(ctx);\n                    break;\n                case \"string\":\n                    this.generateString(ctx);\n                    break;\n                case \"buffer\":\n                    this.generateBuffer(ctx);\n                    break;\n                case \"seek\":\n                    this.generateSeek(ctx);\n                    break;\n                case \"nest\":\n                    this.generateNest(ctx);\n                    break;\n                case \"array\":\n                    this.generateArray(ctx);\n                    break;\n                case \"choice\":\n                    this.generateChoice(ctx);\n                    break;\n                case \"pointer\":\n                    this.generatePointer(ctx);\n                    break;\n                case \"saveOffset\":\n                    this.generateSaveOffset(ctx);\n                    break;\n                case \"wrapper\":\n                    this.generateWrapper(ctx);\n                    break;\n            }\n            if (this.type !== \"bit\")\n                this.generateAssert(ctx);\n        }\n        const varName = ctx.generateVariable(this.varName);\n        if (this.options.formatter && this.type !== \"bit\") {\n            this.generateFormatter(ctx, varName, this.options.formatter);\n        }\n        return this.generateNext(ctx);\n    }\n    generateAssert(ctx) {\n        if (!this.options.assert) {\n            return;\n        }\n        const varName = ctx.generateVariable(this.varName);\n        switch (typeof this.options.assert) {\n            case \"function\":\n                {\n                    const func = ctx.addImport(this.options.assert);\n                    ctx.pushCode(`if (!${func}.call(vars, ${varName})) {`);\n                }\n                break;\n            case \"number\":\n                ctx.pushCode(`if (${this.options.assert} !== ${varName}) {`);\n                break;\n            case \"string\":\n                ctx.pushCode(`if (${JSON.stringify(this.options.assert)} !== ${varName}) {`);\n                break;\n            default:\n                throw new Error(\"assert option must be a string, number or a function.\");\n        }\n        ctx.generateError(`\"Assertion error: ${varName} is \" + ${JSON.stringify(this.options.assert.toString())}`);\n        ctx.pushCode(\"}\");\n    }\n    // Recursively call code generators and append results\n    generateNext(ctx) {\n        if (this.next) {\n            ctx = this.next.generate(ctx);\n        }\n        return ctx;\n    }\n    generateBit(ctx) {\n        // TODO find better method to handle nested bit fields\n        const parser = JSON.parse(JSON.stringify(this));\n        parser.options = this.options;\n        parser.generateAssert = this.generateAssert.bind(this);\n        parser.generateFormatter = this.generateFormatter.bind(this);\n        parser.varName = ctx.generateVariable(parser.varName);\n        ctx.bitFields.push(parser);\n        if (!this.next ||\n            (this.next && [\"bit\", \"nest\"].indexOf(this.next.type) < 0)) {\n            const val = ctx.generateTmpVariable();\n            ctx.pushCode(`var ${val} = 0;`);\n            const getMaxBits = (from = 0) => {\n                let sum = 0;\n                for (let i = from; i < ctx.bitFields.length; i++) {\n                    const length = ctx.bitFields[i].options.length;\n                    if (sum + length > 32)\n                        break;\n                    sum += length;\n                }\n                return sum;\n            };\n            const getBytes = (sum) => {\n                if (sum <= 8) {\n                    ctx.pushCode(`${val} = dataView.getUint8(offset);`);\n                    sum = 8;\n                }\n                else if (sum <= 16) {\n                    ctx.pushCode(`${val} = dataView.getUint16(offset);`);\n                    sum = 16;\n                }\n                else if (sum <= 24) {\n                    ctx.pushCode(`${val} = (dataView.getUint16(offset) << 8) | dataView.getUint8(offset + 2);`);\n                    sum = 24;\n                }\n                else {\n                    ctx.pushCode(`${val} = dataView.getUint32(offset);`);\n                    sum = 32;\n                }\n                ctx.pushCode(`offset += ${sum / 8};`);\n                return sum;\n            };\n            let bitOffset = 0;\n            const isBigEndian = this.endian === \"be\";\n            let sum = 0;\n            let rem = 0;\n            ctx.bitFields.forEach((parser, i) => {\n                let length = parser.options.length;\n                if (length > rem) {\n                    if (rem) {\n                        const mask = -1 >>> (32 - rem);\n                        ctx.pushCode(`${parser.varName} = (${val} & 0x${mask.toString(16)}) << ${length - rem};`);\n                        length -= rem;\n                    }\n                    bitOffset = 0;\n                    rem = sum = getBytes(getMaxBits(i) - rem);\n                }\n                const offset = isBigEndian ? sum - bitOffset - length : bitOffset;\n                const mask = -1 >>> (32 - length);\n                ctx.pushCode(`${parser.varName} ${length < parser.options.length ? \"|=\" : \"=\"} ${val} >> ${offset} & 0x${mask.toString(16)};`);\n                // Ensure value is unsigned\n                if (parser.options.length === 32) {\n                    ctx.pushCode(`${parser.varName} >>>= 0`);\n                }\n                if (parser.options.assert) {\n                    parser.generateAssert(ctx);\n                }\n                if (parser.options.formatter) {\n                    parser.generateFormatter(ctx, parser.varName, parser.options.formatter);\n                }\n                bitOffset += length;\n                rem -= length;\n            });\n            ctx.bitFields = [];\n        }\n    }\n    generateSeek(ctx) {\n        const length = ctx.generateOption(this.options.length);\n        ctx.pushCode(`offset += ${length};`);\n    }\n    generateString(ctx) {\n        const name = ctx.generateVariable(this.varName);\n        const start = ctx.generateTmpVariable();\n        const encoding = this.options.encoding;\n        const isHex = encoding.toLowerCase() === \"hex\";\n        const toHex = 'b => b.toString(16).padStart(2, \"0\")';\n        if (this.options.length && this.options.zeroTerminated) {\n            const len = this.options.length;\n            ctx.pushCode(`var ${start} = offset;`);\n            ctx.pushCode(`while(dataView.getUint8(offset++) !== 0 && offset - ${start} < ${len});`);\n            const end = `offset - ${start} < ${len} ? offset - 1 : offset`;\n            ctx.pushCode(isHex\n                ? `${name} = Array.from(buffer.subarray(${start}, ${end}), ${toHex}).join('');`\n                : `${name} = new TextDecoder('${encoding}').decode(buffer.subarray(${start}, ${end}));`);\n        }\n        else if (this.options.length) {\n            const len = ctx.generateOption(this.options.length);\n            ctx.pushCode(isHex\n                ? `${name} = Array.from(buffer.subarray(offset, offset + ${len}), ${toHex}).join('');`\n                : `${name} = new TextDecoder('${encoding}').decode(buffer.subarray(offset, offset + ${len}));`);\n            ctx.pushCode(`offset += ${len};`);\n        }\n        else if (this.options.zeroTerminated) {\n            ctx.pushCode(`var ${start} = offset;`);\n            ctx.pushCode(\"while(dataView.getUint8(offset++) !== 0);\");\n            ctx.pushCode(isHex\n                ? `${name} = Array.from(buffer.subarray(${start}, offset - 1), ${toHex}).join('');`\n                : `${name} = new TextDecoder('${encoding}').decode(buffer.subarray(${start}, offset - 1));`);\n        }\n        else if (this.options.greedy) {\n            ctx.pushCode(`var ${start} = offset;`);\n            ctx.pushCode(\"while(buffer.length > offset++);\");\n            ctx.pushCode(isHex\n                ? `${name} = Array.from(buffer.subarray(${start}, offset), ${toHex}).join('');`\n                : `${name} = new TextDecoder('${encoding}').decode(buffer.subarray(${start}, offset));`);\n        }\n        if (this.options.stripNull) {\n            ctx.pushCode(`${name} = ${name}.replace(/\\\\x00+$/g, '')`);\n        }\n    }\n    generateBuffer(ctx) {\n        const varName = ctx.generateVariable(this.varName);\n        if (typeof this.options.readUntil === \"function\") {\n            const pred = this.options.readUntil;\n            const start = ctx.generateTmpVariable();\n            const cur = ctx.generateTmpVariable();\n            ctx.pushCode(`var ${start} = offset;`);\n            ctx.pushCode(`var ${cur} = 0;`);\n            ctx.pushCode(`while (offset < buffer.length) {`);\n            ctx.pushCode(`${cur} = dataView.getUint8(offset);`);\n            const func = ctx.addImport(pred);\n            ctx.pushCode(`if (${func}.call(${ctx.generateVariable()}, ${cur}, buffer.subarray(offset))) break;`);\n            ctx.pushCode(`offset += 1;`);\n            ctx.pushCode(`}`);\n            ctx.pushCode(`${varName} = buffer.subarray(${start}, offset);`);\n        }\n        else if (this.options.readUntil === \"eof\") {\n            ctx.pushCode(`${varName} = buffer.subarray(offset);`);\n        }\n        else {\n            const len = ctx.generateOption(this.options.length);\n            ctx.pushCode(`${varName} = buffer.subarray(offset, offset + ${len});`);\n            ctx.pushCode(`offset += ${len};`);\n        }\n        if (this.options.clone) {\n            ctx.pushCode(`${varName} = buffer.constructor.from(${varName});`);\n        }\n    }\n    generateArray(ctx) {\n        const length = ctx.generateOption(this.options.length);\n        const lengthInBytes = ctx.generateOption(this.options.lengthInBytes);\n        const type = this.options.type;\n        const counter = ctx.generateTmpVariable();\n        const lhs = ctx.generateVariable(this.varName);\n        const item = ctx.generateTmpVariable();\n        const key = this.options.key;\n        const isHash = typeof key === \"string\";\n        if (isHash) {\n            ctx.pushCode(`${lhs} = {};`);\n        }\n        else {\n            ctx.pushCode(`${lhs} = [];`);\n        }\n        if (typeof this.options.readUntil === \"function\") {\n            ctx.pushCode(\"do {\");\n        }\n        else if (this.options.readUntil === \"eof\") {\n            ctx.pushCode(`for (var ${counter} = 0; offset < buffer.length; ${counter}++) {`);\n        }\n        else if (lengthInBytes !== undefined) {\n            ctx.pushCode(`for (var ${counter} = offset + ${lengthInBytes}; offset < ${counter}; ) {`);\n        }\n        else {\n            ctx.pushCode(`for (var ${counter} = ${length}; ${counter} > 0; ${counter}--) {`);\n        }\n        if (typeof type === \"string\") {\n            if (!aliasRegistry.get(type)) {\n                const typeName = PRIMITIVE_NAMES[type];\n                const littleEndian = PRIMITIVE_LITTLE_ENDIANS[type];\n                ctx.pushCode(`var ${item} = dataView.get${typeName}(offset, ${littleEndian});`);\n                ctx.pushCode(`offset += ${PRIMITIVE_SIZES[type]};`);\n            }\n            else {\n                const tempVar = ctx.generateTmpVariable();\n                ctx.pushCode(`var ${tempVar} = ${FUNCTION_PREFIX + type}(offset, {`);\n                if (ctx.useContextVariables) {\n                    const parentVar = ctx.generateVariable();\n                    ctx.pushCode(`$parent: ${parentVar},`);\n                    ctx.pushCode(`$root: ${parentVar}.$root,`);\n                    if (!this.options.readUntil && lengthInBytes === undefined) {\n                        ctx.pushCode(`$index: ${length} - ${counter},`);\n                    }\n                }\n                ctx.pushCode(`});`);\n                ctx.pushCode(`var ${item} = ${tempVar}.result; offset = ${tempVar}.offset;`);\n                if (type !== this.alias)\n                    ctx.addReference(type);\n            }\n        }\n        else if (type instanceof Parser) {\n            ctx.pushCode(`var ${item} = {};`);\n            const parentVar = ctx.generateVariable();\n            ctx.pushScope(item);\n            if (ctx.useContextVariables) {\n                ctx.pushCode(`${item}.$parent = ${parentVar};`);\n                ctx.pushCode(`${item}.$root = ${parentVar}.$root;`);\n                if (!this.options.readUntil && lengthInBytes === undefined) {\n                    ctx.pushCode(`${item}.$index = ${length} - ${counter};`);\n                }\n            }\n            type.generate(ctx);\n            if (ctx.useContextVariables) {\n                ctx.pushCode(`delete ${item}.$parent;`);\n                ctx.pushCode(`delete ${item}.$root;`);\n                ctx.pushCode(`delete ${item}.$index;`);\n            }\n            ctx.popScope();\n        }\n        if (isHash) {\n            ctx.pushCode(`${lhs}[${item}.${key}] = ${item};`);\n        }\n        else {\n            ctx.pushCode(`${lhs}.push(${item});`);\n        }\n        ctx.pushCode(\"}\");\n        if (typeof this.options.readUntil === \"function\") {\n            const pred = this.options.readUntil;\n            const func = ctx.addImport(pred);\n            ctx.pushCode(`while (!${func}.call(${ctx.generateVariable()}, ${item}, buffer.subarray(offset)));`);\n        }\n    }\n    generateChoiceCase(ctx, varName, type) {\n        if (typeof type === \"string\") {\n            const varName = ctx.generateVariable(this.varName);\n            if (!aliasRegistry.has(type)) {\n                const typeName = PRIMITIVE_NAMES[type];\n                const littleEndian = PRIMITIVE_LITTLE_ENDIANS[type];\n                ctx.pushCode(`${varName} = dataView.get${typeName}(offset, ${littleEndian});`);\n                ctx.pushCode(`offset += ${PRIMITIVE_SIZES[type]}`);\n            }\n            else {\n                const tempVar = ctx.generateTmpVariable();\n                ctx.pushCode(`var ${tempVar} = ${FUNCTION_PREFIX + type}(offset, {`);\n                if (ctx.useContextVariables) {\n                    ctx.pushCode(`$parent: ${varName}.$parent,`);\n                    ctx.pushCode(`$root: ${varName}.$root,`);\n                }\n                ctx.pushCode(`});`);\n                ctx.pushCode(`${varName} = ${tempVar}.result; offset = ${tempVar}.offset;`);\n                if (type !== this.alias)\n                    ctx.addReference(type);\n            }\n        }\n        else if (type instanceof Parser) {\n            ctx.pushPath(varName);\n            type.generate(ctx);\n            ctx.popPath(varName);\n        }\n    }\n    generateChoice(ctx) {\n        const tag = ctx.generateOption(this.options.tag);\n        const nestVar = ctx.generateVariable(this.varName);\n        if (this.varName) {\n            ctx.pushCode(`${nestVar} = {};`);\n            if (ctx.useContextVariables) {\n                const parentVar = ctx.generateVariable();\n                ctx.pushCode(`${nestVar}.$parent = ${parentVar};`);\n                ctx.pushCode(`${nestVar}.$root = ${parentVar}.$root;`);\n            }\n        }\n        ctx.pushCode(`switch(${tag}) {`);\n        for (const tagString in this.options.choices) {\n            const tag = parseInt(tagString, 10);\n            const type = this.options.choices[tag];\n            ctx.pushCode(`case ${tag}:`);\n            this.generateChoiceCase(ctx, this.varName, type);\n            ctx.pushCode(\"break;\");\n        }\n        ctx.pushCode(\"default:\");\n        if (this.options.defaultChoice) {\n            this.generateChoiceCase(ctx, this.varName, this.options.defaultChoice);\n        }\n        else {\n            ctx.generateError(`\"Met undefined tag value \" + ${tag} + \" at choice\"`);\n        }\n        ctx.pushCode(\"}\");\n        if (this.varName && ctx.useContextVariables) {\n            ctx.pushCode(`delete ${nestVar}.$parent;`);\n            ctx.pushCode(`delete ${nestVar}.$root;`);\n        }\n    }\n    generateNest(ctx) {\n        const nestVar = ctx.generateVariable(this.varName);\n        if (this.options.type instanceof Parser) {\n            if (this.varName) {\n                ctx.pushCode(`${nestVar} = {};`);\n                if (ctx.useContextVariables) {\n                    const parentVar = ctx.generateVariable();\n                    ctx.pushCode(`${nestVar}.$parent = ${parentVar};`);\n                    ctx.pushCode(`${nestVar}.$root = ${parentVar}.$root;`);\n                }\n            }\n            ctx.pushPath(this.varName);\n            this.options.type.generate(ctx);\n            ctx.popPath(this.varName);\n            if (this.varName && ctx.useContextVariables) {\n                if (ctx.useContextVariables) {\n                    ctx.pushCode(`delete ${nestVar}.$parent;`);\n                    ctx.pushCode(`delete ${nestVar}.$root;`);\n                }\n            }\n        }\n        else if (aliasRegistry.has(this.options.type)) {\n            const tempVar = ctx.generateTmpVariable();\n            ctx.pushCode(`var ${tempVar} = ${FUNCTION_PREFIX + this.options.type}(offset, {`);\n            if (ctx.useContextVariables) {\n                const parentVar = ctx.generateVariable();\n                ctx.pushCode(`$parent: ${parentVar},`);\n                ctx.pushCode(`$root: ${parentVar}.$root,`);\n            }\n            ctx.pushCode(`});`);\n            ctx.pushCode(`${nestVar} = ${tempVar}.result; offset = ${tempVar}.offset;`);\n            if (this.options.type !== this.alias) {\n                ctx.addReference(this.options.type);\n            }\n        }\n    }\n    generateWrapper(ctx) {\n        const wrapperVar = ctx.generateVariable(this.varName);\n        const wrappedBuf = ctx.generateTmpVariable();\n        if (typeof this.options.readUntil === \"function\") {\n            const pred = this.options.readUntil;\n            const start = ctx.generateTmpVariable();\n            const cur = ctx.generateTmpVariable();\n            ctx.pushCode(`var ${start} = offset;`);\n            ctx.pushCode(`var ${cur} = 0;`);\n            ctx.pushCode(`while (offset < buffer.length) {`);\n            ctx.pushCode(`${cur} = dataView.getUint8(offset);`);\n            const func = ctx.addImport(pred);\n            ctx.pushCode(`if (${func}.call(${ctx.generateVariable()}, ${cur}, buffer.subarray(offset))) break;`);\n            ctx.pushCode(`offset += 1;`);\n            ctx.pushCode(`}`);\n            ctx.pushCode(`${wrappedBuf} = buffer.subarray(${start}, offset);`);\n        }\n        else if (this.options.readUntil === \"eof\") {\n            ctx.pushCode(`${wrappedBuf} = buffer.subarray(offset);`);\n        }\n        else {\n            const len = ctx.generateOption(this.options.length);\n            ctx.pushCode(`${wrappedBuf} = buffer.subarray(offset, offset + ${len});`);\n            ctx.pushCode(`offset += ${len};`);\n        }\n        if (this.options.clone) {\n            ctx.pushCode(`${wrappedBuf} = buffer.constructor.from(${wrappedBuf});`);\n        }\n        const tempBuf = ctx.generateTmpVariable();\n        const tempOff = ctx.generateTmpVariable();\n        const tempView = ctx.generateTmpVariable();\n        const func = ctx.addImport(this.options.wrapper);\n        ctx.pushCode(`${wrappedBuf} = ${func}.call(this, ${wrappedBuf}).subarray(0);`);\n        ctx.pushCode(`var ${tempBuf} = buffer;`);\n        ctx.pushCode(`var ${tempOff} = offset;`);\n        ctx.pushCode(`var ${tempView} = dataView;`);\n        ctx.pushCode(`buffer = ${wrappedBuf};`);\n        ctx.pushCode(`offset = 0;`);\n        ctx.pushCode(`dataView = new DataView(buffer.buffer, buffer.byteOffset, buffer.length);`);\n        if (this.options.type instanceof Parser) {\n            if (this.varName) {\n                ctx.pushCode(`${wrapperVar} = {};`);\n            }\n            ctx.pushPath(this.varName);\n            this.options.type.generate(ctx);\n            ctx.popPath(this.varName);\n        }\n        else if (aliasRegistry.has(this.options.type)) {\n            const tempVar = ctx.generateTmpVariable();\n            ctx.pushCode(`var ${tempVar} = ${FUNCTION_PREFIX + this.options.type}(0);`);\n            ctx.pushCode(`${wrapperVar} = ${tempVar}.result;`);\n            if (this.options.type !== this.alias) {\n                ctx.addReference(this.options.type);\n            }\n        }\n        ctx.pushCode(`buffer = ${tempBuf};`);\n        ctx.pushCode(`dataView = ${tempView};`);\n        ctx.pushCode(`offset = ${tempOff};`);\n    }\n    generateFormatter(ctx, varName, formatter) {\n        if (typeof formatter === \"function\") {\n            const func = ctx.addImport(formatter);\n            ctx.pushCode(`${varName} = ${func}.call(${ctx.generateVariable()}, ${varName});`);\n        }\n    }\n    generatePointer(ctx) {\n        const type = this.options.type;\n        const offset = ctx.generateOption(this.options.offset);\n        const tempVar = ctx.generateTmpVariable();\n        const nestVar = ctx.generateVariable(this.varName);\n        // Save current offset\n        ctx.pushCode(`var ${tempVar} = offset;`);\n        // Move offset\n        ctx.pushCode(`offset = ${offset};`);\n        if (this.options.type instanceof Parser) {\n            ctx.pushCode(`${nestVar} = {};`);\n            if (ctx.useContextVariables) {\n                const parentVar = ctx.generateVariable();\n                ctx.pushCode(`${nestVar}.$parent = ${parentVar};`);\n                ctx.pushCode(`${nestVar}.$root = ${parentVar}.$root;`);\n            }\n            ctx.pushPath(this.varName);\n            this.options.type.generate(ctx);\n            ctx.popPath(this.varName);\n            if (ctx.useContextVariables) {\n                ctx.pushCode(`delete ${nestVar}.$parent;`);\n                ctx.pushCode(`delete ${nestVar}.$root;`);\n            }\n        }\n        else if (aliasRegistry.has(this.options.type)) {\n            const tempVar = ctx.generateTmpVariable();\n            ctx.pushCode(`var ${tempVar} = ${FUNCTION_PREFIX + this.options.type}(offset, {`);\n            if (ctx.useContextVariables) {\n                const parentVar = ctx.generateVariable();\n                ctx.pushCode(`$parent: ${parentVar},`);\n                ctx.pushCode(`$root: ${parentVar}.$root,`);\n            }\n            ctx.pushCode(`});`);\n            ctx.pushCode(`${nestVar} = ${tempVar}.result; offset = ${tempVar}.offset;`);\n            if (this.options.type !== this.alias) {\n                ctx.addReference(this.options.type);\n            }\n        }\n        else if (Object.keys(PRIMITIVE_SIZES).indexOf(this.options.type) >= 0) {\n            const typeName = PRIMITIVE_NAMES[type];\n            const littleEndian = PRIMITIVE_LITTLE_ENDIANS[type];\n            ctx.pushCode(`${nestVar} = dataView.get${typeName}(offset, ${littleEndian});`);\n            ctx.pushCode(`offset += ${PRIMITIVE_SIZES[type]};`);\n        }\n        // Restore offset\n        ctx.pushCode(`offset = ${tempVar};`);\n    }\n    generateSaveOffset(ctx) {\n        const varName = ctx.generateVariable(this.varName);\n        ctx.pushCode(`${varName} = offset`);\n    }\n}\n//# sourceMappingURL=binary_parser.js.map"],"names":[],"sourceRoot":""}
{"version":3,"file":"vendors-node_modules_jbrowse_plugin-legacy-jbrowse_esm_NCListAdapter_NCListAdapter_js.bundle.js","mappings":";;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,6BAA6B;AACzC,YAAY,4BAA4B;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,mCAAmC;AAC/C,YAAY,mCAAmC;AAC/C;AACA,YAAY,6BAA6B;AACzC,YAAY,6BAA6B;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,OAAO;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ,sBAAsB,gBAAgB;AACtC,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,qBAAqB;AAC9C;AACA,4BAA4B,mCAAmC;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,QAAQ,QAAQ,iBAAiB,IAAI,sBAAsB,MAAM;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,uCAAuC;AACvC;AACA,gDAAgD,SAAS;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,+DAAe,SAAS,EAAC;AACzB;;AAEA;;AAEA;;AAEA,+DAA+D;AAC/D;AACA;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACtQA;AAC0B;AACO;AAC2B;AACvB;AACU;AACV;AACH;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB;AACA,uDAAuD,OAAO;AAC9D,WAAW,UAAU;AACrB;AACe;AACf,kBAAkB,gDAAgD;AAClE;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA,iCAAiC,gEAAqB;AACtD,uBAAuB,kDAAQ,GAAG,oBAAoB;AACtD;AACA,SAAS;AACT;AACA;AACA,mBAAmB,+CAAa,GAAG,yBAAyB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,wCAAe,gDAAgD,aAAa;AAChG;AACA,eAAe,+CAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,gCAAgC,6DAAS;AACzC;AACA;AACA,gBAAgB,aAAa;AAC7B;AACA,4BAA4B,4BAA4B;AACxD,mDAAmD,mDAAS,GAAG,4DAA4D;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,iBAAiB,QAAQ;AACzB,aAAa,8BAA8B;AAC3C;AACA,sCAAsC,4CAA4C;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,kCAAkC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,eAAe;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,eAAe,QAAQ;AACvB,gBAAgB;AAChB;AACA,yBAAyB,qBAAqB;AAC9C;AACA;AACA;AACA;AACA,+CAA+C;AAC/C;AACA;AACA;AACA;AACA;AACA,4DAA4D,QAAQ,GAAG,SAAS;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,GAAG,GAAG,EAAE;AAC1D,SAAS;AACT;AACA;AACA;AACA;;;;;;;;;;;;AC5MA;AAC0C;AAC1C,+DAAe,sDAAW,EAAC;AAC3B;;;;;;;;;;;;;;;;;;;;ACHA;AAC0B;AACO;AAC2B;AAC1B;AAClC;AACA;AACA;AACA;AACA;AACe;AACf,kBAAkB,2DAA2D;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,gEAAqB;AACnD,uBAAuB,kDAAQ,GAAG,oBAAoB;AACtD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,oBAAoB;AACzD;AACA;AACA,wBAAwB,2BAA2B;AACnD;AACA;AACA;AACA;AACA;AACA,8CAA8C,OAAO;AACrD;AACA,kBAAkB,wCAAe;AACjC;AACA,2BAA2B,+CAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,eAAe;AAChD;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACxEA;AAC0B;AACO;AAC2B;AAC1B;AACnB;AACf,kBAAkB,2BAA2B;AAC7C;AACA,8BAA8B,gEAAqB;AACnD,uBAAuB,kDAAQ,GAAG,oBAAoB;AACtD;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,wCAAe,+CAA+C,OAAO;AACzF,eAAe,+CAAQ,uBAAuB,oBAAoB;AAClE;AACA;AACA;AACA;AACA;AACA,8DAA8D,8DAA8D;AAC5H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,4BAA4B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,gBAAgB;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACjHA;AACO,mDAAmD;AAC1D,YAAY,sBAAsB;AAClC;AACA;AACA,oCAAoC,kBAAkB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;;;;;;;;;;AChBa;;AAEb;AACA,yBAAyB;AACzB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;AClHuC;AAC2C;AACvB;AACL;AACN;AACa;AACjB;AAC7B,4BAA4B,2FAAsB;AACjE;AACA;AACA,yBAAyB,2EAAc;AACvC,gCAAgC,2EAAc;AAC9C;AACA,0BAA0B,oDAAW;AACrC;AACA;AACA,mCAAmC,0DAAU;AAC7C;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC,eAAe,yEAAgB;AAC/B,oBAAoB,SAAS;AAC7B;AACA,gBAAgB,oEAAgB;AAChC;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,mBAAmB,sDAAa,0BAA0B,QAAQ,GAAG,eAAe;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;AC7DA,mBAAmB;AACnB,mBAAmB;AACnB;AACA;AACA;AACe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA,yDAAyD,UAAU,GAAG,EAAE;AACxE;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;;;;;;;;;;;;;;;AC7EgC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,6BAA6B,+CAAW;AACxC;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,SAAS;AAC9D;AACA;AACA,eAAe,+CAAW;AAC1B;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC5FU;;;;;;;;;;;;;;;;;;;;;;;;ACA0B;AACE;AACJ;AACL;AAC7B,kCAAkC;AAClC,eAAe,mDAAU;AACzB;AACA,6DAA6D;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mDAAS;AAC5B;AACA;AACA;AAC0D;;;;;;;;;;;;;;;;ACnB1B;AAChC;AACA;AACA;AACA;AACA,YAAY;AACG;AACf,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,+CAAW;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,EAAE;AACrB;AACA;AACA;AACA;AACA,+DAA+D,OAAO;AACtE;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE;AAClE,gBAAgB,YAAY,2BAA2B;AACvD;AACA,qCAAqC,SAAS,GAAG,kBAAkB;AACnE;AACA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,iBAAiB,EAAE,qBAAqB,EAAE,SAAS;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA,qBAAqB;AACrB;AACA;AACA,+BAA+B,UAAU;AACzC;AACA;AACA,gCAAgC,iBAAiB,WAAW,SAAS;AACrE;AACA,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,YAAY,2BAA2B;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,iBAAiB,WAAW,SAAS;AACvF;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,qDAAqD,SAAS;AAC9D;AACA;AACA;AACA;AACA;AACA,wBAAwB,sDAAkB;AAC1C;AACA;AACA,uEAAuE,SAAS;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://taxonium/./node_modules/@gmod/nclist/esm/array_representation.js","webpack://taxonium/./node_modules/@gmod/nclist/esm/feature_store.js","webpack://taxonium/./node_modules/@gmod/nclist/esm/index.js","webpack://taxonium/./node_modules/@gmod/nclist/esm/lazy_array.js","webpack://taxonium/./node_modules/@gmod/nclist/esm/nclist.js","webpack://taxonium/./node_modules/@gmod/nclist/esm/util.js","webpack://taxonium/./node_modules/@gmod/nclist/node_modules/quick-lru/index.js","webpack://taxonium/./node_modules/@jbrowse/plugin-legacy-jbrowse/esm/NCListAdapter/NCListAdapter.js","webpack://taxonium/./node_modules/@jbrowse/plugin-legacy-jbrowse/esm/NCListAdapter/NCListFeature.js","webpack://taxonium/./node_modules/@jbrowse/plugin-legacy-jbrowse/node_modules/generic-filehandle/esm/blobFile.js","webpack://taxonium/./node_modules/@jbrowse/plugin-legacy-jbrowse/node_modules/generic-filehandle/esm/filehandle.js","webpack://taxonium/./node_modules/@jbrowse/plugin-legacy-jbrowse/node_modules/generic-filehandle/esm/index.js","webpack://taxonium/./node_modules/@jbrowse/plugin-legacy-jbrowse/node_modules/generic-filehandle/esm/remoteFile.js"],"sourcesContent":["//@ts-nocheck\n/**\n * @class ArrayRepr\n *\n * Class for operating on indexed array representations of objects.\n *\n * For example, if we have a lot of objects with similar attrbutes, e.g.:\n *\n * <pre class=\"code\">\n *     [\n *         {start: 1, end: 2, strand: -1},\n *         {start: 5, end: 6, strand: 1},\n *         ...\n *     ]\n * </pre>\n *\n * @description\n * we can represent them more compactly (e.g., in JSON) something like this:\n *\n * <pre class=\"code\">\n *     class = [\"start\", \"end\", \"strand\"]\n *     [\n *         [1, 2, -1],\n *         [5, 6, 1],\n *         ...\n *     ]\n * </pre>\n *\n * If we want to represent a few different kinds of objects in our big list,\n * we can have multiple \"class\" arrays, and tag each object to identify\n * which \"class\" array describes it.\n *\n * For example, if we have a lot of instances of a few types of objects,\n * like this:\n *\n * <pre class=\"code\">\n *     [\n *         {start: 1, end: 2, strand: 1, id: 1},\n *         {start: 5, end: 6, strand: 1, id: 2},\n *         ...\n *         {start: 10, end: 20, chunk: 1},\n *         {start: 30, end: 40, chunk: 2},\n *         ...\n *     ]\n * </pre>\n *\n * We could use the first array position to indicate the \"class\" for the\n * object, like this:\n *\n * <pre class=\"code\">\n *     classes = [[\"start\", \"end\", \"strand\", \"id\"], [\"start\", \"end\", \"chunk\"]]\n *     [\n *         [0, 1, 2, 1, 1],\n *         [0, 5, 6, 1, 2],\n *         ...\n *         [1, 10, 20, 1],\n *         [1, 30, 40, 1]\n *     ]\n * </pre>\n *\n * Also, if we occasionally want to add an ad-hoc attribute, we could just\n * stick an optional dictionary onto the end:\n *\n * <pre class=\"code\">\n *     classes = [[\"start\", \"end\", \"strand\", \"id\"], [\"start\", \"end\", \"chunk\"]]\n *     [\n *         [0, 1, 2, 1, 1],\n *         [0, 5, 6, 1, 2, {foo: 1}]\n *     ]\n * </pre>\n *\n * Given that individual objects are being represented by arrays, generic\n * code needs some way to differentiate arrays that are meant to be objects\n * from arrays that are actually meant to be arrays.\n * So for each class, we include a dict with <attribute name>: true mappings\n * for each attribute that is meant to be an array.\n *\n * Also, in cases where some attribute values are the same for all objects\n * in a particular set, it may be convenient to define a \"prototype\"\n * with default values for all objects in the set\n *\n * In the end, we get something like this:\n *\n * <pre class=\"code\">\n *     classes=[\n *         {'attributes': ['Start', 'End', 'Subfeatures'],\n *          'proto': {'Chrom': 'chr1'},\n *          'isArrayAttr': {Subfeatures: true}}\n *         ]\n * </pre>\n *\n * That's what this class facilitates.\n */\nclass ArrayRepr {\n    constructor(classes) {\n        this.classes = classes;\n        this.fields = [];\n        for (let cl = 0; cl < classes.length; cl += 1) {\n            this.fields[cl] = {};\n            for (let f = 0; f < classes[cl].attributes.length; f += 1) {\n                this.fields[cl][classes[cl].attributes[f]] = f + 1;\n            }\n            if (classes[cl].proto === undefined) {\n                classes[cl].proto = {};\n            }\n            if (classes[cl].isArrayAttr === undefined) {\n                classes[cl].isArrayAttr = {};\n            }\n        }\n    }\n    /**\n     * @private\n     */\n    attrIndices(attr) {\n        return this.classes.map(x => x.attributes.indexOf(attr) + 1 ||\n            x.attributes.indexOf(attr.toLowerCase()) + 1 ||\n            undefined);\n    }\n    get(obj, attr) {\n        if (attr in this.fields[obj[0]]) {\n            return obj[this.fields[obj[0]][attr]];\n        }\n        // try lowercase\n        const lcattr = attr.toLowerCase();\n        if (lcattr in this.fields[obj[0]]) {\n            return obj[this.fields[obj[0]][lcattr]];\n        }\n        const adhocIndex = this.classes[obj[0]].attributes.length + 1;\n        if (adhocIndex >= obj.length || !(attr in obj[adhocIndex])) {\n            if (attr in this.classes[obj[0]].proto) {\n                return this.classes[obj[0]].proto[attr];\n            }\n            return undefined;\n        }\n        return obj[adhocIndex][attr];\n    }\n    makeSetter(attr) {\n        return (obj, val) => {\n            this.set(obj, attr, val);\n        };\n    }\n    makeGetter(attr) {\n        return obj => {\n            return this.get(obj, attr);\n        };\n    }\n    makeFastGetter(attr) {\n        // can be used only if attr is guaranteed to be in\n        // the \"classes\" array for this object\n        const indices = this.attrIndices(attr);\n        return function get(obj) {\n            if (indices[obj[0]] !== undefined) {\n                return obj[indices[obj[0]]];\n            }\n            return undefined;\n        };\n    }\n    // construct(self, obj, klass) {\n    //   const result = new Array(self.classes[klass].length)\n    //   Object.keys(obj).forEach(attr => {\n    //     this.set(result, attr, obj[attr])\n    //   })\n    //   return result\n    // }\n    /**\n     * Returns fast pre-compiled getter and setter functions for use with\n     * Arrays that use this representation.\n     * When the returned <code>get</code> and <code>set</code> functions are\n     * added as methods to an Array that contains data in this\n     * representation, they provide fast access by name to the data.\n     *\n     * @returns {Object} <code>{ get: function() {...}, set: function(val) {...} }</code>\n     *\n     * @example\n     * var accessors = attrs.accessors();\n     * var feature = get_feature_from_someplace();\n     * feature.get = accessors.get;\n     * // print out the feature start and end\n     * console.log( feature.get('start') + ',' + feature.get('end') );\n     */\n    accessors() {\n        if (!this._accessors) {\n            this._accessors = this._makeAccessors();\n        }\n        return this._accessors;\n    }\n    /**\n     * @private\n     */\n    _makeAccessors() {\n        const indices = {};\n        const accessors = {\n            get(field) {\n                const f = this.get.field_accessors[field.toLowerCase()];\n                if (f) {\n                    return f.call(this);\n                }\n                return undefined;\n            },\n            set(field, val) {\n                const f = this.set.field_accessors[field];\n                if (f) {\n                    return f.call(this, val);\n                }\n                return undefined;\n            },\n            tags() {\n                return tags[this[0]] || [];\n            },\n        };\n        accessors.get.field_accessors = {};\n        accessors.set.field_accessors = {};\n        // make a data structure as: { attr_name: [offset,offset,offset], }\n        // that will be convenient for finding the location of the attr\n        // for a given class like: indexForAttr{attrname}[classnum]\n        this.classes.forEach((cdef, classnum) => {\n            ;\n            (cdef.attributes || []).forEach((attrname, offset) => {\n                indices[attrname] = indices[attrname] || [];\n                indices[attrname][classnum] = offset + 1;\n                attrname = attrname.toLowerCase();\n                indices[attrname] = indices[attrname] || [];\n                indices[attrname][classnum] = offset + 1;\n            });\n        });\n        // lowercase all the class attributes\n        const tags = this.classes.map(c => c.attributes);\n        // use that to make precalculated get and set accessors for each field\n        Object.keys(indices).forEach(attrname => {\n            const attrIndices = indices[attrname];\n            // get\n            accessors.get.field_accessors[attrname] = !attrIndices\n                ? function get() {\n                    return undefined;\n                }\n                : function get() {\n                    return this[attrIndices[this[0]]];\n                };\n            // // set\n            // accessors.set.field_accessors[attrname] = !attrIndices\n            //   ? () => undefined\n            //   : v => {\n            //       this[attrIndices[this[0]]] = v\n            //       return v\n            //     }\n        });\n        return accessors;\n    }\n}\nexport default ArrayRepr;\n/*\n\nCopyright (c) 2007-2010 The Evolutionary Software Foundation\n\nCreated by Mitchell Skinner <mitch_skinner@berkeley.edu>\n\nThis package and its accompanying libraries are free software; you can\nredistribute it and/or modify it under the terms of the LGPL (either\nversion 2.1, or at your option, any later version) or the Artistic\nLicense 2.0.  Refer to LICENSE for the full license text.\n\n*/\n//# sourceMappingURL=array_representation.js.map","//@ts-nocheck\nimport nodeUrl from 'url';\nimport QuickLRU from 'quick-lru';\nimport AbortablePromiseCache from 'abortable-promise-cache';\nimport GenericNCList from './nclist';\nimport ArrayRepr from './array_representation';\nimport LazyArray from './lazy_array';\nimport { readJSON } from './util';\nfunction idfunc() {\n    return this._uniqueID;\n}\nfunction parentfunc() {\n    return this._parent;\n}\nfunction childrenfunc() {\n    return this.get('subfeatures');\n}\n/**\n * Sequence feature store using nested containment\n * lists held in JSON files that are lazily read.\n *\n * @param {object} args constructor args\n * @param {string} args.baseUrl base URL for resolving relative URLs\n * @param {string} args.urlTemplate Template string for\n *  the root file of each reference sequence. The reference sequence\n *  name will be interpolated into this string where `{refseq}` appears.\n * @param {function} args.readFile function to use for reading remote from URLs.\n */\nexport default class NCListStore {\n    constructor({ baseUrl, urlTemplate, readFile, cacheSize = 10 }) {\n        this.baseUrl = baseUrl;\n        this.urlTemplates = { root: urlTemplate };\n        this.readFile = readFile;\n        if (!this.readFile) {\n            throw new Error(`must provide a \"readFile\" function argument`);\n        }\n        this.dataRootCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: cacheSize }),\n            fill: this.fetchDataRoot.bind(this),\n        });\n    }\n    makeNCList() {\n        return new GenericNCList({ readFile: this.readFile });\n    }\n    loadNCList(refData, trackInfo, listUrl) {\n        refData.nclist.importExisting(trackInfo.intervals.nclist, refData.attrs, listUrl, trackInfo.intervals.urlTemplate, trackInfo.intervals.lazyClass);\n    }\n    getDataRoot(refName) {\n        return this.dataRootCache.get(refName, refName);\n    }\n    fetchDataRoot(refName) {\n        const url = nodeUrl.resolve(this.baseUrl, this.urlTemplates.root.replace(/{\\s*refseq\\s*}/g, refName));\n        // fetch the trackdata\n        return readJSON(url, this.readFile).then(trackInfo => \n        // trackInfo = JSON.parse( trackInfo );\n        this.parseTrackInfo(trackInfo, url));\n    }\n    parseTrackInfo(trackInfo, url) {\n        const refData = {\n            nclist: this.makeNCList(),\n            stats: {\n                featureCount: trackInfo.featureCount || 0,\n            },\n        };\n        if (trackInfo.intervals) {\n            refData.attrs = new ArrayRepr(trackInfo.intervals.classes);\n            this.loadNCList(refData, trackInfo, url);\n        }\n        const { histograms } = trackInfo;\n        if (histograms && histograms.meta) {\n            for (let i = 0; i < histograms.meta.length; i += 1) {\n                histograms.meta[i].lazyArray = new LazyArray({ ...histograms.meta[i].arrayParams, readFile: this.readFile }, url);\n            }\n            refData._histograms = histograms;\n        }\n        // parse any strings in the histogram data that look like numbers\n        if (refData._histograms) {\n            Object.keys(refData._histograms).forEach(key => {\n                const entries = refData._histograms[key];\n                entries.forEach(entry => {\n                    Object.keys(entry).forEach(key2 => {\n                        if (typeof entry[key2] === 'string' &&\n                            String(Number(entry[key2])) === entry[key2]) {\n                            entry[key2] = Number(entry[key2]);\n                        }\n                    });\n                });\n            });\n        }\n        return refData;\n    }\n    async getRegionStats(query) {\n        const data = await this.getDataRoot(query.ref);\n        return data.stats;\n    }\n    /**\n     * fetch binned counts of feature coverage in the given region.\n     *\n     * @param {object} query\n     * @param {string} query.refName reference sequence name\n     * @param {number} query.start region start\n     * @param {number} query.end region end\n     * @param {number} query.numBins number of bins desired in the feature counts\n     * @param {number} query.basesPerBin number of bp desired in each feature counting bin\n     * @returns {object} as:\n     *    `{ bins: hist, stats: statEntry }`\n     */\n    async getRegionFeatureDensities({ refName, start, end, numBins, basesPerBin, }) {\n        const data = await this.getDataRoot(refName);\n        if (numBins) {\n            basesPerBin = (end - start) / numBins;\n        }\n        else if (basesPerBin) {\n            numBins = Math.ceil((end - start) / basesPerBin);\n        }\n        else {\n            throw new TypeError('numBins or basesPerBin arg required for getRegionFeatureDensities');\n        }\n        // pick the relevant entry in our pre-calculated stats\n        const stats = data._histograms.stats || [];\n        const statEntry = stats.find(entry => entry.basesPerBin >= basesPerBin);\n        // The histogramMeta array describes multiple levels of histogram detail,\n        // going from the finest (smallest number of bases per bin) to the\n        // coarsest (largest number of bases per bin).\n        // We want to use coarsest histogramMeta that's at least as fine as the\n        // one we're currently rendering.\n        // TODO: take into account that the histogramMeta chosen here might not\n        // fit neatly into the current histogram (e.g., if the current histogram\n        // is at 50,000 bases/bin, and we have server histograms at 20,000\n        // and 2,000 bases/bin, then we should choose the 2,000 histogramMeta\n        // rather than the 20,000)\n        let histogramMeta = data._histograms.meta[0];\n        for (let i = 0; i < data._histograms.meta.length; i += 1) {\n            if (basesPerBin >= data._histograms.meta[i].basesPerBin) {\n                histogramMeta = data._histograms.meta[i];\n            }\n        }\n        // number of bins in the server-supplied histogram for each current bin\n        let binRatio = basesPerBin / histogramMeta.basesPerBin;\n        // if the server-supplied histogram fits neatly into our requested\n        if (binRatio > 0.9 && Math.abs(binRatio - Math.round(binRatio)) < 0.0001) {\n            // console.log('server-supplied',query);\n            // we can use the server-supplied counts\n            const firstServerBin = Math.floor(start / histogramMeta.basesPerBin);\n            binRatio = Math.round(binRatio);\n            const histogram = [];\n            for (let bin = 0; bin < numBins; bin += 1) {\n                histogram[bin] = 0;\n            }\n            for await (const [i, val] of histogramMeta.lazyArray.range(firstServerBin, firstServerBin + binRatio * numBins - 1)) {\n                // this will count features that span the boundaries of\n                // the original histogram multiple times, so it's not\n                // perfectly quantitative.  Hopefully it's still useful, though.\n                histogram[Math.floor((i - firstServerBin) / binRatio)] += val;\n            }\n            return { bins: histogram, stats: statEntry };\n        }\n        // console.log('make own',query);\n        // make our own counts\n        const hist = await data.nclist.histogram(start, end, numBins);\n        return { bins: hist, stats: statEntry };\n    }\n    /**\n     * Fetch features in a given region. This method is an asynchronous generator\n     * yielding feature objects.\n     *\n     * @param {object} args\n     * @param {string} args.refName reference sequence name\n     * @param {number} args.start start of region. 0-based half-open.\n     * @param {number} args.end end of region. 0-based half-open.\n     * @yields {object}\n     */\n    async *getFeatures({ refName, start, end }) {\n        const data = await this.getDataRoot(refName);\n        const accessors = data.attrs && data.attrs.accessors();\n        for await (const [feature, path] of data.nclist.iterate(start, end)) {\n            // the unique ID is a stringification of the path in the\n            // NCList where the feature lives; it's unique across the\n            // top-level NCList (the top-level NCList covers a\n            // track/chromosome combination)\n            // only need to decorate a feature once\n            if (!feature.decorated) {\n                const uniqueID = path.join(',');\n                this.decorateFeature(accessors, feature, `${refName},${uniqueID}`);\n            }\n            yield feature;\n        }\n    }\n    // helper method to recursively add .get and .tags methods to a feature and its\n    // subfeatures\n    decorateFeature(accessors, feature, id, parent) {\n        feature.get = accessors.get;\n        feature.tags = accessors.tags;\n        feature._uniqueID = id;\n        feature.id = idfunc;\n        feature._parent = parent;\n        feature.parent = parentfunc;\n        feature.children = childrenfunc;\n        (feature.get('subfeatures') || []).forEach((f, i) => {\n            this.decorateFeature(accessors, f, `${id}-${i}`, feature);\n        });\n        feature.decorated = true;\n    }\n}\n//# sourceMappingURL=feature_store.js.map","//@ts-nocheck\nimport NCListStore from './feature_store';\nexport default NCListStore;\n//# sourceMappingURL=index.js.map","//@ts-nocheck\nimport nodeUrl from 'url';\nimport QuickLRU from 'quick-lru';\nimport AbortablePromiseCache from 'abortable-promise-cache';\nimport { readJSON } from './util';\n/**\n * For a JSON array that gets too large to load in one go, this class\n * helps break it up into chunks and provides an\n * async API for using the information in the array.\n */\nexport default class LazyArray {\n    constructor({ urlTemplate, chunkSize, length, cacheSize = 100, readFile }, baseUrl) {\n        this.urlTemplate = urlTemplate;\n        this.chunkSize = chunkSize;\n        this.length = length;\n        this.baseUrl = baseUrl === undefined ? '' : baseUrl;\n        this.readFile = readFile;\n        if (!readFile) {\n            throw new Error('must provide readFile callback');\n        }\n        this.chunkCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: cacheSize }),\n            fill: this.getChunk.bind(this),\n        });\n    }\n    /**\n     * call the callback on one element of the array\n     * @param i index\n     * @param callback callback, gets called with (i, value, param)\n     * @param param (optional) callback will get this as its last parameter\n     */\n    index(i, callback, param) {\n        this.range(i, i, callback, undefined, param);\n    }\n    /**\n     * async generator for the elements in the range [start,end]\n     *\n     * @param start index of first element to call the callback on\n     * @param end index of last element to call the callback on\n     */\n    async *range(start, end) {\n        start = Math.max(0, start);\n        end = Math.min(end, this.length - 1);\n        const firstChunk = Math.floor(start / this.chunkSize);\n        const lastChunk = Math.floor(end / this.chunkSize);\n        const chunkreadFiles = [];\n        for (let chunk = firstChunk; chunk <= lastChunk; chunk += 1) {\n            chunkreadFiles.push(this.chunkCache.get(chunk, chunk));\n        }\n        for (let i = 0; i < chunkreadFiles.length; i += 1) {\n            const [chunkNumber, chunkData] = await chunkreadFiles[i];\n            yield* this.filterChunkData(start, end, chunkNumber, chunkData);\n        }\n    }\n    async getChunk(chunkNumber) {\n        let url = this.urlTemplate.replace(/\\{Chunk\\}/gi, chunkNumber);\n        if (this.baseUrl) {\n            url = nodeUrl.resolve(this.baseUrl, url);\n        }\n        const data = await readJSON(url, this.readFile);\n        return [chunkNumber, data];\n    }\n    *filterChunkData(queryStart, queryEnd, chunkNumber, chunkData) {\n        // index (in the overall lazy array) of the first position in this chunk\n        const firstIndex = chunkNumber * this.chunkSize;\n        const chunkStart = Math.max(0, queryStart - firstIndex);\n        const chunkEnd = Math.min(queryEnd - firstIndex, this.chunkSize - 1);\n        for (let i = chunkStart; i <= chunkEnd; i += 1) {\n            yield [i + firstIndex, chunkData[i]];\n        }\n    }\n}\n//# sourceMappingURL=lazy_array.js.map","//@ts-nocheck\nimport nodeUrl from 'url';\nimport QuickLRU from 'quick-lru';\nimport AbortablePromiseCache from 'abortable-promise-cache';\nimport { readJSON } from './util';\nexport default class NCList {\n    constructor({ readFile, cacheSize = 100 }) {\n        this.topList = [];\n        this.chunkCache = new AbortablePromiseCache({\n            cache: new QuickLRU({ maxSize: cacheSize }),\n            fill: this.readChunkItems.bind(this),\n        });\n        this.readFile = readFile;\n        if (!this.readFile) {\n            throw new Error(`must provide a \"readFile\" function`);\n        }\n    }\n    importExisting(nclist, attrs, baseURL, lazyUrlTemplate, lazyClass) {\n        this.topList = nclist;\n        this.attrs = attrs;\n        this.start = attrs.makeFastGetter('Start');\n        this.end = attrs.makeFastGetter('End');\n        this.lazyClass = lazyClass;\n        this.baseURL = baseURL;\n        this.lazyUrlTemplate = lazyUrlTemplate;\n    }\n    binarySearch(arr, item, getter) {\n        let low = -1;\n        let high = arr.length;\n        let mid;\n        while (high - low > 1) {\n            mid = (low + high) >>> 1;\n            if (getter(arr[mid]) >= item) {\n                high = mid;\n            }\n            else {\n                low = mid;\n            }\n        }\n        // if we're iterating rightward, return the high index;\n        // if leftward, the low index\n        if (getter === this.end) {\n            return high;\n        }\n        return low;\n    }\n    readChunkItems(chunkNum) {\n        const url = nodeUrl.resolve(this.baseURL, this.lazyUrlTemplate.replace(/\\{Chunk\\}/gi, chunkNum));\n        return readJSON(url, this.readFile, { defaultContent: [] });\n    }\n    async *iterateSublist(arr, from, to, inc, searchGet, testGet, path) {\n        const getChunk = this.attrs.makeGetter('Chunk');\n        const getSublist = this.attrs.makeGetter('Sublist');\n        const pendingPromises = [];\n        for (let i = this.binarySearch(arr, from, searchGet); i < arr.length && i >= 0 && inc * testGet(arr[i]) < inc * to; i += inc) {\n            if (arr[i][0] === this.lazyClass) {\n                // this is a lazily-loaded chunk of the nclist\n                const chunkNum = getChunk(arr[i]);\n                const chunkItemsP = this.chunkCache\n                    .get(chunkNum, chunkNum)\n                    .then(item => [item, chunkNum]);\n                pendingPromises.push(chunkItemsP);\n            }\n            else {\n                // this is just a regular feature\n                yield [arr[i], path.concat(i)];\n            }\n            // if this node has a contained sublist, process that too\n            const sublist = getSublist(arr[i]);\n            if (sublist) {\n                yield* this.iterateSublist(sublist, from, to, inc, searchGet, testGet, path.concat(i));\n            }\n        }\n        for (let i = 0; i < pendingPromises.length; i += 1) {\n            const [item, chunkNum] = await pendingPromises[i];\n            if (item) {\n                yield* this.iterateSublist(item, from, to, inc, searchGet, testGet, [\n                    ...path,\n                    chunkNum,\n                ]);\n            }\n        }\n    }\n    async *iterate(from, to) {\n        // calls the given function once for each of the\n        // intervals that overlap the given interval\n        // if from <= to, iterates left-to-right, otherwise iterates right-to-left\n        // inc: iterate leftward or rightward\n        const inc = from > to ? -1 : 1;\n        // searchGet: search on start or end\n        const searchGet = from > to ? this.start : this.end;\n        // testGet: test on start or end\n        const testGet = from > to ? this.end : this.start;\n        if (this.topList.length > 0) {\n            yield* this.iterateSublist(this.topList, from, to, inc, searchGet, testGet, [0]);\n        }\n    }\n    async histogram(from, to, numBins) {\n        // calls callback with a histogram of the feature density\n        // in the given interval\n        const result = new Array(numBins);\n        result.fill(0);\n        const binWidth = (to - from) / numBins;\n        for await (const feat of this.iterate(from, to)) {\n            const firstBin = Math.max(0, ((this.start(feat) - from) / binWidth) | 0);\n            const lastBin = Math.min(numBins, ((this.end(feat) - from) / binWidth) | 0);\n            for (let bin = firstBin; bin <= lastBin; bin += 1) {\n                result[bin] += 1;\n            }\n        }\n        return result;\n    }\n}\n//# sourceMappingURL=nclist.js.map","//@ts-nocheck\nexport async function readJSON(url, readFile, options = {}) {\n    const { defaultContent = {} } = options;\n    let str;\n    try {\n        str = await readFile(url, { encoding: 'utf8' });\n        return JSON.parse(str);\n    }\n    catch (error) {\n        if (error.code === 'ENOENT' || error.status === 404) {\n            return defaultContent;\n        }\n        throw error;\n    }\n}\nexport function foo() { }\n//# sourceMappingURL=util.js.map","'use strict';\n\nclass QuickLRU {\n\tconstructor(options = {}) {\n\t\tif (!(options.maxSize && options.maxSize > 0)) {\n\t\t\tthrow new TypeError('`maxSize` must be a number greater than 0');\n\t\t}\n\n\t\tthis.maxSize = options.maxSize;\n\t\tthis.cache = new Map();\n\t\tthis.oldCache = new Map();\n\t\tthis._size = 0;\n\t}\n\n\t_set(key, value) {\n\t\tthis.cache.set(key, value);\n\t\tthis._size++;\n\n\t\tif (this._size >= this.maxSize) {\n\t\t\tthis._size = 0;\n\t\t\tthis.oldCache = this.cache;\n\t\t\tthis.cache = new Map();\n\t\t}\n\t}\n\n\tget(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\treturn this.cache.get(key);\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\tconst value = this.oldCache.get(key);\n\t\t\tthis.oldCache.delete(key);\n\t\t\tthis._set(key, value);\n\t\t\treturn value;\n\t\t}\n\t}\n\n\tset(key, value) {\n\t\tif (this.cache.has(key)) {\n\t\t\tthis.cache.set(key, value);\n\t\t} else {\n\t\t\tthis._set(key, value);\n\t\t}\n\n\t\treturn this;\n\t}\n\n\thas(key) {\n\t\treturn this.cache.has(key) || this.oldCache.has(key);\n\t}\n\n\tpeek(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\treturn this.cache.get(key);\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\treturn this.oldCache.get(key);\n\t\t}\n\t}\n\n\tdelete(key) {\n\t\tconst deleted = this.cache.delete(key);\n\t\tif (deleted) {\n\t\t\tthis._size--;\n\t\t}\n\n\t\treturn this.oldCache.delete(key) || deleted;\n\t}\n\n\tclear() {\n\t\tthis.cache.clear();\n\t\tthis.oldCache.clear();\n\t\tthis._size = 0;\n\t}\n\n\t* keys() {\n\t\tfor (const [key] of this) {\n\t\t\tyield key;\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const [, value] of this) {\n\t\t\tyield value;\n\t\t}\n\t}\n\n\t* [Symbol.iterator]() {\n\t\tfor (const item of this.cache) {\n\t\t\tyield item;\n\t\t}\n\n\t\tfor (const item of this.oldCache) {\n\t\t\tconst [key] = item;\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\tyield item;\n\t\t\t}\n\t\t}\n\t}\n\n\tget size() {\n\t\tlet oldCacheSize = 0;\n\t\tfor (const key of this.oldCache.keys()) {\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\toldCacheSize++;\n\t\t\t}\n\t\t}\n\n\t\treturn this._size + oldCacheSize;\n\t}\n}\n\nmodule.exports = QuickLRU;\n","import NCListStore from '@gmod/nclist';\nimport { BaseFeatureDataAdapter, } from '@jbrowse/core/data_adapters/BaseAdapter';\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs';\nimport { checkAbortSignal } from '@jbrowse/core/util';\nimport { RemoteFile } from 'generic-filehandle';\nimport { readConfObject } from '@jbrowse/core/configuration';\nimport NCListFeature from './NCListFeature';\nexport default class NCListAdapter extends BaseFeatureDataAdapter {\n    constructor(config, getSubAdapter, pluginManager) {\n        super(config, getSubAdapter, pluginManager);\n        const refNames = readConfObject(config, 'refNames');\n        const rootUrlTemplate = readConfObject(config, 'rootUrlTemplate');\n        this.configRefNames = refNames;\n        this.nclist = new NCListStore({\n            baseUrl: '',\n            urlTemplate: rootUrlTemplate.uri,\n            readFile: (url) => new RemoteFile(String(rootUrlTemplate.baseUri\n                ? new URL(url, rootUrlTemplate.baseUri).toString()\n                : url)).readFile(),\n        });\n    }\n    /**\n     * Fetch features for a certain region. Use getFeaturesInRegion() if you also\n     * want to verify that the store has features for the given reference sequence\n     * before fetching.\n     * @param region -\n     * @param opts - [signal] optional signalling object for aborting the fetch\n     * @returns Observable of Feature objects in the region\n     */\n    getFeatures(region, opts = {}) {\n        return ObservableCreate(async (observer) => {\n            const { signal } = opts;\n            for await (const feature of this.nclist.getFeatures(region, opts)) {\n                checkAbortSignal(signal);\n                observer.next(this.wrapFeature(feature));\n            }\n            observer.complete();\n        });\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    wrapFeature(ncFeature) {\n        return new NCListFeature(ncFeature, undefined, `${this.id}-${ncFeature.id()}`);\n    }\n    async hasDataForRefName(refName) {\n        const root = await this.nclist.getDataRoot(refName);\n        return !!(root && root.stats && root.stats.featureCount);\n    }\n    /*\n     * NCList is unable to get list of ref names so returns empty\n     * @return Promise<string[]> of empty list\n     */\n    getRefNames() {\n        return Promise.resolve(this.configRefNames || []);\n    }\n    /**\n     * called to provide a hint that data tied to a certain region\n     * will not be needed for the forseeable future and can be purged\n     * from caches, etc\n     */\n    freeResources() { }\n}\n//# sourceMappingURL=NCListAdapter.js.map","const jb2ToJb1 = { refName: 'seq_id' };\nconst jb1ToJb2 = { seq_id: 'refName' };\n/**\n * wrapper to adapt nclist features to act like jbrowse 2 features\n */\nexport default class NCListFeature {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    constructor(ncFeature, parent, id) {\n        this.ncFeature = ncFeature;\n        this.uniqueId = id || ncFeature.id();\n        this.parentHandle = parent;\n    }\n    set() {\n        throw new Error('not implemented');\n    }\n    jb2TagToJb1Tag(tag) {\n        // @ts-ignore\n        const mapped = jb2ToJb1[tag] || tag;\n        return mapped.toLowerCase();\n    }\n    jb1TagToJb2Tag(tag) {\n        const t = tag.toLowerCase();\n        // @ts-ignore\n        const mapped = jb1ToJb2[t] || t;\n        return mapped;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    get(attrName) {\n        const attr = this.ncFeature.get(this.jb2TagToJb1Tag(attrName));\n        if (attr && attrName === 'subfeatures') {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            return attr.map((subfeature) => new NCListFeature(subfeature, this));\n        }\n        return attr;\n    }\n    /**\n     * Get an array listing which data keys are present in this feature.\n     */\n    tags() {\n        return this.ncFeature.tags().map((t) => this.jb1TagToJb2Tag(t));\n    }\n    /**\n     * Get the unique ID of this feature.\n     */\n    id() {\n        return this.uniqueId;\n    }\n    /**\n     * Get this feature's parent feature, or undefined if none.\n     */\n    parent() {\n        return this.parentHandle;\n    }\n    /**\n     * Get an array of child features, or undefined if none.\n     */\n    children() {\n        return this.get('subfeatures');\n    }\n    toJSON() {\n        const data = { uniqueId: this.id() };\n        this.ncFeature.tags().forEach((tag) => {\n            const mappedTag = this.jb1TagToJb2Tag(tag);\n            const value = this.ncFeature.get(tag);\n            if (mappedTag === 'subfeatures') {\n                data.subfeatures = (value || []).map((f) => {\n                    // note: was new NCListFeature(f, `${this.id()}-${i}`, this).toJSON()\n                    return new NCListFeature(f, this).toJSON();\n                });\n            }\n            else {\n                data[mappedTag] = value;\n            }\n        });\n        return data;\n    }\n}\n//# sourceMappingURL=NCListFeature.js.map","import { Buffer } from 'buffer';\n// Using this you can \"await\" the file like a normal promise\n// https://blog.shovonhasan.com/using-promises-with-filereader/\nfunction readBlobAsArrayBuffer(blob) {\n    const fileReader = new FileReader();\n    return new Promise((resolve, reject) => {\n        fileReader.onerror = () => {\n            fileReader.abort();\n            reject(new Error('problem reading blob'));\n        };\n        fileReader.onabort = () => {\n            reject(new Error('blob reading was aborted'));\n        };\n        fileReader.onload = () => {\n            if (fileReader.result && typeof fileReader.result !== 'string') {\n                resolve(fileReader.result);\n            }\n            else {\n                reject(new Error('unknown error reading blob'));\n            }\n        };\n        fileReader.readAsArrayBuffer(blob);\n    });\n}\nfunction readBlobAsText(blob) {\n    const fileReader = new FileReader();\n    return new Promise((resolve, reject) => {\n        fileReader.onerror = () => {\n            fileReader.abort();\n            reject(new Error('problem reading blob'));\n        };\n        fileReader.onabort = () => {\n            reject(new Error('blob reading was aborted'));\n        };\n        fileReader.onload = () => {\n            if (fileReader.result && typeof fileReader.result === 'string') {\n                resolve(fileReader.result);\n            }\n            else {\n                reject(new Error('unknown error reading blob'));\n            }\n        };\n        fileReader.readAsText(blob);\n    });\n}\n/**\n * Blob of binary data fetched from a local file (with FileReader).\n *\n * Adapted by Robert Buels and Garrett Stevens from the BlobFetchable object in\n * the Dalliance Genome Explorer, which is copyright Thomas Down 2006-2011.\n */\nexport default class BlobFile {\n    constructor(blob) {\n        this.blob = blob;\n        this.size = blob.size;\n    }\n    async read(buffer, offset = 0, length, position = 0) {\n        // short-circuit a read of 0 bytes here, because browsers actually sometimes\n        // crash if you try to read 0 bytes from a local file!\n        if (!length) {\n            return { bytesRead: 0, buffer };\n        }\n        const start = position;\n        const end = start + length;\n        const result = await readBlobAsArrayBuffer(this.blob.slice(start, end));\n        const resultBuffer = Buffer.from(result);\n        const bytesCopied = resultBuffer.copy(buffer, offset);\n        return { bytesRead: bytesCopied, buffer: resultBuffer };\n    }\n    async readFile(options) {\n        let encoding;\n        if (typeof options === 'string') {\n            encoding = options;\n        }\n        else {\n            encoding = options && options.encoding;\n        }\n        if (encoding === 'utf8') {\n            return readBlobAsText(this.blob);\n        }\n        if (encoding) {\n            throw new Error(`unsupported encoding: ${encoding}`);\n        }\n        const result = await readBlobAsArrayBuffer(this.blob);\n        return Buffer.from(result);\n    }\n    async stat() {\n        return { size: this.size };\n    }\n    async close() {\n        return;\n    }\n}\n","export {};\n","import LocalFile from './localFile';\nimport RemoteFile from './remoteFile';\nimport BlobFile from './blobFile';\nexport * from './filehandle';\nfunction fromUrl(source, opts = {}) {\n    return new RemoteFile(source, opts);\n}\nfunction open(maybeUrl, maybePath, maybeFilehandle, opts = {}) {\n    if (maybeFilehandle !== undefined) {\n        return maybeFilehandle;\n    }\n    if (maybeUrl !== undefined) {\n        return fromUrl(maybeUrl, opts);\n    }\n    if (maybePath !== undefined) {\n        return new LocalFile(maybePath, opts);\n    }\n    throw new Error('no url, path, or filehandle provided, cannot open');\n}\nexport { open, fromUrl, RemoteFile, LocalFile, BlobFile };\n","import { Buffer } from 'buffer';\nconst myGlobal = typeof window !== 'undefined'\n    ? window\n    : typeof self !== 'undefined'\n        ? self\n        : { fetch: undefined };\nexport default class RemoteFile {\n    constructor(source, opts = {}) {\n        this.baseOverrides = {};\n        this.url = source;\n        const fetch = opts.fetch || (myGlobal.fetch && myGlobal.fetch.bind(myGlobal));\n        if (!fetch) {\n            throw new TypeError(`no fetch function supplied, and none found in global environment`);\n        }\n        if (opts.overrides) {\n            this.baseOverrides = opts.overrides;\n        }\n        this.fetchImplementation = fetch;\n    }\n    async getBufferFromResponse(response) {\n        if (typeof response.buffer === 'function') {\n            return response.buffer();\n        }\n        else if (typeof response.arrayBuffer === 'function') {\n            const resp = await response.arrayBuffer();\n            return Buffer.from(resp);\n        }\n        else {\n            throw new TypeError('invalid HTTP response object, has no buffer method, and no arrayBuffer method');\n        }\n    }\n    async fetch(input, init) {\n        let response;\n        try {\n            response = await this.fetchImplementation(input, init);\n        }\n        catch (e) {\n            if (`${e}`.includes('Failed to fetch')) {\n                // refetch to to help work around a chrome bug (discussed in\n                // generic-filehandle issue #72) in which the chrome cache returns a\n                // CORS error for content in its cache.  see also\n                // https://github.com/GMOD/jbrowse-components/pull/1511\n                console.warn(`generic-filehandle: refetching ${input} to attempt to work around chrome CORS header caching bug`);\n                response = await this.fetchImplementation(input, {\n                    ...init,\n                    cache: 'reload',\n                });\n            }\n            else {\n                throw e;\n            }\n        }\n        return response;\n    }\n    async read(buffer, offset = 0, length, position = 0, opts = {}) {\n        const { headers = {}, signal, overrides = {} } = opts;\n        if (length < Infinity) {\n            headers.range = `bytes=${position}-${position + length}`;\n        }\n        else if (length === Infinity && position !== 0) {\n            headers.range = `bytes=${position}-`;\n        }\n        const args = {\n            ...this.baseOverrides,\n            ...overrides,\n            headers: {\n                ...headers,\n                ...overrides.headers,\n                ...this.baseOverrides.headers,\n            },\n            method: 'GET',\n            redirect: 'follow',\n            mode: 'cors',\n            signal,\n        };\n        const response = await this.fetch(this.url, args);\n        if (!response.ok) {\n            throw new Error(`HTTP ${response.status} ${response.statusText} ${this.url}`);\n        }\n        if ((response.status === 200 && position === 0) ||\n            response.status === 206) {\n            const responseData = await this.getBufferFromResponse(response);\n            const bytesCopied = responseData.copy(buffer, offset, 0, Math.min(length, responseData.length));\n            // try to parse out the size of the remote file\n            const res = response.headers.get('content-range');\n            const sizeMatch = /\\/(\\d+)$/.exec(res || '');\n            if (sizeMatch && sizeMatch[1]) {\n                this._stat = { size: parseInt(sizeMatch[1], 10) };\n            }\n            return { bytesRead: bytesCopied, buffer };\n        }\n        if (response.status === 200) {\n            throw new Error('${this.url} fetch returned status 200, expected 206');\n        }\n        // TODO: try harder here to gather more information about what the problem is\n        throw new Error(`HTTP ${response.status} fetching ${this.url}`);\n    }\n    async readFile(options = {}) {\n        let encoding;\n        let opts;\n        if (typeof options === 'string') {\n            encoding = options;\n            opts = {};\n        }\n        else {\n            encoding = options.encoding;\n            opts = options;\n            delete opts.encoding;\n        }\n        const { headers = {}, signal, overrides = {} } = opts;\n        const args = {\n            headers,\n            method: 'GET',\n            redirect: 'follow',\n            mode: 'cors',\n            signal,\n            ...this.baseOverrides,\n            ...overrides,\n        };\n        const response = await this.fetch(this.url, args);\n        if (!response) {\n            throw new Error('generic-filehandle failed to fetch');\n        }\n        if (response.status !== 200) {\n            throw Object.assign(new Error(`HTTP ${response.status} fetching ${this.url}`), {\n                status: response.status,\n            });\n        }\n        if (encoding === 'utf8') {\n            return response.text();\n        }\n        if (encoding) {\n            throw new Error(`unsupported encoding: ${encoding}`);\n        }\n        return this.getBufferFromResponse(response);\n    }\n    async stat() {\n        if (!this._stat) {\n            const buf = Buffer.allocUnsafe(10);\n            await this.read(buf, 0, 10, 0);\n            if (!this._stat) {\n                throw new Error(`unable to determine size of file at ${this.url}`);\n            }\n        }\n        return this._stat;\n    }\n    async close() {\n        return;\n    }\n}\n"],"names":[],"sourceRoot":""}
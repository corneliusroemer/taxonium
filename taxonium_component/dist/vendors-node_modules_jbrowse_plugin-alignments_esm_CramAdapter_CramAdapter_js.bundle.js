(self["webpackChunktaxonium"] = self["webpackChunktaxonium"] || []).push([["vendors-node_modules_jbrowse_plugin-alignments_esm_CramAdapter_CramAdapter_js"],{

/***/ "./node_modules/@gmod/cram/esm/craiIndex.js":
/*!**************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/craiIndex.js ***!
  \**************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CraiIndex; }
/* harmony export */ });
/* harmony import */ var abortable_promise_cache__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! abortable-promise-cache */ "./node_modules/abortable-promise-cache/esm/index.js");
/* harmony import */ var abortable_promise_cache__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(abortable_promise_cache__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var quick_lru__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! quick-lru */ "./node_modules/quick-lru/index.js");
/* harmony import */ var quick_lru__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(quick_lru__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _unzip__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./unzip */ "./node_modules/@gmod/cram/esm/unzip-pako.js");
/* harmony import */ var _io__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./io */ "./node_modules/@gmod/cram/esm/io/index.js");
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./errors */ "./node_modules/@gmod/cram/esm/errors.js");





const BAI_MAGIC = 21578050; // BAI\1
class Slice {
    constructor(args) {
        Object.assign(this, args);
    }
    toString() {
        return `${this.start}:${this.span}:${this.containerStart}:${this.sliceStart}:${this.sliceBytes}`;
    }
}
function addRecordToIndex(index, record) {
    if (record.some(el => el === undefined)) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_4__.CramMalformedError('invalid .crai index file');
    }
    const [seqId, start, span, containerStart, sliceStart, sliceBytes] = record;
    if (!index[seqId]) {
        index[seqId] = [];
    }
    index[seqId].push(new Slice({
        start,
        span,
        containerStart,
        sliceStart,
        sliceBytes,
    }));
}
class CraiIndex {
    // A CRAM index (.crai) is a gzipped tab delimited file containing the following columns:
    // 1. Sequence id
    // 2. Alignment start
    // 3. Alignment span
    // 4. Container start byte position in the file
    // 5. Slice start byte position in the container data (‘blocks’)
    // 6. Slice size in bytes
    // Each line represents a slice in the CRAM file. Please note that all slices must be listed in index file.
    /**
     *
     * @param {object} args
     * @param {string} [args.path]
     * @param {string} [args.url]
     * @param {FileHandle} [args.filehandle]
     */
    constructor(args) {
        const filehandle = (0,_io__WEBPACK_IMPORTED_MODULE_3__.open)(args.url, args.path, args.filehandle);
        this._parseCache = new (abortable_promise_cache__WEBPACK_IMPORTED_MODULE_0___default())({
            cache: new (quick_lru__WEBPACK_IMPORTED_MODULE_1___default())({ maxSize: 1 }),
            fill: (data, signal) => this.parseIndex({ signal }),
        });
        this.readFile = filehandle.readFile.bind(filehandle);
    }
    parseIndex() {
        const index = {};
        return this.readFile()
            .then(data => {
            if (data[0] === 31 && data[1] === 139) {
                return (0,_unzip__WEBPACK_IMPORTED_MODULE_2__.unzip)(data);
            }
            return data;
        })
            .then(uncompressedBuffer => {
            if (uncompressedBuffer.length > 4 &&
                uncompressedBuffer.readUInt32LE(0) === BAI_MAGIC) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_4__.CramMalformedError('invalid .crai index file. note: file appears to be a .bai index. this is technically legal but please open a github issue if you need support');
            }
            // interpret the text as regular ascii, since it is
            // supposed to be only digits and whitespace characters
            // this is written in a deliberately low-level fashion for performance,
            // because some .crai files can be pretty large.
            let currentRecord = [];
            let currentString = '';
            for (let i = 0; i < uncompressedBuffer.length; i += 1) {
                const charCode = uncompressedBuffer[i];
                if ((charCode >= 48 && charCode <= 57) /* 0-9 */ ||
                    (!currentString && charCode === 45) /* leading - */) {
                    currentString += String.fromCharCode(charCode);
                }
                else if (charCode === 9 /* \t */) {
                    currentRecord.push(Number.parseInt(currentString, 10));
                    currentString = '';
                }
                else if (charCode === 10 /* \n */) {
                    currentRecord.push(Number.parseInt(currentString, 10));
                    currentString = '';
                    addRecordToIndex(index, currentRecord);
                    currentRecord = [];
                }
                else if (charCode !== 13 /* \r */ && charCode !== 32 /* space */) {
                    // if there are other characters in the file besides
                    // space and \r, something is wrong.
                    throw new _errors__WEBPACK_IMPORTED_MODULE_4__.CramMalformedError('invalid .crai index file');
                }
            }
            // if the file ends without a \n, we need to flush our buffers
            if (currentString) {
                currentRecord.push(Number.parseInt(currentString, 10));
            }
            if (currentRecord.length === 6) {
                addRecordToIndex(index, currentRecord);
            }
            // sort each of them by start
            Object.entries(index).forEach(([seqId, ent]) => {
                index[seqId] = ent.sort((a, b) => a.start - b.start || a.span - b.span);
            });
            return index;
        });
    }
    getIndex(opts = {}) {
        return this._parseCache.get('index', null, opts.signal);
    }
    /**
     * @param {number} seqId
     * @returns {Promise} true if the index contains entries for
     * the given reference sequence ID, false otherwise
     */
    async hasDataForReferenceSequence(seqId) {
        return !!(await this.getIndex())[seqId];
    }
    /**
     * fetch index entries for the given range
     *
     * @param {number} seqId
     * @param {number} queryStart
     * @param {number} queryEnd
     *
     * @returns {Promise} promise for
     * an array of objects of the form
     * `{start, span, containerStart, sliceStart, sliceBytes }`
     */
    async getEntriesForRange(seqId, queryStart, queryEnd) {
        const seqEntries = (await this.getIndex())[seqId];
        if (!seqEntries) {
            return [];
        }
        const compare = entry => {
            const entryStart = entry.start;
            const entryEnd = entry.start + entry.span;
            if (entryStart > queryEnd) {
                return -1;
            } // entry is ahead of query
            if (entryEnd <= queryStart) {
                return 1;
            } // entry is behind query
            return 0; // entry overlaps query
        };
        const bins = [];
        for (let i = 0; i < seqEntries.length; i += 1) {
            if (compare(seqEntries[i]) === 0) {
                bins.push(seqEntries[i]);
            }
        }
        return bins;
    }
}
//# sourceMappingURL=craiIndex.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js":
/*!**************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js ***!
  \**************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CramCodec; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");

const validDataTypes = {
    int: true,
    byte: true,
    long: true,
    byteArray: true,
    byteArrayBlock: true,
};
// codec base class
class CramCodec {
    constructor(parameters = {}, dataType) {
        this.parameters = parameters;
        this.dataType = dataType;
        if (!dataType) {
            throw new TypeError('must provide a data type to codec constructor');
        }
        if (!validDataTypes[dataType]) {
            throw new TypeError(`invalid data type ${dataType}`);
        }
    }
    // decode(slice, coreDataBlock, blocksByContentId, cursors) {
    // }
    _getBits(data, cursor, numBits) {
        let val = 0;
        if (cursor.bytePosition + (7 - cursor.bitPosition + numBits) / 8 >
            data.length) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramBufferOverrunError('read error during decoding. the file seems to be truncated.');
        }
        for (let dlen = numBits; dlen; dlen -= 1) {
            // get the next `dlen` bits in the input, put them in val
            val <<= 1;
            val |= (data[cursor.bytePosition] >> cursor.bitPosition) & 1;
            cursor.bitPosition -= 1;
            if (cursor.bitPosition < 0) {
                cursor.bytePosition += 1;
            }
            cursor.bitPosition &= 7;
        }
        return val;
    }
}
//# sourceMappingURL=_base.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/beta.js":
/*!*************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/beta.js ***!
  \*************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ BetaCodec; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_base */ "./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js");


class BetaCodec extends _base__WEBPACK_IMPORTED_MODULE_1__["default"] {
    constructor(parameters = {}, dataType) {
        super(parameters, dataType);
        if (this.dataType !== 'int') {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramUnimplementedError(`${this.dataType} decoding not yet implemented by BETA codec`);
        }
    }
    decode(slice, coreDataBlock, blocksByContentId, cursors) {
        const data = this._getBits(coreDataBlock.content, cursors.coreBlock, this.parameters.length) - this.parameters.offset;
        return data;
    }
}
//# sourceMappingURL=beta.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayLength.js":
/*!************************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayLength.js ***!
  \************************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ ByteArrayStopCodec; }
/* harmony export */ });
/* harmony import */ var _util__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util */ "./node_modules/@gmod/cram/esm/cramFile/util.js");
/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_base */ "./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js");


class ByteArrayStopCodec extends _base__WEBPACK_IMPORTED_MODULE_1__["default"] {
    constructor(parameters = {}, dataType, instantiateCodec) {
        super(parameters, dataType);
        this.instantiateCodec = instantiateCodec;
        if (dataType !== 'byteArray') {
            throw new TypeError(`byteArrayLength does not support data type ${dataType}`);
        }
    }
    decode(slice, coreDataBlock, blocksByContentId, cursors) {
        const lengthCodec = this._getLengthCodec();
        const arrayLength = lengthCodec.decode(slice, coreDataBlock, blocksByContentId, cursors);
        const dataCodec = this._getDataCodec();
        const data = new Uint8Array(arrayLength);
        for (let i = 0; i < arrayLength; i += 1) {
            data[i] = dataCodec.decode(slice, coreDataBlock, blocksByContentId, cursors);
        }
        return data;
    }
    // memoize
    _getLengthCodec() {
        const encodingParams = this.parameters.lengthsEncoding;
        return this.instantiateCodec(encodingParams, 'int');
    }
    // memoize
    _getDataCodec() {
        const encodingParams = this.parameters.valuesEncoding;
        return this.instantiateCodec(encodingParams, 'byte');
    }
}
'_getLengthCodec _getDataCodec'
    .split(' ')
    .forEach(method => (0,_util__WEBPACK_IMPORTED_MODULE_0__.tinyMemoize)(ByteArrayStopCodec, method));
//# sourceMappingURL=byteArrayLength.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayStop.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayStop.js ***!
  \**********************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ ByteArrayStopCodec; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_base */ "./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js");


class ByteArrayStopCodec extends _base__WEBPACK_IMPORTED_MODULE_1__["default"] {
    constructor(parameters = {}, dataType) {
        super(parameters, dataType);
        if (dataType === 'byteArray') {
            this._decode = this._decodeByteArray;
        }
        else {
            throw new TypeError(`byteArrayStop codec does not support data type ${dataType}`);
        }
    }
    decode(slice, coreDataBlock, blocksByContentId, cursors) {
        const { blockContentId } = this.parameters;
        const contentBlock = blocksByContentId[blockContentId];
        if (!contentBlock) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`no block found with content ID ${blockContentId}`);
        }
        const cursor = cursors.externalBlocks.getCursor(blockContentId);
        return this._decode(contentBlock, cursor);
    }
    _decodeByteArray(contentBlock, cursor) {
        const dataBuffer = contentBlock.content;
        const { stopByte } = this.parameters;
        // scan to the next stop byte
        const startPosition = cursor.bytePosition;
        let stopPosition = cursor.bytePosition;
        while (dataBuffer[stopPosition] !== stopByte &&
            stopPosition < dataBuffer.length) {
            if (stopPosition === dataBuffer.length) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramBufferOverrunError(`byteArrayStop reading beyond length of data buffer?`);
            }
            stopPosition += 1;
        }
        cursor.bytePosition = stopPosition + 1;
        return dataBuffer.slice(startPosition, stopPosition);
    }
}
//# sourceMappingURL=byteArrayStop.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/external.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/external.js ***!
  \*****************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ ExternalCodec; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_base */ "./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js");
/* harmony import */ var _util__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util */ "./node_modules/@gmod/cram/esm/cramFile/util.js");



class ExternalCodec extends _base__WEBPACK_IMPORTED_MODULE_1__["default"] {
    constructor(parameters = {}, dataType) {
        super(parameters, dataType);
        if (this.dataType === 'int') {
            this._decodeData = this._decodeInt;
        }
        else if (this.dataType === 'byte') {
            this._decodeData = this._decodeByte;
        }
        else {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramUnimplementedError(`${this.dataType} decoding not yet implemented by EXTERNAL codec`);
        }
    }
    decode(slice, coreDataBlock, blocksByContentId, cursors) {
        const { blockContentId } = this.parameters;
        const contentBlock = blocksByContentId[blockContentId];
        if (!contentBlock) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`no block found with content ID ${blockContentId}`);
        }
        const cursor = cursors.externalBlocks.getCursor(blockContentId);
        return this._decodeData(contentBlock, cursor);
    }
    _decodeInt(contentBlock, cursor) {
        const [result, bytesRead] = (0,_util__WEBPACK_IMPORTED_MODULE_2__.parseItf8)(contentBlock.content, cursor.bytePosition);
        cursor.bytePosition += bytesRead;
        return result;
    }
    _decodeByte(contentBlock, cursor) {
        if (cursor.bytePosition >= contentBlock.content.length) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramBufferOverrunError('attempted to read beyond end of block. this file seems truncated.');
        }
        return contentBlock.content[cursor.bytePosition++];
    }
}
//# sourceMappingURL=external.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/gamma.js":
/*!**************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/gamma.js ***!
  \**************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ GammaCodec; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_base */ "./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js");


class GammaCodec extends _base__WEBPACK_IMPORTED_MODULE_1__["default"] {
    constructor(parameters = {}, dataType) {
        super(parameters, dataType);
        if (this.dataType !== 'int') {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramUnimplementedError(`${this.dataType} decoding not yet implemented by GAMMA codec`);
        }
    }
    decode(slice, coreDataBlock, blocksByContentId, cursors) {
        let length = 1;
        while (this._getBits(coreDataBlock.content, cursors.coreBlock, 1) === 0) {
            length += 1;
        }
        const readBits = this._getBits(coreDataBlock.content, cursors.coreBlock, length - 1);
        const value = readBits | (1 << (length - 1));
        return value - this.parameters.offset;
    }
}
//# sourceMappingURL=gamma.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/huffman.js":
/*!****************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/huffman.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ HuffmanIntCodec; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_base */ "./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js");


function numberOfSetBits(ii) {
    let i = (ii - (ii >> 1)) & 0x55555555;
    i = (i & 0x33333333) + ((i >> 2) & 0x33333333);
    return (((i + (i >> 4)) & 0x0f0f0f0f) * 0x01010101) >> 24;
}
class HuffmanIntCodec extends _base__WEBPACK_IMPORTED_MODULE_1__["default"] {
    constructor(parameters = {}, dataType) {
        super(parameters, dataType);
        if (!['byte', 'int'].includes(this.dataType)) {
            throw new TypeError(`${this.dataType} decoding not yet implemented by HUFFMAN_INT codec`);
        }
        this.buildCodeBook();
        this.buildCodes();
        this.buildCaches();
        // if this is a degenerate zero-length huffman code, special-case the decoding
        if (this.sortedCodes[0].bitLength === 0) {
            this._decode = this._decodeZeroLengthCode;
        }
    }
    buildCodeBook() {
        // parse the parameters together into a `codes` data structure
        let codes = new Array(this.parameters.numCodes);
        for (let i = 0; i < this.parameters.numCodes; i += 1) {
            codes[i] = {
                symbol: this.parameters.symbols[i],
                bitLength: this.parameters.bitLengths[i],
            };
        }
        // sort the codes by bit length and symbol value
        codes = codes.sort((a, b) => a.bitLength - b.bitLength || a.symbol - b.symbol);
        this.codeBook = {};
        codes.forEach(code => {
            if (!this.codeBook[code.bitLength]) {
                this.codeBook[code.bitLength] = [];
            }
            this.codeBook[code.bitLength].push(code.symbol);
        });
    }
    buildCodes() {
        this.codes = {}; /*  new TreeMap<Integer, HuffmanBitCode>(); */
        let codeLength = 0;
        let codeValue = -1;
        Object.entries(this.codeBook).forEach(([bitLength, symbols]) => {
            bitLength = parseInt(bitLength, 10);
            symbols.forEach(symbol => {
                const code = { bitLength, value: symbol };
                codeValue += 1;
                const delta = bitLength - codeLength; // new length?
                codeValue <<= delta; // pad with 0's
                code.bitCode = codeValue; // calculated: huffman code
                codeLength += delta; // adjust current code length
                if (numberOfSetBits(codeValue) > bitLength) {
                    throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('Symbol out of range');
                }
                this.codes[symbol] = code;
            });
        });
    }
    buildCaches() {
        this.sortedCodes = Object.values(this.codes).sort((a, b) => a.bitLength - b.bitLength || a.bitCode - b.bitCode);
        // this.sortedValues = this.parameters.values.sort((a,b) => a-b)
        this.sortedByValue = Object.values(this.codes).sort((a, b) => a.value - b.value);
        this.sortedValuesByBitCode = this.sortedCodes.map(c => c.value);
        this.sortedBitCodes = this.sortedCodes.map(c => c.bitCode);
        this.sortedBitLengthsByBitCode = this.sortedCodes.map(c => c.bitLength);
        const maxBitCode = Math.max(...this.sortedBitCodes);
        this.bitCodeToValue = new Array(maxBitCode + 1).fill(-1);
        for (let i = 0; i < this.sortedBitCodes.length; i += 1) {
            this.bitCodeToValue[this.sortedCodes[i].bitCode] = i;
        }
    }
    decode(slice, coreDataBlock, blocksByContentId, cursors) {
        return this._decode(slice, coreDataBlock, cursors.coreBlock);
    }
    // _decodeNull() {
    //   return -1
    // }
    // the special case for zero-length codes
    _decodeZeroLengthCode() {
        return this.sortedCodes[0].value;
    }
    _decode(slice, coreDataBlock, coreCursor) {
        const input = coreDataBlock.content;
        let prevLen = 0;
        let bits = 0;
        for (let i = 0; i < this.sortedCodes.length; i += 1) {
            const length = this.sortedCodes[i].bitLength;
            bits <<= length - prevLen;
            bits |= this._getBits(input, coreCursor, length - prevLen);
            prevLen = length;
            {
                const index = this.bitCodeToValue[bits];
                if (index > -1 && this.sortedBitLengthsByBitCode[index] === length) {
                    return this.sortedValuesByBitCode[index];
                }
                for (let j = i; this.sortedCodes[j + 1].bitLength === length &&
                    j < this.sortedCodes.length; j += 1) {
                    i += 1;
                }
            }
        }
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('Huffman symbol not found.');
    }
}
//# sourceMappingURL=huffman.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/index.js":
/*!**************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/index.js ***!
  \**************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "getCodecClassWithId": function() { return /* binding */ getCodecClassWithId; },
/* harmony export */   "instantiateCodec": function() { return /* binding */ instantiateCodec; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _huffman__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./huffman */ "./node_modules/@gmod/cram/esm/cramFile/codecs/huffman.js");
/* harmony import */ var _external__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./external */ "./node_modules/@gmod/cram/esm/cramFile/codecs/external.js");
/* harmony import */ var _byteArrayStop__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./byteArrayStop */ "./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayStop.js");
/* harmony import */ var _byteArrayLength__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./byteArrayLength */ "./node_modules/@gmod/cram/esm/cramFile/codecs/byteArrayLength.js");
/* harmony import */ var _beta__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./beta */ "./node_modules/@gmod/cram/esm/cramFile/codecs/beta.js");
/* harmony import */ var _gamma__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./gamma */ "./node_modules/@gmod/cram/esm/cramFile/codecs/gamma.js");
/* harmony import */ var _subexp__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./subexp */ "./node_modules/@gmod/cram/esm/cramFile/codecs/subexp.js");








const codecClasses = {
    1: _external__WEBPACK_IMPORTED_MODULE_2__["default"],
    // 2: GolombCodec,
    3: _huffman__WEBPACK_IMPORTED_MODULE_1__["default"],
    4: _byteArrayLength__WEBPACK_IMPORTED_MODULE_4__["default"],
    5: _byteArrayStop__WEBPACK_IMPORTED_MODULE_3__["default"],
    6: _beta__WEBPACK_IMPORTED_MODULE_5__["default"],
    7: _subexp__WEBPACK_IMPORTED_MODULE_7__["default"],
    // 8: GolombRiceCodec,
    9: _gamma__WEBPACK_IMPORTED_MODULE_6__["default"],
};
function getCodecClassWithId(id) {
    return codecClasses[id];
}
function instantiateCodec(encodingData, dataType) {
    const CodecClass = getCodecClassWithId(dataType === 'ignore' ? 0 : encodingData.codecId);
    if (!CodecClass) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramUnimplementedError(`no codec implemented for codec ID ${encodingData.codecId}`);
    }
    return new CodecClass(encodingData.parameters, dataType, instantiateCodec);
}
//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/codecs/subexp.js":
/*!***************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/codecs/subexp.js ***!
  \***************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ SubexpCodec; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _base__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./_base */ "./node_modules/@gmod/cram/esm/cramFile/codecs/_base.js");


class SubexpCodec extends _base__WEBPACK_IMPORTED_MODULE_1__["default"] {
    constructor(parameters = {}, dataType) {
        super(parameters, dataType);
        if (this.dataType !== 'int') {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramUnimplementedError(`${this.dataType} decoding not yet implemented by SUBEXP codec`);
        }
    }
    decode(slice, coreDataBlock, blocksByContentId, cursors) {
        let numLeadingOnes = 0;
        while (this._getBits(coreDataBlock.content, cursors.coreBlock, 1)) {
            numLeadingOnes += 1;
        }
        let b;
        let n;
        if (numLeadingOnes === 0) {
            b = this.parameters.K;
            n = this._getBits(coreDataBlock.content, cursors.coreBlock, b);
        }
        else {
            b = numLeadingOnes + this.parameters.K - 1;
            n = (1 << b) | this._getBits(coreDataBlock.content, cursors.coreBlock, b);
        }
        return n - this.parameters.offset;
    }
}
//# sourceMappingURL=subexp.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/constants.js":
/*!***********************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/constants.js ***!
  \***********************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
const Constants = {
    CRAM_FLAG_PRESERVE_QUAL_SCORES: 1 << 0,
    CRAM_FLAG_DETACHED: 1 << 1,
    CRAM_FLAG_MATE_DOWNSTREAM: 1 << 2,
    CRAM_FLAG_NO_SEQ: 1 << 3,
    CRAM_FLAG_MASK: (1 << 4) - 1,
    // mate read is reversed
    CRAM_M_REVERSE: 1,
    // mated read is unmapped
    CRAM_M_UNMAP: 2,
    //  the read is paired in sequencing, no matter whether it is mapped in a pair
    BAM_FPAIRED: 1,
    //  the read is mapped in a proper pair
    BAM_FPROPER_PAIR: 2,
    //  the read itself is unmapped; conflictive with BAM_FPROPER_PAIR
    BAM_FUNMAP: 4,
    //  the mate is unmapped
    BAM_FMUNMAP: 8,
    //  the read is mapped to the reverse strand
    BAM_FREVERSE: 16,
    //  the mate is mapped to the reverse strand
    BAM_FMREVERSE: 32,
    //  this is read1
    BAM_FREAD1: 64,
    //  this is read2
    BAM_FREAD2: 128,
    //  not primary alignment
    BAM_FSECONDARY: 256,
    //  QC failure
    BAM_FQCFAIL: 512,
    //  optical or PCR duplicate
    BAM_FDUP: 1024,
    //  supplementary alignment
    BAM_FSUPPLEMENTARY: 2048,
    BAM_CMATCH: 0,
    BAM_CINS: 1,
    BAM_CDEL: 2,
    BAM_CREF_SKIP: 3,
    BAM_CSOFT_CLIP: 4,
    BAM_CHARD_CLIP: 5,
    BAM_CPAD: 6,
    BAM_CEQUAL: 7,
    BAM_CDIFF: 8,
    BAM_CBACK: 9,
    BAM_CIGAR_STR: 'MIDNSHP:XB',
    BAM_CIGAR_SHIFT: 4,
    BAM_CIGAR_MASK: 0xf,
    BAM_CIGAR_TYPE: 0x3c1a7,
};
/* harmony default export */ __webpack_exports__["default"] = (Constants);
//# sourceMappingURL=constants.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/container/compressionScheme.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/container/compressionScheme.js ***!
  \*****************************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CramContainerCompressionScheme; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _codecs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../codecs */ "./node_modules/@gmod/cram/esm/cramFile/codecs/index.js");


// the hardcoded data type to be decoded for each core
// data field
const dataSeriesTypes = {
    BF: 'int',
    CF: 'int',
    RI: 'int',
    RL: 'int',
    AP: 'int',
    RG: 'int',
    MF: 'int',
    NS: 'int',
    NP: 'int',
    TS: 'int',
    NF: 'int',
    TC: 'byte',
    TN: 'int',
    FN: 'int',
    FC: 'byte',
    FP: 'int',
    BS: 'byte',
    IN: 'byteArray',
    SC: 'byteArray',
    DL: 'int',
    BA: 'byte',
    BB: 'byteArray',
    RS: 'int',
    PD: 'int',
    HC: 'int',
    MQ: 'int',
    RN: 'byteArray',
    QS: 'byte',
    QQ: 'byteArray',
    TL: 'int',
    TM: 'ignore',
    TV: 'ignore',
};
function parseSubstitutionMatrix(byteArray) {
    const matrix = new Array(5);
    for (let i = 0; i < 5; i += 1) {
        matrix[i] = new Array(4);
    }
    matrix[0][(byteArray[0] >> 6) & 3] = 'C';
    matrix[0][(byteArray[0] >> 4) & 3] = 'G';
    matrix[0][(byteArray[0] >> 2) & 3] = 'T';
    matrix[0][(byteArray[0] >> 0) & 3] = 'N';
    matrix[1][(byteArray[1] >> 6) & 3] = 'A';
    matrix[1][(byteArray[1] >> 4) & 3] = 'G';
    matrix[1][(byteArray[1] >> 2) & 3] = 'T';
    matrix[1][(byteArray[1] >> 0) & 3] = 'N';
    matrix[2][(byteArray[2] >> 6) & 3] = 'A';
    matrix[2][(byteArray[2] >> 4) & 3] = 'C';
    matrix[2][(byteArray[2] >> 2) & 3] = 'T';
    matrix[2][(byteArray[2] >> 0) & 3] = 'N';
    matrix[3][(byteArray[3] >> 6) & 3] = 'A';
    matrix[3][(byteArray[3] >> 4) & 3] = 'C';
    matrix[3][(byteArray[3] >> 2) & 3] = 'G';
    matrix[3][(byteArray[3] >> 0) & 3] = 'N';
    matrix[4][(byteArray[4] >> 6) & 3] = 'A';
    matrix[4][(byteArray[4] >> 4) & 3] = 'C';
    matrix[4][(byteArray[4] >> 2) & 3] = 'G';
    matrix[4][(byteArray[4] >> 0) & 3] = 'T';
    return matrix;
}
class CramContainerCompressionScheme {
    constructor(content) {
        Object.assign(this, content);
        // interpret some of the preservation map tags for convenient use
        this.readNamesIncluded = content.preservation.RN;
        this.APdelta = content.preservation.AP;
        this.referenceRequired = !!content.preservation.RR;
        this.tagIdsDictionary = content.preservation.TD;
        this.substitutionMatrix = parseSubstitutionMatrix(content.preservation.SM);
        this.dataSeriesCodecCache = new Map();
        this.tagCodecCache = {};
    }
    /**
     * @param {string} tagName three-character tag name
     * @private
     */
    getCodecForTag(tagName) {
        if (!this.tagCodecCache[tagName]) {
            const encodingData = this.tagEncoding[tagName];
            if (encodingData) {
                this.tagCodecCache[tagName] = (0,_codecs__WEBPACK_IMPORTED_MODULE_1__.instantiateCodec)(encodingData, 'byteArray');
            }
        }
        return this.tagCodecCache[tagName];
    }
    /**
     *
     * @param {number} tagListId ID of the tag list to fetch from the tag dictionary
     * @private
     */
    getTagNames(tagListId) {
        return this.tagIdsDictionary[tagListId];
    }
    getCodecForDataSeries(dataSeriesName) {
        let r = this.dataSeriesCodecCache.get(dataSeriesName);
        if (r === undefined) {
            const encodingData = this.dataSeriesEncoding[dataSeriesName];
            if (encodingData) {
                const dataType = dataSeriesTypes[dataSeriesName];
                if (!dataType) {
                    throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`data series name ${dataSeriesName} not defined in file compression header`);
                }
                r = (0,_codecs__WEBPACK_IMPORTED_MODULE_1__.instantiateCodec)(encodingData, dataType);
                this.dataSeriesCodecCache.set(dataSeriesName, r);
            }
        }
        return r;
    }
    toJSON() {
        const data = {};
        Object.keys(this).forEach(k => {
            if (/Cache$/.test(k)) {
                return;
            }
            data[k] = this[k];
        });
        return data;
    }
}
//# sourceMappingURL=compressionScheme.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/container/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/container/index.js ***!
  \*****************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CramContainer; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _util__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util */ "./node_modules/@gmod/cram/esm/cramFile/util.js");
/* harmony import */ var _slice__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../slice */ "./node_modules/@gmod/cram/esm/cramFile/slice/index.js");
/* harmony import */ var _compressionScheme__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./compressionScheme */ "./node_modules/@gmod/cram/esm/cramFile/container/compressionScheme.js");
/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];




class CramContainer {
    constructor(cramFile, position) {
        // cram file this container comes from
        this.file = cramFile;
        // position of this container in the file
        this.filePosition = position;
        // console.log(`container: ${this.filePosition}`)
    }
    // memoize
    getHeader() {
        return this._readContainerHeader(this.filePosition);
    }
    // memoize
    async getCompressionHeaderBlock() {
        const containerHeader = await this.getHeader();
        // if there are no records in the container, there will be no compression header
        if (!containerHeader.numRecords) {
            return null;
        }
        const sectionParsers = await this.file.getSectionParsers();
        const block = await this.getFirstBlock();
        if (block.contentType !== 'COMPRESSION_HEADER') {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`invalid content type ${block.contentType} in what is supposed to be the compression header block`);
        }
        const content = (0,_util__WEBPACK_IMPORTED_MODULE_1__.parseItem)(block.content, sectionParsers.cramCompressionHeader.parser, 0, block.contentPosition);
        block.content = content;
        return block;
    }
    async getFirstBlock() {
        const containerHeader = await this.getHeader();
        return this.file.readBlock(containerHeader._endPosition);
    }
    // parses the compression header data into a CramContainerCompressionScheme object
    // memoize
    async getCompressionScheme() {
        const header = await this.getCompressionHeaderBlock();
        if (!header) {
            return undefined;
        }
        return new _compressionScheme__WEBPACK_IMPORTED_MODULE_3__["default"](header.content);
    }
    getSlice(slicePosition, sliceSize) {
        // note: slicePosition is relative to the end of the container header
        // TODO: perhaps we should cache slices?
        return new _slice__WEBPACK_IMPORTED_MODULE_2__["default"](this, slicePosition, sliceSize);
    }
    async _readContainerHeader(position) {
        const sectionParsers = await this.file.getSectionParsers();
        const { cramContainerHeader1, cramContainerHeader2 } = sectionParsers;
        const { size: fileSize } = await this.file.stat();
        if (position >= fileSize) {
            return undefined;
        }
        // parse the container header. do it in 2 pieces because you cannot tell
        // how much to buffer until you read numLandmarks
        const bytes1 = Buffer.allocUnsafe(cramContainerHeader1.maxLength);
        await this.file.read(bytes1, 0, cramContainerHeader1.maxLength, position);
        const header1 = (0,_util__WEBPACK_IMPORTED_MODULE_1__.parseItem)(bytes1, cramContainerHeader1.parser);
        const numLandmarksSize = (0,_util__WEBPACK_IMPORTED_MODULE_1__.itf8Size)(header1.numLandmarks);
        if (position + header1.length >= fileSize) {
            console.warn(`${this.file}: container header at ${position} indicates that the container has length ${header1.length}, which extends beyond the length of the file. Skipping this container.`);
            return undefined;
        }
        const bytes2 = Buffer.allocUnsafe(cramContainerHeader2.maxLength(header1.numLandmarks));
        await this.file.read(bytes2, 0, cramContainerHeader2.maxLength(header1.numLandmarks), position + header1._size - numLandmarksSize);
        const header2 = (0,_util__WEBPACK_IMPORTED_MODULE_1__.parseItem)(bytes2, cramContainerHeader2.parser);
        if (this.file.validateChecksums && header2.crc32 !== undefined) {
            await this.file.checkCrc32(position, header1._size + header2._size - numLandmarksSize - 4, header2.crc32, `container header beginning at position ${position}`);
        }
        const completeHeader = Object.assign(header1, header2, {
            _size: header1._size + header2._size - numLandmarksSize,
            _endPosition: header1._size + header2._size - numLandmarksSize + position,
        });
        return completeHeader;
    }
}
'getHeader getCompressionHeaderBlock getCompressionScheme'
    .split(' ')
    .forEach(method => (0,_util__WEBPACK_IMPORTED_MODULE_1__.tinyMemoize)(CramContainer, method));
//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/file.js":
/*!******************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/file.js ***!
  \******************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CramFile; }
/* harmony export */ });
/* harmony import */ var _unzip__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../unzip */ "./node_modules/@gmod/cram/esm/unzip-pako.js");
/* harmony import */ var buffer_crc32__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! buffer-crc32 */ "./node_modules/buffer-crc32/index.js");
/* harmony import */ var buffer_crc32__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(buffer_crc32__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var quick_lru__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! quick-lru */ "./node_modules/quick-lru/index.js");
/* harmony import */ var quick_lru__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(quick_lru__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _rans__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../rans */ "./node_modules/@gmod/cram/esm/rans/index.js");
/* harmony import */ var _sectionParsers__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./sectionParsers */ "./node_modules/@gmod/cram/esm/cramFile/sectionParsers.js");
/* harmony import */ var _jkbonfield_htscodecs__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @jkbonfield/htscodecs */ "./node_modules/@jkbonfield/htscodecs/index.js");
/* harmony import */ var _jkbonfield_htscodecs__WEBPACK_IMPORTED_MODULE_6___default = /*#__PURE__*/__webpack_require__.n(_jkbonfield_htscodecs__WEBPACK_IMPORTED_MODULE_6__);
/* harmony import */ var _container__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./container */ "./node_modules/@gmod/cram/esm/cramFile/container/index.js");
/* harmony import */ var _io__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../io */ "./node_modules/@gmod/cram/esm/io/index.js");
/* harmony import */ var _util__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./util */ "./node_modules/@gmod/cram/esm/cramFile/util.js");
/* harmony import */ var _sam__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../sam */ "./node_modules/@gmod/cram/esm/sam.js");
/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];











//source:https://abdulapopoola.com/2019/01/20/check-endianness-with-javascript/
function getEndianness() {
    let uInt32 = new Uint32Array([0x11223344]);
    let uInt8 = new Uint8Array(uInt32.buffer);
    if (uInt8[0] === 0x44) {
        return 0; //little-endian
    }
    else if (uInt8[0] === 0x11) {
        return 1; //big-endian
    }
    else {
        return 2; //mixed-endian?
    }
}
class CramFile {
    /**
     * @param {object} args
     * @param {object} [args.filehandle] - a filehandle that implements the stat() and
     * read() methods of the Node filehandle API https://nodejs.org/api/fs.html#fs_class_filehandle
     * @param {object} [args.path] - path to the cram file
     * @param {object} [args.url] - url for the cram file.  also supports file:// urls for local files
     * @param {function} [args.seqFetch] - a function with signature
     * `(seqId, startCoordinate, endCoordinate)` that returns a promise for a string of sequence bases
     * @param {number} [args.cacheSize] optional maximum number of CRAM records to cache.  default 20,000
     * @param {boolean} [args.checkSequenceMD5] - default true. if false, disables verifying the MD5
     * checksum of the reference sequence underlying a slice. In some applications, this check can cause an inconvenient amount (many megabases) of sequences to be fetched.
     */
    constructor(args) {
        this.file = (0,_io__WEBPACK_IMPORTED_MODULE_8__.open)(args.url, args.path, args.filehandle);
        this.validateChecksums = true;
        this.fetchReferenceSequenceCallback = args.seqFetch;
        this.options = {
            checkSequenceMD5: args.checkSequenceMD5 !== false,
            cacheSize: args.cacheSize !== undefined ? args.cacheSize : 20000,
        };
        // cache of features in a slice, keyed by the
        // slice offset. caches all of the features in a slice, or none.
        // the cache is actually used by the slice object, it's just
        // kept here at the level of the file
        this.featureCache = new (quick_lru__WEBPACK_IMPORTED_MODULE_2___default())({
            maxSize: this.options.cacheSize,
        });
        if (getEndianness() > 0) {
            throw new Error('Detected big-endian machine, may be unable to run');
        }
    }
    toString() {
        if (this.file.filename) {
            return this.file.filename;
        }
        if (this.file.url) {
            return this.file.url;
        }
        return '(cram file)';
    }
    // can just read this object like a filehandle
    read(buffer, offset, length, position) {
        return this.file.read(buffer, offset, length, position);
    }
    // can just stat this object like a filehandle
    stat() {
        return this.file.stat();
    }
    // memoized
    async getDefinition() {
        const headbytes = Buffer.allocUnsafe(_sectionParsers__WEBPACK_IMPORTED_MODULE_5__.cramFileDefinition.maxLength);
        await this.file.read(headbytes, 0, _sectionParsers__WEBPACK_IMPORTED_MODULE_5__.cramFileDefinition.maxLength, 0);
        const definition = _sectionParsers__WEBPACK_IMPORTED_MODULE_5__.cramFileDefinition.parser.parse(headbytes).result;
        if (definition.majorVersion !== 2 && definition.majorVersion !== 3) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_3__.CramUnimplementedError(`CRAM version ${definition.majorVersion} not supported`);
        }
        return definition;
    }
    // memoize
    async getSamHeader() {
        const firstContainer = await this.getContainerById(0);
        if (!firstContainer) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_3__.CramMalformedError('file contains no containers');
        }
        const { content } = await firstContainer.getFirstBlock();
        // find the end of the trailing zeros in the header text
        const headerLength = content.readInt32LE(0);
        const textStart = 4;
        // let textEnd = content.length - 1
        // while (textEnd >= textStart && !content[textEnd]) textEnd -= 1
        // trim off the trailing zeros
        const text = content.toString('utf8', textStart, textStart + headerLength);
        this.header = text;
        return (0,_sam__WEBPACK_IMPORTED_MODULE_10__.parseHeaderText)(text);
    }
    async getHeaderText() {
        await this.getSamHeader();
        return this.header;
    }
    // memoize
    async getSectionParsers() {
        const { majorVersion } = await this.getDefinition();
        return (0,_sectionParsers__WEBPACK_IMPORTED_MODULE_5__.getSectionParsers)(majorVersion);
    }
    async getContainerById(containerNumber) {
        const sectionParsers = await this.getSectionParsers();
        let position = sectionParsers.cramFileDefinition.maxLength;
        const { size: fileSize } = await this.file.stat();
        const { cramContainerHeader1 } = sectionParsers;
        // skip with a series of reads to the proper container
        let currentContainer;
        for (let i = 0; i <= containerNumber; i += 1) {
            // if we are about to go off the end of the file
            // and have not found that container, it does not exist
            if (position + cramContainerHeader1.maxLength + 8 >= fileSize) {
                return undefined;
            }
            currentContainer = this.getContainerAtPosition(position);
            const currentHeader = await currentContainer.getHeader();
            if (!currentHeader) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_3__.CramMalformedError(`container ${containerNumber} not found in file`);
            }
            // if this is the first container, read all the blocks in the
            // container to determine its length, because we cannot trust
            // the container header's given length due to a bug somewhere
            // in htslib
            if (i === 0) {
                position = currentHeader._endPosition;
                for (let j = 0; j < currentHeader.numBlocks; j += 1) {
                    const block = await this.readBlock(position);
                    position = block._endPosition;
                }
            }
            else {
                // otherwise, just traverse to the next container using the container's length
                position += currentHeader._size + currentHeader.length;
            }
        }
        return currentContainer;
    }
    async checkCrc32(position, length, recordedCrc32, description) {
        const b = Buffer.allocUnsafe(length);
        await this.file.read(b, 0, length, position);
        const calculatedCrc32 = buffer_crc32__WEBPACK_IMPORTED_MODULE_1___default().unsigned(b);
        if (calculatedCrc32 !== recordedCrc32) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_3__.CramMalformedError(`crc mismatch in ${description}: recorded CRC32 = ${recordedCrc32}, but calculated CRC32 = ${calculatedCrc32}`);
        }
    }
    /**
     * @returns {Promise[number]} the number of containers in the file
     */
    async containerCount() {
        const sectionParsers = await this.getSectionParsers();
        const { size: fileSize } = await this.file.stat();
        const { cramContainerHeader1 } = sectionParsers;
        let containerCount = 0;
        let position = sectionParsers.cramFileDefinition.maxLength;
        while (position + cramContainerHeader1.maxLength + 8 < fileSize) {
            const currentHeader = await this.getContainerAtPosition(position).getHeader();
            if (!currentHeader) {
                break;
            }
            // if this is the first container, read all the blocks in the
            // container, because we cannot trust the container
            // header's given length due to a bug somewhere in htslib
            if (containerCount === 0) {
                position = currentHeader._endPosition;
                for (let j = 0; j < currentHeader.numBlocks; j += 1) {
                    const block = await this.readBlock(position);
                    position = block._endPosition;
                }
            }
            else {
                // otherwise, just traverse to the next container using the container's length
                position += currentHeader._size + currentHeader.length;
            }
            containerCount += 1;
        }
        return containerCount;
    }
    getContainerAtPosition(position) {
        return new _container__WEBPACK_IMPORTED_MODULE_7__["default"](this, position);
    }
    async readBlockHeader(position) {
        const sectionParsers = await this.getSectionParsers();
        const { cramBlockHeader } = sectionParsers;
        const { size: fileSize } = await this.file.stat();
        if (position + cramBlockHeader.maxLength >= fileSize) {
            return undefined;
        }
        const buffer = Buffer.allocUnsafe(cramBlockHeader.maxLength);
        await this.file.read(buffer, 0, cramBlockHeader.maxLength, position);
        return (0,_util__WEBPACK_IMPORTED_MODULE_9__.parseItem)(buffer, cramBlockHeader.parser, 0, position);
    }
    async _parseSection(section, position, size = section.maxLength, preReadBuffer) {
        let buffer;
        if (preReadBuffer) {
            buffer = preReadBuffer;
        }
        else {
            const { size: fileSize } = await this.file.stat();
            if (position + size >= fileSize) {
                return undefined;
            }
            buffer = Buffer.allocUnsafe(size);
            await this.file.read(buffer, 0, size, position);
        }
        const data = (0,_util__WEBPACK_IMPORTED_MODULE_9__.parseItem)(buffer, section.parser, 0, position);
        if (data._size !== size) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_3__.CramMalformedError(`section read error: requested size ${size} does not equal parsed size ${data._size}`);
        }
        return data;
    }
    _uncompress(compressionMethod, inputBuffer, outputBuffer) {
        if (compressionMethod === 'gzip') {
            const result = (0,_unzip__WEBPACK_IMPORTED_MODULE_0__.unzip)(inputBuffer);
            result.copy(outputBuffer);
        }
        else if (compressionMethod === 'bzip2') {
            var bits = bzip2.array(inputBuffer);
            var size = bzip2.header(bits);
            var j = 0;
            do {
                var chunk = bzip2.decompress(bits, size);
                if (chunk != -1) {
                    Buffer.from(chunk).copy(outputBuffer, j);
                    j += chunk.length;
                    size -= chunk.length;
                }
            } while (chunk != -1);
        }
        else if (compressionMethod === 'rans') {
            (0,_rans__WEBPACK_IMPORTED_MODULE_4__["default"])(inputBuffer, outputBuffer);
            //htscodecs r4x8 is slower, but compatible.
            //htscodecs.r4x8_uncompress(inputBuffer, outputBuffer);
        }
        else if (compressionMethod === 'rans4x16') {
            _jkbonfield_htscodecs__WEBPACK_IMPORTED_MODULE_6___default().r4x16_uncompress(inputBuffer, outputBuffer);
        }
        else if (compressionMethod === 'arith') {
            _jkbonfield_htscodecs__WEBPACK_IMPORTED_MODULE_6___default().arith_uncompress(inputBuffer, outputBuffer);
        }
        else if (compressionMethod === 'fqzcomp') {
            _jkbonfield_htscodecs__WEBPACK_IMPORTED_MODULE_6___default().fqzcomp_uncompress(inputBuffer, outputBuffer);
        }
        else if (compressionMethod === 'tok3') {
            _jkbonfield_htscodecs__WEBPACK_IMPORTED_MODULE_6___default().tok3_uncompress(inputBuffer, outputBuffer);
        }
        else {
            throw new _errors__WEBPACK_IMPORTED_MODULE_3__.CramUnimplementedError(`${compressionMethod} decompression not yet implemented`);
        }
    }
    async readBlock(position) {
        const { majorVersion } = await this.getDefinition();
        const sectionParsers = await this.getSectionParsers();
        const block = await this.readBlockHeader(position);
        const blockContentPosition = block._endPosition;
        block.contentPosition = block._endPosition;
        const uncompressedData = Buffer.allocUnsafe(block.uncompressedSize);
        if (block.compressionMethod !== 'raw') {
            const compressedData = Buffer.allocUnsafe(block.compressedSize);
            await this.read(compressedData, 0, block.compressedSize, blockContentPosition);
            this._uncompress(block.compressionMethod, compressedData, uncompressedData);
        }
        else {
            await this.read(uncompressedData, 0, block.uncompressedSize, blockContentPosition);
        }
        block.content = uncompressedData;
        if (majorVersion >= 3) {
            // parse the crc32
            const crc = await this._parseSection(sectionParsers.cramBlockCrc32, blockContentPosition + block.compressedSize);
            block.crc32 = crc.crc32;
            // check the block data crc32
            if (this.validateChecksums) {
                await this.checkCrc32(position, block._size + block.compressedSize, block.crc32, 'block data');
            }
            // make the endposition and size reflect the whole block
            block._endPosition = crc._endPosition;
            block._size =
                block.compressedSize + sectionParsers.cramBlockCrc32.maxLength;
        }
        else {
            block._endPosition = blockContentPosition + block.compressedSize;
            block._size = block.compressedSize;
        }
        return block;
    }
}
'getDefinition getSectionParsers getSamHeader'
    .split(' ')
    .forEach(method => (0,_util__WEBPACK_IMPORTED_MODULE_9__.tinyMemoize)(CramFile, method));
//# sourceMappingURL=file.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/index.js ***!
  \*******************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _file__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./file */ "./node_modules/@gmod/cram/esm/cramFile/file.js");

/* harmony default export */ __webpack_exports__["default"] = (_file__WEBPACK_IMPORTED_MODULE_0__["default"]);
//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/record.js":
/*!********************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/record.js ***!
  \********************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CramRecord; }
/* harmony export */ });
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./constants */ "./node_modules/@gmod/cram/esm/cramFile/constants.js");

function decodeReadSequence(cramRecord, refRegion) {
    // if it has no length, it has no sequence
    if (!cramRecord.lengthOnRef && !cramRecord.readLength) {
        return undefined;
    }
    if (cramRecord.isUnknownBases()) {
        return undefined;
    }
    // remember: all coordinates are 1-based closed
    const regionSeqOffset = cramRecord.alignmentStart - refRegion.start;
    if (!cramRecord.readFeatures) {
        return refRegion.seq
            .substr(regionSeqOffset, cramRecord.lengthOnRef)
            .toUpperCase();
    }
    let bases = '';
    let regionPos = regionSeqOffset;
    let currentReadFeature = 0;
    while (bases.length < cramRecord.readLength) {
        if (currentReadFeature < cramRecord.readFeatures.length) {
            const feature = cramRecord.readFeatures[currentReadFeature];
            if (feature.code === 'Q' || feature.code === 'q') {
                currentReadFeature += 1;
            }
            else if (feature.pos === bases.length + 1) {
                // process the read feature
                currentReadFeature += 1;
                if (feature.code === 'b') {
                    // specify a base pair for some reason
                    const ret = feature.data.split(',');
                    const added = String.fromCharCode(...ret);
                    bases += added;
                    regionPos += added.length;
                }
                else if (feature.code === 'B') {
                    // base pair and associated quality
                    // TODO: do we need to set the quality in the qual scores?
                    bases += feature.data[0];
                    regionPos += 1;
                }
                else if (feature.code === 'X') {
                    // base substitution
                    bases += feature.sub;
                    regionPos += 1;
                }
                else if (feature.code === 'I') {
                    // insertion
                    bases += feature.data;
                }
                else if (feature.code === 'D') {
                    // deletion
                    regionPos += feature.data;
                }
                else if (feature.code === 'i') {
                    // insert single base
                    bases += feature.data;
                }
                else if (feature.code === 'N') {
                    // reference skip. delete some bases
                    // do nothing
                    // seqBases.splice(feature.pos - 1, feature.data)
                    regionPos += feature.data;
                }
                else if (feature.code === 'S') {
                    // soft clipped bases that should be present in the read seq
                    // seqBases.splice(feature.pos - 1, 0, ...feature.data.split(''))
                    bases += feature.data;
                }
                else if (feature.code === 'P') {
                    // padding, do nothing
                }
                else if (feature.code === 'H') {
                    // hard clip, do nothing
                }
            }
            else if (currentReadFeature < cramRecord.readFeatures.length) {
                // put down a chunk of sequence up to the next read feature
                const chunk = refRegion.seq.substr(regionPos, cramRecord.readFeatures[currentReadFeature].pos - bases.length - 1);
                bases += chunk;
                regionPos += chunk.length;
            }
        }
        else {
            // put down a chunk of reference up to the full read length
            const chunk = refRegion.seq.substr(regionPos, cramRecord.readLength - bases.length);
            bases += chunk;
            regionPos += chunk.length;
        }
    }
    return bases.toUpperCase();
}
const baseNumbers = {
    a: 0,
    A: 0,
    c: 1,
    C: 1,
    g: 2,
    G: 2,
    t: 3,
    T: 3,
    n: 4,
    N: 4,
};
function decodeBaseSubstitution(cramRecord, refRegion, compressionScheme, readFeature) {
    if (!refRegion) {
        return;
    }
    // decode base substitution code using the substitution matrix
    const refCoord = readFeature.refPos - refRegion.start;
    const refBase = refRegion.seq.charAt(refCoord);
    if (refBase) {
        readFeature.ref = refBase;
    }
    let baseNumber = baseNumbers[refBase];
    if (baseNumber === undefined) {
        baseNumber = 4;
    }
    const substitutionScheme = compressionScheme.substitutionMatrix[baseNumber];
    const base = substitutionScheme[readFeature.data];
    if (base) {
        readFeature.sub = base;
    }
}
/**
 * Class of each CRAM record returned by this API.
 */
class CramRecord {
    constructor() {
        this.tags = {};
    }
    /**
     * @returns {boolean} true if the read is paired, regardless of whether both segments are mapped
     */
    isPaired() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FPAIRED);
    }
    /** @returns {boolean} true if the read is paired, and both segments are mapped */
    isProperlyPaired() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FPROPER_PAIR);
    }
    /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */
    isSegmentUnmapped() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FUNMAP);
    }
    /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */
    isMateUnmapped() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FMUNMAP);
    }
    /** @returns {boolean} true if the read is mapped to the reverse strand */
    isReverseComplemented() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FREVERSE);
    }
    /** @returns {boolean} true if the mate is mapped to the reverse strand */
    isMateReverseComplemented() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FMREVERSE);
    }
    /** @returns {boolean} true if this is read number 1 in a pair */
    isRead1() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FREAD1);
    }
    /** @returns {boolean} true if this is read number 2 in a pair */
    isRead2() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FREAD2);
    }
    /** @returns {boolean} true if this is a secondary alignment */
    isSecondary() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FSECONDARY);
    }
    /** @returns {boolean} true if this read has failed QC checks */
    isFailedQc() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FQCFAIL);
    }
    /** @returns {boolean} true if the read is an optical or PCR duplicate */
    isDuplicate() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FDUP);
    }
    /** @returns {boolean} true if this is a supplementary alignment */
    isSupplementary() {
        return !!(this.flags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].BAM_FSUPPLEMENTARY);
    }
    /**
     * @returns {boolean} true if the read is detached
     */
    isDetached() {
        return !!(this.cramFlags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].CRAM_FLAG_DETACHED);
    }
    /** @returns {boolean} true if the read has a mate in this same CRAM segment */
    hasMateDownStream() {
        return !!(this.cramFlags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].CRAM_FLAG_MATE_DOWNSTREAM);
    }
    /** @returns {boolean} true if the read contains qual scores */
    isPreservingQualityScores() {
        return !!(this.cramFlags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].CRAM_FLAG_PRESERVE_QUAL_SCORES);
    }
    /** @returns {boolean} true if the read has no sequence bases */
    isUnknownBases() {
        return !!(this.cramFlags & _constants__WEBPACK_IMPORTED_MODULE_0__["default"].CRAM_FLAG_NO_SEQ);
    }
    /**
     * Get the original sequence of this read.
     * @returns {String} sequence basepairs
     */
    getReadBases() {
        if (!this.readBases && this._refRegion) {
            this.readBases = decodeReadSequence(this, this._refRegion);
        }
        return this.readBases;
    }
    /**
     * Get the pair orientation of a paired read. Adapted from igv.js
     * @returns {String} of paired orientatin
     */
    getPairOrientation() {
        if (!this.isSegmentUnmapped() &&
            this.isPaired() &&
            !this.isMateUnmapped() &&
            this.mate &&
            this.sequenceId === this.mate.sequenceId) {
            const s1 = this.isReverseComplemented() ? 'R' : 'F';
            const s2 = this.isMateReverseComplemented() ? 'R' : 'F';
            let o1 = ' ';
            let o2 = ' ';
            if (this.isRead1()) {
                o1 = '1';
                o2 = '2';
            }
            else if (this.isRead2()) {
                o1 = '2';
                o2 = '1';
            }
            const tmp = [];
            let isize = this.templateLength || this.templateSize;
            if (this.alignmentStart > this.mate.alignmentStart && isize > 0) {
                isize = -isize;
            }
            if (isize > 0) {
                tmp[0] = s1;
                tmp[1] = o1;
                tmp[2] = s2;
                tmp[3] = o2;
            }
            else {
                tmp[2] = s1;
                tmp[3] = o1;
                tmp[0] = s2;
                tmp[1] = o2;
            }
            return tmp.join('');
        }
        return null;
    }
    /**
     * Annotates this feature with the given reference sequence basepair
     * information. This will add a `sub` and a `ref` item to base
     * subsitution read features given the actual substituted and reference
     * base pairs, and will make the `getReadSequence()` method work.
     *
     * @param {object} refRegion
     * @param {number} refRegion.start
     * @param {number} refRegion.end
     * @param {string} refRegion.seq
     * @param {CramContainerCompressionScheme} compressionScheme
     * @returns {undefined} nothing
     */
    addReferenceSequence(refRegion, compressionScheme) {
        if (this.readFeatures) {
            // use the reference bases to decode the bases
            // substituted in each base substitution
            this.readFeatures.forEach(readFeature => {
                if (readFeature.code === 'X') {
                    decodeBaseSubstitution(this, refRegion, compressionScheme, readFeature);
                }
            });
        }
        // if this region completely covers this read,
        // keep a reference to it
        if (!this.readBases &&
            refRegion.start <= this.alignmentStart &&
            refRegion.end >=
                this.alignmentStart + (this.lengthOnRef || this.readLength) - 1) {
            this._refRegion = refRegion;
        }
    }
    toJSON() {
        const data = {};
        Object.keys(this).forEach(k => {
            if (k.charAt(0) === '_') {
                return;
            }
            data[k] = this[k];
        });
        data.readBases = this.getReadBases();
        return data;
    }
}
//# sourceMappingURL=record.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/sectionParsers.js":
/*!****************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/sectionParsers.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "cramFileDefinition": function() { return /* binding */ cramFileDefinition; },
/* harmony export */   "getSectionParsers": function() { return /* binding */ getSectionParsers; }
/* harmony export */ });
/* harmony import */ var _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @gmod/binary-parser */ "./node_modules/@gmod/binary-parser/dist/binary_parser.js");

const singleItf8 = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8();
const cramFileDefinition = {
    parser: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
        .string('magic', { length: 4 })
        .uint8('majorVersion')
        .uint8('minorVersion')
        .string('fileId', { length: 20, stripNull: true }),
    maxLength: 26,
};
const cramBlockHeader = {
    parser: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
        .uint8('compressionMethod', {
        formatter: /* istanbul ignore next */ /* istanbul ignore next */ b => {
            const method = [
                'raw',
                'gzip',
                'bzip2',
                'lzma',
                'rans',
                'rans4x16',
                'arith',
                'fqzcomp',
                'tok3',
            ][b];
            if (!method) {
                throw new Error(`compression method number ${b} not implemented`);
            }
            return method;
        },
    })
        .uint8('contentType', {
        formatter: /* istanbul ignore next */ /* istanbul ignore next */ b => {
            const type = [
                'FILE_HEADER',
                'COMPRESSION_HEADER',
                'MAPPED_SLICE_HEADER',
                'UNMAPPED_SLICE_HEADER',
                'EXTERNAL_DATA',
                'CORE_DATA',
            ][b];
            if (!type) {
                throw new Error(`invalid block content type id ${b}`);
            }
            return type;
        },
    })
        .itf8('contentId')
        .itf8('compressedSize')
        .itf8('uncompressedSize'),
    maxLength: 17,
};
const cramBlockCrc32 = {
    parser: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().uint32('crc32'),
    maxLength: 4,
};
// const ENCODING_NAMES = [
//   'NULL', // 0
//   'EXTERNAL', // 1
//   'GOLOMB', // 2
//   'HUFFMAN_INT', // 3
//   'BYTE_ARRAY_LEN', // 4
//   'BYTE_ARRAY_STOP', // 5
//   'BETA', // 6
//   'SUBEXP', // 7
//   'GOLOMB_RICE', // 8
//   'GAMMA', // 9
// ]
const cramTagDictionary = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8('size').buffer('ents', {
    length: 'size',
    formatter: /* istanbul ignore next */ /* istanbul ignore next */ buffer => {
        function makeTagSet(stringStart, stringEnd) {
            const str = buffer.toString('utf8', stringStart, stringEnd);
            const tags = [];
            for (let i = 0; i < str.length; i += 3) {
                tags.push(str.substr(i, 3));
            }
            return tags;
        }
        /* eslint-disable */
        var tagSets = [];
        var stringStart = 0;
        var i;
        /* eslint-enable */
        for (i = 0; i < buffer.length; i += 1) {
            if (!buffer[i]) {
                tagSets.push(makeTagSet(stringStart, i));
                stringStart = i + 1;
            }
        }
        if (i > stringStart) {
            tagSets.push(makeTagSet(stringStart, i));
        }
        return tagSets;
    },
});
// const cramPreservationMapKeys = 'XX RN AP RR SM TD'.split(' ')
const parseByteAsBool = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().uint8(null, {
    formatter: /* istanbul ignore next */ /* istanbul ignore next */ val => !!val,
});
const cramPreservationMap = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
    .itf8('mapSize')
    .itf8('mapCount')
    .array('ents', {
    length: 'mapCount',
    type: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
        .string('key', {
        length: 2,
        stripNull: false,
        // formatter: val => cramPreservationMapKeys[val] || 0,
    })
        .choice('value', {
        tag: 'key',
        choices: {
            MI: parseByteAsBool,
            UI: parseByteAsBool,
            PI: parseByteAsBool,
            RN: parseByteAsBool,
            AP: parseByteAsBool,
            RR: parseByteAsBool,
            SM: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().array(null, { type: 'uint8', length: 5 }),
            TD: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().nest(null, {
                type: cramTagDictionary,
                formatter: /* istanbul ignore next */ /* istanbul ignore next */ data => data.ents,
            }),
        },
    }),
});
/* istanbul ignore next */
function formatMap(data) {
    const map = {};
    for (let i = 0; i < data.ents.length; i += 1) {
        const { key, value } = data.ents[i];
        if (map[key]) {
            console.warn(`duplicate key ${key} in map`);
        }
        map[key] = value;
    }
    return map;
}
const unversionedParsers = {
    cramFileDefinition,
    cramBlockHeader,
    cramBlockCrc32,
};
// each of these is a function of the major and minor version
const versionedParsers = {
    // assemble a section parser for the unmapped slice header, with slight
    // variations depending on the major version of the cram file
    cramUnmappedSliceHeader(majorVersion) {
        let maxLength = 0;
        let parser = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8('numRecords');
        maxLength += 5;
        // recordCounter is itf8 in a CRAM v2 file, absent in CRAM v1
        if (majorVersion >= 3) {
            parser = parser.ltf8('recordCounter');
            maxLength += 9;
        }
        else if (majorVersion === 2) {
            parser = parser.itf8('recordCounter');
            maxLength += 5;
        }
        parser = parser
            .itf8('numBlocks')
            .itf8('numContentIds')
            .array('contentIds', {
            type: singleItf8,
            length: 'numContentIds',
        });
        maxLength += 5 * 2; // + numContentIds*5
        // the md5 sum is missing in cram v1
        if (majorVersion >= 2) {
            parser = parser.array('md5', { type: 'uint8', length: 16 });
            maxLength += 16;
        }
        const maxLengthFunc = numContentIds => maxLength + numContentIds * 5;
        return { parser, maxLength: maxLengthFunc }; // : p, maxLength: numContentIds => 5 + 9 + 5 * 2 + 5 * numContentIds + 16 }
    },
    // assembles a section parser for the unmapped slice header, with slight
    // variations depending on the major version of the cram file
    cramMappedSliceHeader(majorVersion) {
        let parser = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
            .itf8('refSeqId')
            .itf8('refSeqStart')
            .itf8('refSeqSpan')
            .itf8('numRecords');
        let maxLength = 5 * 4;
        if (majorVersion >= 3) {
            parser = parser.ltf8('recordCounter');
            maxLength += 9;
        }
        else if (majorVersion === 2) {
            parser = parser.itf8('recordCounter');
            maxLength += 5;
        }
        parser = parser
            .itf8('numBlocks')
            .itf8('numContentIds')
            .array('contentIds', {
            type: singleItf8,
            length: 'numContentIds',
        })
            .itf8('refBaseBlockId');
        maxLength += 5 * 3;
        // the md5 sum is missing in cram v1
        if (majorVersion >= 2) {
            parser = parser.array('md5', { type: 'uint8', length: 16 });
            maxLength += 16;
        }
        const maxLengthFunc = numContentIds => maxLength + numContentIds * 5;
        return { parser, maxLength: maxLengthFunc };
    },
    cramEncoding(majorVersion) {
        const parser = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
            .namely('cramEncoding')
            .itf8('codecId')
            .itf8('parametersBytes')
            .choice('parameters', {
            tag: 'codecId',
            choices: {
                0: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser(),
                1: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8('blockContentId'),
                2: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8('offset').itf8('M'),
                // HUFFMAN_INT
                3: _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser.start()
                    .itf8('numCodes')
                    .array('symbols', { length: 'numCodes', type: singleItf8 })
                    .itf8('numLengths')
                    .array('bitLengths', { length: 'numLengths', type: singleItf8 }),
                4: _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser.start() // BYTE_ARRAY_LEN
                    .nest('lengthsEncoding', { type: 'cramEncoding' })
                    .nest('valuesEncoding', { type: 'cramEncoding' }),
                // BYTE_ARRAY_STOP is a little different for CRAM v1
                5: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
                    .uint8('stopByte')[majorVersion > 1 ? 'itf8' : 'int']('blockContentId'),
                6: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8('offset').itf8('length'),
                7: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8('offset').itf8('K'),
                8: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8('offset').itf8('log2m'),
                9: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8('offset'), // GAMMA
            },
        });
        return { parser };
    },
    cramDataSeriesEncodingMap(majorVersion) {
        return new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
            .itf8('mapSize')
            .itf8('mapCount')
            .array('ents', {
            length: 'mapCount',
            type: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
                .string('key', { length: 2, stripNull: false })
                .nest('value', { type: this.cramEncoding(majorVersion).parser }),
        });
    },
    cramTagEncodingMap(majorVersion) {
        return new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
            .itf8('mapSize')
            .itf8('mapCount')
            .array('ents', {
            length: 'mapCount',
            type: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
                .itf8('key', {
                formatter: /* istanbul ignore next */ /* istanbul ignore next */ integerRepresentation => 
                /* istanbul ignore next */
                String.fromCharCode((integerRepresentation >> 16) & 0xff) +
                    String.fromCharCode((integerRepresentation >> 8) & 0xff) +
                    String.fromCharCode(integerRepresentation & 0xff),
            })
                .nest('value', { type: this.cramEncoding(majorVersion).parser }),
        });
    },
    cramCompressionHeader(majorVersion) {
        let parser = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser();
        // TODO: if we want to support CRAM v1, we will need to refactor
        // compression header into 2 parts to parse the landmarks,
        // like the container header
        parser = parser
            .nest('preservation', {
            type: cramPreservationMap,
            formatter: formatMap,
        })
            .nest('dataSeriesEncoding', {
            type: this.cramDataSeriesEncodingMap(majorVersion),
            formatter: formatMap,
        })
            .nest('tagEncoding', {
            type: this.cramTagEncodingMap(majorVersion),
            formatter: formatMap,
        });
        return { parser };
    },
    cramContainerHeader1(majorVersion) {
        let parser = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
            .int32('length') // byte size of the container data (blocks)
            .itf8('refSeqId') // reference sequence identifier, -1 for unmapped reads, -2 for multiple reference sequences
            .itf8('refSeqStart') // the alignment start position or 0 for unmapped reads
            .itf8('alignmentSpan') // the length of the alignment or 0 for unmapped reads
            .itf8('numRecords'); // number of records in the container
        let maxLength = 4 + 5 * 4;
        if (majorVersion >= 3) {
            parser = parser.ltf8('recordCounter'); // 1-based sequential index of records in the file/stream.
            maxLength += 9;
        }
        else if (majorVersion === 2) {
            parser = parser.itf8('recordCounter');
            maxLength += 5;
        }
        if (majorVersion > 1) {
            parser = parser.ltf8('numBases'); // number of read bases
            maxLength += 9;
        }
        parser = parser
            .itf8('numBlocks') // the number of blocks
            .itf8('numLandmarks'); // the number of landmarks
        maxLength += 5 + 5;
        return { parser, maxLength };
    },
    cramContainerHeader2(majorVersion) {
        let parser = new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser()
            .itf8('numLandmarks') // the number of blocks
            // Each integer value of this array is a byte offset
            // into the blocks byte array. Landmarks are used for
            // random access indexing.
            .array('landmarks', {
            type: new _gmod_binary_parser__WEBPACK_IMPORTED_MODULE_0__.Parser().itf8(),
            length: 'numLandmarks',
        });
        let crcLength = 0;
        if (majorVersion >= 3) {
            parser = parser.uint32('crc32');
            crcLength = 4;
        }
        return {
            parser,
            maxLength: numLandmarks => 5 + numLandmarks * 5 + crcLength,
        };
    },
};
function getSectionParsers(majorVersion) {
    const parsers = Object.assign({}, unversionedParsers);
    Object.keys(versionedParsers).forEach(parserName => {
        parsers[parserName] = versionedParsers[parserName](majorVersion);
    });
    return parsers;
}

//# sourceMappingURL=sectionParsers.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/slice/decodeRecord.js":
/*!********************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/slice/decodeRecord.js ***!
  \********************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ decodeRecord; }
/* harmony export */ });
/* harmony import */ var long__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! long */ "./node_modules/long/src/long.js");
/* harmony import */ var long__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(long__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _record__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../record */ "./node_modules/@gmod/cram/esm/cramFile/record.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../constants */ "./node_modules/@gmod/cram/esm/cramFile/constants.js");




/**
 * given a Buffer, read a string up to the first null character
 * @private
 */
function readNullTerminatedString(buffer) {
    let r = '';
    for (let i = 0; i < buffer.length && buffer[i] !== 0; i++) {
        r += String.fromCharCode(buffer[i]);
    }
    return r;
}
/**
 * parse a BAM tag's array value from a binary buffer
 * @private
 */
function parseTagValueArray(buffer) {
    const arrayType = String.fromCharCode(buffer[0]);
    const length = Int32Array.from(buffer.slice(1))[0];
    const array = new Array(length);
    buffer = buffer.slice(5);
    if (arrayType === 'c') {
        const arr = new Int8Array(buffer.buffer);
        for (let i = 0; i < length; i += 1) {
            array[i] = arr[i];
        }
    }
    else if (arrayType === 'C') {
        const arr = new Uint8Array(buffer.buffer);
        for (let i = 0; i < length; i += 1) {
            array[i] = arr[i];
        }
    }
    else if (arrayType === 's') {
        const arr = new Int16Array(buffer.buffer);
        for (let i = 0; i < length; i += 1) {
            array[i] = arr[i];
        }
    }
    else if (arrayType === 'S') {
        const arr = new Uint16Array(buffer.buffer);
        for (let i = 0; i < length; i += 1) {
            array[i] = arr[i];
        }
    }
    else if (arrayType === 'i') {
        const arr = new Int32Array(buffer.buffer);
        for (let i = 0; i < length; i += 1) {
            array[i] = arr[i];
        }
    }
    else if (arrayType === 'I') {
        const arr = new Uint32Array(buffer.buffer);
        for (let i = 0; i < length; i += 1) {
            array[i] = arr[i];
        }
    }
    else if (arrayType === 'f') {
        const arr = new Float32Array(buffer.buffer);
        for (let i = 0; i < length; i += 1) {
            array[i] = arr[i];
        }
    }
    else {
        throw new Error('unknown type: ' + arrayType);
    }
    return array;
}
function parseTagData(tagType, buffer) {
    if (tagType === 'Z') {
        return readNullTerminatedString(buffer);
    }
    if (tagType === 'A') {
        return String.fromCharCode(buffer[0]);
    }
    if (tagType === 'I') {
        return long__WEBPACK_IMPORTED_MODULE_0___default().fromBytesLE(buffer).toNumber();
    }
    if (tagType === 'i') {
        return new Int32Array(buffer.buffer)[0];
    }
    if (tagType === 's') {
        return new Int16Array(buffer.buffer)[0];
    }
    if (tagType === 'S') {
        return new Uint16Array(buffer.buffer)[0];
    }
    if (tagType === 'c') {
        return new Int8Array(buffer.buffer)[0];
    }
    if (tagType === 'C') {
        return buffer[0];
    }
    if (tagType === 'f') {
        return new Float32Array(buffer.buffer)[0];
    }
    if (tagType === 'H') {
        return Number.parseInt(readNullTerminatedString(buffer).replace(/^0x/, ''), 16);
    }
    if (tagType === 'B') {
        return parseTagValueArray(buffer);
    }
    throw new _errors__WEBPACK_IMPORTED_MODULE_1__.CramMalformedError(`Unrecognized tag type ${tagType}`);
}
function decodeReadFeatures(cramRecord, readFeatureCount, decodeDataSeries, compressionScheme, majorVersion) {
    let currentReadPos = 0;
    let currentRefPos = cramRecord.alignmentStart - 1;
    const readFeatures = new Array(readFeatureCount);
    function decodeRFData([type, dataSeriesName]) {
        const data = decodeDataSeries(dataSeriesName);
        if (type === 'character') {
            return String.fromCharCode(data);
        }
        if (type === 'string') {
            return data.toString('utf8');
        }
        if (type === 'numArray') {
            return data.toArray();
        }
        // else if (type === 'number') {
        //   return data[0]
        // }
        return data;
    }
    for (let i = 0; i < readFeatureCount; i += 1) {
        const code = String.fromCharCode(decodeDataSeries('FC'));
        const readPosDelta = decodeDataSeries('FP');
        const readFeature = { code };
        // map of operator name -> data series name
        const data1Schema = {
            B: ['character', 'BA'],
            S: ['string', majorVersion > 1 ? 'SC' : 'IN'],
            X: ['number', 'BS'],
            D: ['number', 'DL'],
            I: ['string', 'IN'],
            i: ['character', 'BA'],
            b: ['string', 'BB'],
            q: ['numArray', 'QQ'],
            Q: ['number', 'QS'],
            H: ['number', 'HC'],
            P: ['number', 'PD'],
            N: ['number', 'RS'],
        }[code];
        if (!data1Schema) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_1__.CramMalformedError(`invalid read feature code "${code}"`);
        }
        readFeature.data = decodeRFData(data1Schema);
        // if this is a tag with two data items, make the data an array and add the second item
        const data2Schema = { B: ['number', 'QS'] }[code];
        if (data2Schema) {
            readFeature.data = [readFeature.data, decodeRFData(data2Schema)];
        }
        currentReadPos += readPosDelta;
        readFeature.pos = currentReadPos;
        currentRefPos += readPosDelta;
        readFeature.refPos = currentRefPos;
        // for gapping features, adjust the reference position for read features that follow
        if (code === 'D' || code === 'N') {
            currentRefPos += readFeature.data;
        }
        else if (code === 'I' || code === 'S') {
            currentRefPos -= readFeature.data.length;
        }
        else if (code === 'i') {
            currentRefPos -= 1;
        }
        readFeatures[i] = readFeature;
    }
    return readFeatures;
}
function decodeRecord(slice, decodeDataSeries, compressionScheme, sliceHeader, coreDataBlock, blocksByContentId, cursors, majorVersion, recordNumber) {
    const cramRecord = new _record__WEBPACK_IMPORTED_MODULE_2__["default"]();
    cramRecord.flags = decodeDataSeries('BF');
    // note: the C data type of compressionFlags is byte in cram v1
    // and int32 in cram v2+, but that does not matter for us here
    // in javascript land.
    cramRecord.cramFlags = decodeDataSeries('CF');
    if (majorVersion > 1 && sliceHeader.content.refSeqId === -2) {
        cramRecord.sequenceId = decodeDataSeries('RI');
    }
    else {
        cramRecord.sequenceId = sliceHeader.content.refSeqId;
    }
    cramRecord.readLength = decodeDataSeries('RL');
    // if APDelta, will calculate the true start in a second pass
    cramRecord.alignmentStart = decodeDataSeries('AP');
    if (compressionScheme.APdelta) {
        cramRecord.alignmentStart += cursors.lastAlignmentStart;
    }
    cursors.lastAlignmentStart = cramRecord.alignmentStart;
    cramRecord.readGroupId = decodeDataSeries('RG');
    if (compressionScheme.readNamesIncluded) {
        cramRecord.readName = readNullTerminatedString(decodeDataSeries('RN'));
    }
    // mate record
    if (cramRecord.isDetached()) {
        // note: the MF is a byte in 1.0, int32 in 2+, but once again this doesn't matter for javascript
        const mate = {};
        mate.flags = decodeDataSeries('MF');
        if (!compressionScheme.readNamesIncluded) {
            mate.readName = readNullTerminatedString(decodeDataSeries('RN'));
            cramRecord.readName = mate.readName;
        }
        mate.sequenceId = decodeDataSeries('NS');
        mate.alignmentStart = decodeDataSeries('NP');
        if (mate.flags || mate.sequenceId > -1) {
            cramRecord.mate = mate;
        }
        cramRecord.templateSize = decodeDataSeries('TS');
        // set mate unmapped if needed
        if (mate.flags & _constants__WEBPACK_IMPORTED_MODULE_3__["default"].CRAM_M_UNMAP) {
            cramRecord.flags |= _constants__WEBPACK_IMPORTED_MODULE_3__["default"].BAM_FMUNMAP;
        }
        // set mate reversed if needed
        if (mate.flags & _constants__WEBPACK_IMPORTED_MODULE_3__["default"].CRAM_M_REVERSE) {
            cramRecord.flags |= _constants__WEBPACK_IMPORTED_MODULE_3__["default"].BAM_FMREVERSE;
        }
        // detachedCount++
    }
    else if (cramRecord.hasMateDownStream()) {
        cramRecord.mateRecordNumber = decodeDataSeries('NF') + recordNumber + 1;
    }
    // TODO: the aux tag parsing will have to be refactored if we want to support
    // cram v1
    const TLindex = decodeDataSeries('TL');
    if (TLindex < 0) {
        /* TODO: check nTL: TLindex >= compressionHeader.tagEncoding.size */
        throw new _errors__WEBPACK_IMPORTED_MODULE_1__.CramMalformedError('invalid TL index');
    }
    // TN = tag names
    const TN = compressionScheme.getTagNames(TLindex);
    const ntags = TN.length;
    for (let i = 0; i < ntags; i += 1) {
        const tagId = TN[i];
        const tagName = tagId.substr(0, 2);
        const tagType = tagId.substr(2, 1);
        const tagCodec = compressionScheme.getCodecForTag(tagId);
        if (!tagCodec) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_1__.CramMalformedError(`no codec defined for auxiliary tag ${tagId}`);
        }
        const tagData = tagCodec.decode(slice, coreDataBlock, blocksByContentId, cursors);
        cramRecord.tags[tagName] = parseTagData(tagType, tagData);
    }
    if (!cramRecord.isSegmentUnmapped()) {
        // reading read features
        const /* int */ readFeatureCount = decodeDataSeries('FN');
        if (readFeatureCount) {
            cramRecord.readFeatures = decodeReadFeatures(cramRecord, readFeatureCount, decodeDataSeries, compressionScheme, majorVersion);
        }
        // compute the read's true span on the reference sequence, and the end coordinate of the alignment on the reference
        let lengthOnRef = cramRecord.readLength;
        if (cramRecord.readFeatures) {
            cramRecord.readFeatures.forEach(({ code, data }) => {
                if (code === 'D' || code === 'N') {
                    lengthOnRef += data;
                }
                else if (code === 'I' || code === 'S') {
                    lengthOnRef -= data.length;
                }
                else if (code === 'i') {
                    lengthOnRef -= 1;
                }
            });
        }
        if (Number.isNaN(lengthOnRef)) {
            console.warn(`${cramRecord.readName ||
                `${cramRecord.sequenceId}:${cramRecord.alignmentStart}`} record has invalid read features`);
            lengthOnRef = cramRecord.readLength;
        }
        cramRecord.lengthOnRef = lengthOnRef;
        // mapping quality
        cramRecord.mappingQuality = decodeDataSeries('MQ');
        if (cramRecord.isPreservingQualityScores()) {
            const bases = new Array(cramRecord.readLength);
            for (let i = 0; i < bases.length; i += 1) {
                bases[i] = decodeDataSeries('QS');
            }
            cramRecord.qualityScores = bases;
        }
    }
    else if (cramRecord.isUnknownBases()) {
        cramRecord.readBases = null;
        cramRecord.qualityScores = null;
    }
    else {
        const bases = new Array(cramRecord.readLength);
        for (let i = 0; i < bases.length; i += 1) {
            bases[i] = decodeDataSeries('BA');
        }
        cramRecord.readBases = String.fromCharCode(...bases);
        if (cramRecord.isPreservingQualityScores()) {
            for (let i = 0; i < bases.length; i += 1) {
                bases[i] = decodeDataSeries('QS');
            }
            cramRecord.qualityScores = bases;
        }
    }
    return cramRecord;
}
//# sourceMappingURL=decodeRecord.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/slice/index.js":
/*!*************************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/slice/index.js ***!
  \*************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CramSlice; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _util__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util */ "./node_modules/@gmod/cram/esm/cramFile/util.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../constants */ "./node_modules/@gmod/cram/esm/cramFile/constants.js");
/* harmony import */ var _decodeRecord__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./decodeRecord */ "./node_modules/@gmod/cram/esm/cramFile/slice/decodeRecord.js");




/**
 * @private
 * Try to estimate the template length from a bunch of interrelated multi-segment reads.
 * @param {Array[CramRecord]} allRecords
 * @param {number} currentRecordNumber
 * @param {CramRecord} thisRecord
 */
function calculateMultiSegmentMatedTemplateLength(allRecords, currentRecordNumber, thisRecord) {
    function getAllMatedRecords(startRecord) {
        const records = [startRecord];
        if (startRecord.mateRecordNumber >= 0) {
            const mateRecord = allRecords[startRecord.mateRecordNumber];
            if (!mateRecord) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('intra-slice mate record not found, this file seems malformed');
            }
            records.push(...getAllMatedRecords(mateRecord));
        }
        return records;
    }
    const matedRecords = getAllMatedRecords(thisRecord);
    const starts = matedRecords.map(r => r.alignmentStart);
    const ends = matedRecords.map(r => r.alignmentStart + r.readLength - 1);
    const estimatedTemplateLength = Math.max(...ends) - Math.min(...starts) + 1;
    if (estimatedTemplateLength >= 0) {
        matedRecords.forEach(r => {
            if (r.templateLength !== undefined) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('mate pair group has some members that have template lengths already, this file seems malformed');
            }
            r.templateLength = estimatedTemplateLength;
        });
    }
}
/**
 * @private
 * Attempt to calculate the `templateLength` for a pair of intra-slice paired reads.
 * Ported from htslib. Algorithm is imperfect.
 * @param {CramRecord} thisRecord
 * @param {CramRecord} mateRecord
 */
function calculateIntraSliceMatePairTemplateLength(thisRecord, mateRecord) {
    // this just estimates the template length by using the simple (non-gapped) end coordinate of each
    // read, because gapping in the alignment doesn't mean the template is longer or shorter
    const start = Math.min(thisRecord.alignmentStart, mateRecord.alignmentStart);
    const end = Math.max(thisRecord.alignmentStart + thisRecord.readLength - 1, mateRecord.alignmentStart + mateRecord.readLength - 1);
    const lengthEstimate = end - start + 1;
    thisRecord.templateLength = lengthEstimate;
    mateRecord.templateLength = lengthEstimate;
}
/**
 * @private establishes a mate-pair relationship between two records in the same slice.
 * CRAM compresses mate-pair relationships between records in the same slice down into
 * just one record having the index in the slice of its mate
 */
function associateIntraSliceMate(allRecords, currentRecordNumber, thisRecord, mateRecord) {
    if (!mateRecord) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('could not resolve intra-slice mate pairs, file seems truncated or malformed');
    }
    const complicatedMultiSegment = !!(mateRecord.mate ||
        (mateRecord.mateRecordNumber !== undefined &&
            mateRecord.mateRecordNumber !== currentRecordNumber));
    // Deal with lossy read names
    if (!thisRecord.readName) {
        thisRecord.readName = String(thisRecord.uniqueId);
        mateRecord.readName = thisRecord.readName;
    }
    thisRecord.mate = {
        sequenceId: mateRecord.sequenceId,
        alignmentStart: mateRecord.alignmentStart,
        uniqueId: mateRecord.uniqueId,
    };
    if (mateRecord.readName) {
        thisRecord.mate.readName = mateRecord.readName;
    }
    // the mate record might have its own mate pointer, if this is some kind of
    // multi-segment (more than paired) scheme, so only relate that one back to this one
    // if it does not have any other relationship
    if (!mateRecord.mate && mateRecord.mateRecordNumber === undefined) {
        mateRecord.mate = {
            sequenceId: thisRecord.sequenceId,
            alignmentStart: thisRecord.alignmentStart,
            uniqueId: thisRecord.uniqueId,
        };
        if (thisRecord.readName) {
            mateRecord.mate.readName = thisRecord.readName;
        }
    }
    // make sure the proper flags and cramFlags are set on both records
    // paired
    thisRecord.flags |= _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FPAIRED;
    // set mate unmapped if needed
    if (mateRecord.flags & _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FUNMAP) {
        thisRecord.flags |= _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FMUNMAP;
        // thisRecord.templateLength = 0
    }
    if (thisRecord.flags & _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FUNMAP) {
        // thisRecord.templateLength = 0
        mateRecord.flags |= _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FMUNMAP;
    }
    // set mate reversed if needed
    if (mateRecord.flags & _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FREVERSE) {
        thisRecord.flags |= _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FMREVERSE;
    }
    if (thisRecord.flags & _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FREVERSE) {
        mateRecord.flags |= _constants__WEBPACK_IMPORTED_MODULE_2__["default"].BAM_FMREVERSE;
    }
    if (thisRecord.templateLength === undefined) {
        if (complicatedMultiSegment) {
            calculateMultiSegmentMatedTemplateLength(allRecords, currentRecordNumber, thisRecord);
        }
        else {
            calculateIntraSliceMatePairTemplateLength(thisRecord, mateRecord);
        }
    }
    // delete this last because it's used by the
    // complicated template length estimation
    delete thisRecord.mateRecordNumber;
}
class CramSlice {
    constructor(container, position) {
        this.container = container;
        this.file = container.file;
        this.containerPosition = position;
    }
    // memoize
    async getHeader() {
        // fetch and parse the slice header
        const sectionParsers = await this.file.getSectionParsers();
        const containerHeader = await this.container.getHeader();
        const header = await this.file.readBlock(containerHeader._endPosition + this.containerPosition);
        if (header.contentType === 'MAPPED_SLICE_HEADER') {
            header.content = (0,_util__WEBPACK_IMPORTED_MODULE_1__.parseItem)(header.content, sectionParsers.cramMappedSliceHeader.parser, 0, containerHeader._endPosition);
        }
        else if (header.contentType === 'UNMAPPED_SLICE_HEADER') {
            header.content = (0,_util__WEBPACK_IMPORTED_MODULE_1__.parseItem)(header.content, sectionParsers.cramUnmappedSliceHeader.parser, 0, containerHeader._endPosition);
        }
        else {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`error reading slice header block, invalid content type ${header._contentType}`);
        }
        return header;
    }
    // memoize
    async getBlocks() {
        const header = await this.getHeader();
        // read all the blocks into memory and store them
        let blockPosition = header._endPosition;
        const blocks = new Array(header.content.numBlocks);
        for (let i = 0; i < blocks.length; i += 1) {
            blocks[i] = await this.file.readBlock(blockPosition);
            blockPosition = blocks[i]._endPosition;
        }
        return blocks;
    }
    // no memoize
    async getCoreDataBlock() {
        const blocks = await this.getBlocks();
        // the core data block is always the first block in the slice
        return blocks[0];
    }
    // memoize
    async _getBlocksContentIdIndex() {
        const blocks = await this.getBlocks();
        const blocksByContentId = {};
        blocks.forEach(block => {
            if (block.contentType === 'EXTERNAL_DATA') {
                blocksByContentId[block.contentId] = block;
            }
        });
        return blocksByContentId;
    }
    async getBlockByContentId(id) {
        const blocksByContentId = await this._getBlocksContentIdIndex();
        return blocksByContentId[id];
    }
    async getReferenceRegion() {
        // read the slice header
        const sliceHeader = (await this.getHeader()).content;
        if (sliceHeader.refSeqId < 0) {
            return undefined;
        }
        const compressionScheme = await this.container.getCompressionScheme();
        // console.log(JSON.stringify(sliceHeader, null, '  '))
        if (sliceHeader.refBaseBlockId >= 0) {
            const refBlock = this.getBlockByContentId(sliceHeader.refBaseBlockId);
            if (!refBlock) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('embedded reference specified, but reference block does not exist');
            }
            if (sliceHeader.span > refBlock.uncompressedSize) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('Embedded reference is too small');
            }
            return {
                seq: refBlock.data.toString('utf8'),
                start: sliceHeader.refSeqStart,
                end: sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1,
                span: sliceHeader.refSeqSpan,
            };
        }
        if (compressionScheme.referenceRequired ||
            this.file.fetchReferenceSequenceCallback) {
            if (!this.file.fetchReferenceSequenceCallback) {
                throw new Error('reference sequence not embedded, and seqFetch callback not provided, cannot fetch reference sequence');
            }
            const seq = await this.file.fetchReferenceSequenceCallback(sliceHeader.refSeqId, sliceHeader.refSeqStart, sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1);
            if (seq.length !== sliceHeader.refSeqSpan) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramArgumentError('seqFetch callback returned a reference sequence of the wrong length');
            }
            return {
                seq,
                start: sliceHeader.refSeqStart,
                end: sliceHeader.refSeqStart + sliceHeader.refSeqSpan - 1,
                span: sliceHeader.refSeqSpan,
            };
        }
        return undefined;
    }
    getAllRecords() {
        return this.getRecords(() => true);
    }
    async _fetchRecords() {
        const { majorVersion } = await this.file.getDefinition();
        const compressionScheme = await this.container.getCompressionScheme();
        const sliceHeader = await this.getHeader();
        const blocksByContentId = await this._getBlocksContentIdIndex();
        // check MD5 of reference if available
        if (majorVersion > 1 &&
            this.file.options.checkSequenceMD5 &&
            sliceHeader.content.refSeqId >= 0 &&
            sliceHeader.content.md5.join('') !== '0000000000000000') {
            const refRegion = await this.getReferenceRegion();
            if (refRegion) {
                const { seq, start, end } = refRegion;
                const seqMd5 = (0,_util__WEBPACK_IMPORTED_MODULE_1__.sequenceMD5)(seq);
                const storedMd5 = sliceHeader.content.md5
                    .map(byte => (byte < 16 ? '0' : '') + byte.toString(16))
                    .join('');
                if (seqMd5 !== storedMd5) {
                    throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`MD5 checksum reference mismatch for ref ${sliceHeader.content.refSeqId} pos ${start}..${end}. recorded MD5: ${storedMd5}, calculated MD5: ${seqMd5}`);
                }
            }
        }
        // tracks the read position within the block. codec.decode() methods
        // advance the byte and bit positions in the cursor as they decode
        // data note that we are only decoding a single block here, the core
        // data block
        const coreDataBlock = await this.getCoreDataBlock();
        const cursors = {
            lastAlignmentStart: sliceHeader.content.refSeqStart || 0,
            coreBlock: { bitPosition: 7, bytePosition: 0 },
            externalBlocks: {
                map: new Map(),
                getCursor(contentId) {
                    let r = this.map.get(contentId);
                    if (r === undefined) {
                        r = { bitPosition: 7, bytePosition: 0 };
                        this.map.set(contentId, r);
                    }
                    return r;
                },
            },
        };
        const decodeDataSeries = dataSeriesName => {
            const codec = compressionScheme.getCodecForDataSeries(dataSeriesName);
            if (!codec) {
                throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`no codec defined for ${dataSeriesName} data series`);
            }
            // console.log(dataSeriesName, Object.getPrototypeOf(codec))
            return codec.decode(this, coreDataBlock, blocksByContentId, cursors);
        };
        let records = new Array(sliceHeader.content.numRecords);
        for (let i = 0; i < records.length; i += 1) {
            try {
                records[i] = (0,_decodeRecord__WEBPACK_IMPORTED_MODULE_3__["default"])(this, decodeDataSeries, compressionScheme, sliceHeader, coreDataBlock, blocksByContentId, cursors, majorVersion, i);
                records[i].uniqueId =
                    sliceHeader.contentPosition +
                        sliceHeader.content.recordCounter +
                        i +
                        1;
            }
            catch (e) {
                if (e instanceof _errors__WEBPACK_IMPORTED_MODULE_0__.CramBufferOverrunError) {
                    console.warn('read attempted beyond end of buffer, file seems truncated.');
                    records = records.filter(r => !!r);
                    break;
                }
                else {
                    throw e;
                }
            }
        }
        // interpret `recordsToNextFragment` attributes to make standard `mate`
        // objects Resolve mate pair cross-references between records in this slice
        for (let i = 0; i < records.length; i += 1) {
            const { mateRecordNumber } = records[i];
            if (mateRecordNumber >= 0) {
                associateIntraSliceMate(records, i, records[i], records[mateRecordNumber]);
            }
        }
        return records;
    }
    async getRecords(filterFunction) {
        // fetch the features if necessary, using the file-level feature cache
        const cacheKey = this.container.filePosition + this.containerPosition;
        let recordsPromise = this.file.featureCache.get(cacheKey);
        if (!recordsPromise) {
            recordsPromise = this._fetchRecords();
            this.file.featureCache.set(cacheKey, recordsPromise);
        }
        const records = (await recordsPromise).filter(filterFunction);
        // if we can fetch reference sequence, add the reference sequence to the records
        if (records.length && this.file.fetchReferenceSequenceCallback) {
            const sliceHeader = await this.getHeader();
            if (sliceHeader.content.refSeqId >= 0 || // single-ref slice
                sliceHeader.content.refSeqId === -2 // multi-ref slice
            ) {
                const singleRefId = sliceHeader.content.refSeqId >= 0
                    ? sliceHeader.content.refSeqId
                    : undefined;
                const compressionScheme = await this.container.getCompressionScheme();
                const refRegions = {}; // seqId => { start, end, seq }
                // iterate over the records to find the spans of the reference sequences we need to fetch
                for (let i = 0; i < records.length; i += 1) {
                    const seqId = singleRefId !== undefined ? singleRefId : records[i].sequenceId;
                    let refRegion = refRegions[seqId];
                    if (!refRegion) {
                        refRegion = {
                            id: seqId,
                            start: records[i].alignmentStart,
                            end: -Infinity,
                        };
                        refRegions[seqId] = refRegion;
                    }
                    const end = records[i].alignmentStart +
                        (records[i].lengthOnRef || records[i].readLength) -
                        1;
                    if (end > refRegion.end) {
                        refRegion.end = end;
                    }
                    if (records[i].alignmentStart < refRegion.start) {
                        refRegion.start = records[i].alignmentStart;
                    }
                }
                // fetch the `seq` for all of the ref regions
                await Promise.all(Object.values(refRegions).map(async (refRegion) => {
                    if (refRegion.id !== -1 && refRegion.start <= refRegion.end) {
                        refRegion.seq = await this.file.fetchReferenceSequenceCallback(refRegion.id, refRegion.start, refRegion.end);
                    }
                }));
                // now decorate all the records with them
                for (let i = 0; i < records.length; i += 1) {
                    const seqId = singleRefId !== undefined ? singleRefId : records[i].sequenceId;
                    const refRegion = refRegions[seqId];
                    if (refRegion && refRegion.seq) {
                        records[i].addReferenceSequence(refRegion, compressionScheme);
                    }
                }
            }
        }
        return records;
    }
}
// memoize several methods in the class for performance
'getHeader getBlocks _getBlocksContentIdIndex'
    .split(' ')
    .forEach(method => (0,_util__WEBPACK_IMPORTED_MODULE_1__.tinyMemoize)(CramSlice, method));
//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/cramFile/util.js":
/*!******************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/cramFile/util.js ***!
  \******************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "itf8Size": function() { return /* binding */ itf8Size; },
/* harmony export */   "parseItem": function() { return /* binding */ parseItem; },
/* harmony export */   "parseItf8": function() { return /* binding */ parseItf8; },
/* harmony export */   "sequenceMD5": function() { return /* binding */ sequenceMD5; },
/* harmony export */   "tinyMemoize": function() { return /* binding */ tinyMemoize; }
/* harmony export */ });
/* harmony import */ var md5__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! md5 */ "./node_modules/md5/md5.js");
/* harmony import */ var md5__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(md5__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../errors */ "./node_modules/@gmod/cram/esm/errors.js");


function itf8Size(v) {
    if (!(v & ~0x7f)) {
        return 1;
    }
    if (!(v & ~0x3fff)) {
        return 2;
    }
    if (!(v & ~0x1fffff)) {
        return 3;
    }
    if (!(v & ~0xfffffff)) {
        return 4;
    }
    return 5;
}
function parseItf8(buffer, initialOffset) {
    let offset = initialOffset;
    const countFlags = buffer[offset];
    let result;
    if (countFlags < 0x80) {
        result = countFlags;
        offset += 1;
    }
    else if (countFlags < 0xc0) {
        result = ((countFlags << 8) | buffer[offset + 1]) & 0x3fff;
        offset += 2;
    }
    else if (countFlags < 0xe0) {
        result =
            ((countFlags << 16) | (buffer[offset + 1] << 8) | buffer[offset + 2]) &
                0x1fffff;
        offset += 3;
    }
    else if (countFlags < 0xf0) {
        result =
            ((countFlags << 24) |
                (buffer[offset + 1] << 16) |
                (buffer[offset + 2] << 8) |
                buffer[offset + 3]) &
                0x0fffffff;
        offset += 4;
    }
    else {
        result =
            ((countFlags & 0x0f) << 28) |
                (buffer[offset + 1] << 20) |
                (buffer[offset + 2] << 12) |
                (buffer[offset + 3] << 4) |
                (buffer[offset + 4] & 0x0f);
        // x=((0xff & 0x0f)<<28) | (0xff<<20) | (0xff<<12) | (0xff<<4) | (0x0f & 0x0f);
        // TODO *val_p = uv < 0x80000000UL ? uv : -((int32_t) (0xffffffffUL - uv)) - 1;
        offset += 5;
    }
    if (offset > buffer.length) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_1__.CramBufferOverrunError('Attempted to read beyond end of buffer; this file seems truncated.');
    }
    return [result, offset - initialOffset];
}
// parseLtf8(buffer, initialOffset) {
//   let offset = initialOffset
//   const countFlags = buffer[offset]
//   let result
//   if (countFlags < 0x80) {
//     result = countFlags
//     offset += 1
//   } else if (countFlags < 0xc0) {
//     result = ((buffer[offset] << 8) | buffer[offset + 1]) & 0x3fff
//     offset += 2
//   } else if (countFlags < 0xe0) {
//     result =
//       ((buffer[offset] << 16) |
//         (buffer[offset + 1] << 8) |
//         buffer[offset + 2]) &
//       0x1fffff
//     offset += 3
//   } else if (countFlags < 0xf0) {
//     result =
//       ((buffer[offset] << 24) |
//         (buffer[offset + 1] << 16) |
//         (buffer[offset + 2] << 8) |
//         buffer[offset + 3]) &
//       0x0fffffff
//     offset += 4
//   } else if (countFlags < 0xf8) {
//     result =
//       ((buffer[offset] & 15) * Math.pow(2,32) + (buffer[offset + 1] << 24)) |
//       ((buffer[offset + 2] << 16) |
//         (buffer[offset + 3] << 8) |
//         buffer[offset + 4])
//     // TODO *val_p = uv < 0x80000000UL ? uv : -((int32_t) (0xffffffffUL - uv)) - 1;
//     offset += 5
//   } else if (countFlags < 0xfc) {
//     result =
//       ((((buffer[offset] & 7) << 8) | buffer[offset + 1]) * Math.pow(2,32) +
//         (buffer[offset + 2] << 24)) |
//       ((buffer[offset + 3] << 16) |
//         (buffer[offset + 4] << 8) |
//         buffer[offset + 5])
//     offset += 6
//   } else if (countFlags < 0xfe) {
//     result =
//       ((((buffer[offset] & 3) << 16) |
//         (buffer[offset + 1] << 8) |
//         buffer[offset + 2]) *
//         Math.pow(2,32) +
//         (buffer[offset + 3] << 24)) |
//       ((buffer[offset + 4] << 16) |
//         (buffer[offset + 5] << 8) |
//         buffer[offset + 6])
//     offset += 7
//   } else if (countFlags < 0xff) {
//     result = Long.fromBytesBE(buffer.slice(offset + 1, offset + 8))
//     if (
//       result.greaterThan(Number.MAX_SAFE_INTEGER) ||
//       result.lessThan(Number.MIN_SAFE_INTEGER)
//     )
//       throw new CramUnimplementedError('integer overflow')
//     result = result.toNumber()
//     offset += 8
//   } else {
//     result = Long.fromBytesBE(buffer.slice(offset + 1, offset + 9))
//     if (
//       result.greaterThan(Number.MAX_SAFE_INTEGER) ||
//       result.lessThan(Number.MIN_SAFE_INTEGER)
//     )
//       throw new CramUnimplementedError('integer overflow')
//     result = result.toNumber()
//     offset += 9
//   }
//   return [result, offset - initialOffset]
// },
function parseItem(buffer, parser, startBufferPosition = 0, startFilePosition = 0) {
    const { offset, result } = parser.parse(buffer);
    result._endPosition = offset + startFilePosition;
    result._size = offset - startBufferPosition;
    return result;
}
// this would be nice as a decorator, but i'm a little worried about
// babel support for it going away or changing.
// memoizes a method in the stupidest possible way, with no regard for the
// arguments.  actually, this only works on methods that take no arguments
function tinyMemoize(_class, methodName) {
    const method = _class.prototype[methodName];
    const memoAttrName = `_memo_${methodName}`;
    _class.prototype[methodName] = function _tinyMemoized() {
        if (!(memoAttrName in this)) {
            const res = method.call(this);
            this[memoAttrName] = res;
            Promise.resolve(res).catch(() => {
                delete this[memoAttrName];
            });
        }
        return this[memoAttrName];
    };
}
function sequenceMD5(seq) {
    return md5__WEBPACK_IMPORTED_MODULE_0___default()(seq.toUpperCase().replace(/[^\x21-\x7e]/g, ''));
}
//# sourceMappingURL=util.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/errors.js":
/*!***********************************************!*\
  !*** ./node_modules/@gmod/cram/esm/errors.js ***!
  \***********************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "CramArgumentError": function() { return /* binding */ CramArgumentError; },
/* harmony export */   "CramBufferOverrunError": function() { return /* binding */ CramBufferOverrunError; },
/* harmony export */   "CramError": function() { return /* binding */ CramError; },
/* harmony export */   "CramMalformedError": function() { return /* binding */ CramMalformedError; },
/* harmony export */   "CramSizeLimitError": function() { return /* binding */ CramSizeLimitError; },
/* harmony export */   "CramUnimplementedError": function() { return /* binding */ CramUnimplementedError; }
/* harmony export */ });
class CramError extends Error {
}
/** Error caused by encountering a part of the CRAM spec that has not yet been implemented */
class CramUnimplementedError extends Error {
}
/** An error caused by malformed data.  */
class CramMalformedError extends CramError {
}
/**
 * An error caused by attempting to read beyond the end of the defined data.
 */
class CramBufferOverrunError extends CramMalformedError {
}
/**
 * An error caused by data being too big, exceeding a size limit.
 */
class CramSizeLimitError extends CramError {
}
/**
 * An invalid argument was supplied to a cram-js method or object.
 */
class CramArgumentError extends CramError {
}
//# sourceMappingURL=errors.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/index.js":
/*!**********************************************!*\
  !*** ./node_modules/@gmod/cram/esm/index.js ***!
  \**********************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "CraiIndex": function() { return /* reexport safe */ _craiIndex__WEBPACK_IMPORTED_MODULE_2__["default"]; },
/* harmony export */   "CramFile": function() { return /* reexport safe */ _cramFile__WEBPACK_IMPORTED_MODULE_0__["default"]; },
/* harmony export */   "IndexedCramFile": function() { return /* reexport safe */ _indexedCramFile__WEBPACK_IMPORTED_MODULE_1__["default"]; }
/* harmony export */ });
/* harmony import */ var _cramFile__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./cramFile */ "./node_modules/@gmod/cram/esm/cramFile/index.js");
/* harmony import */ var _indexedCramFile__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./indexedCramFile */ "./node_modules/@gmod/cram/esm/indexedCramFile.js");
/* harmony import */ var _craiIndex__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./craiIndex */ "./node_modules/@gmod/cram/esm/craiIndex.js");




//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/indexedCramFile.js":
/*!********************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/indexedCramFile.js ***!
  \********************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ IndexedCramFile; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _cramFile__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./cramFile */ "./node_modules/@gmod/cram/esm/cramFile/index.js");


class IndexedCramFile {
    /**
     *
     * @param {object} args
     * @param {CramFile} args.cram
     * @param {Index-like} args.index object that supports getEntriesForRange(seqId,start,end) -> Promise[Array[index entries]]
     * @param {number} [args.cacheSize] optional maximum number of CRAM records to cache.  default 20,000
     * @param {number} [args.fetchSizeLimit] optional maximum number of bytes to fetch in a single getRecordsForRange call.  Default 3 MiB.
     * @param {boolean} [args.checkSequenceMD5] - default true. if false, disables verifying the MD5
     * checksum of the reference sequence underlying a slice. In some applications, this check can cause an inconvenient amount (many megabases) of sequences to be fetched.
     */
    constructor(args) {
        // { cram, index, seqFetch /* fasta, fastaIndex */ }) {
        if (args.cram) {
            this.cram = args.cram;
        }
        else {
            this.cram = new _cramFile__WEBPACK_IMPORTED_MODULE_1__["default"]({
                url: args.cramUrl,
                path: args.cramPath,
                filehandle: args.cramFilehandle,
                seqFetch: args.seqFetch,
                checkSequenceMD5: args.checkSequenceMD5,
                cacheSize: args.cacheSize,
            });
        }
        if (!(this.cram instanceof _cramFile__WEBPACK_IMPORTED_MODULE_1__["default"])) {
            throw new Error('invalid arguments: no cramfile');
        }
        this.index = args.index;
        if (!this.index.getEntriesForRange) {
            throw new Error('invalid arguments: not an index');
        }
        this.fetchSizeLimit = args.fetchSizeLimit || 3000000;
    }
    /**
     *
     * @param {number} seq numeric ID of the reference sequence
     * @param {number} start start of the range of interest. 1-based closed coordinates.
     * @param {number} end end of the range of interest. 1-based closed coordinates.
     * @returns {Promise[Array[CramRecord]]}
     */
    async getRecordsForRange(seq, start, end, opts = {}) {
        opts.viewAsPairs = opts.viewAsPairs || false;
        opts.pairAcrossChr = opts.pairAcrossChr || false;
        opts.maxInsertSize = opts.maxInsertSize || 200000;
        if (typeof seq === 'string') {
            // TODO: support string reference sequence names somehow
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramUnimplementedError('string sequence names not yet supported');
        }
        const seqId = seq;
        const slices = await this.index.getEntriesForRange(seqId, start, end);
        const totalSize = slices.map(s => s.sliceBytes).reduce((a, b) => a + b, 0);
        if (totalSize > this.fetchSizeLimit) {
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramSizeLimitError(`data size of ${totalSize.toLocaleString()} bytes exceeded fetch size limit of ${this.fetchSizeLimit.toLocaleString()} bytes`);
        }
        // TODO: do we need to merge or de-duplicate the blocks?
        // fetch all the slices and parse the feature data
        const filter = feature => feature.sequenceId === seq &&
            feature.alignmentStart <= end &&
            feature.alignmentStart + feature.lengthOnRef - 1 >= start;
        const sliceResults = await Promise.all(slices.map(slice => this.getRecordsInSlice(slice, filter)));
        let ret = Array.prototype.concat(...sliceResults);
        if (opts.viewAsPairs) {
            const readNames = {};
            const readIds = {};
            for (let i = 0; i < ret.length; i += 1) {
                const name = ret[i].readName;
                const id = ret[i].uniqueId;
                if (!readNames[name]) {
                    readNames[name] = 0;
                }
                readNames[name] += 1;
                readIds[id] = 1;
            }
            const unmatedPairs = {};
            Object.entries(readNames).forEach(([k, v]) => {
                if (v === 1) {
                    unmatedPairs[k] = true;
                }
            });
            const matePromises = [];
            for (let i = 0; i < ret.length; i += 1) {
                const name = ret[i].readName;
                if (unmatedPairs[name] &&
                    ret[i].mate &&
                    (ret[i].mate.sequenceId === seqId || opts.pairAcrossChr) &&
                    Math.abs(ret[i].alignmentStart - ret[i].mate.alignmentStart) <
                        opts.maxInsertSize) {
                    const mateSlices = this.index.getEntriesForRange(ret[i].mate.sequenceId, ret[i].mate.alignmentStart, ret[i].mate.alignmentStart + 1);
                    matePromises.push(mateSlices);
                }
            }
            const mateBlocks = await Promise.all(matePromises);
            let mateChunks = [];
            for (let i = 0; i < mateBlocks.length; i += 1) {
                mateChunks.push(...mateBlocks[i]);
            }
            // filter out duplicates
            mateChunks = mateChunks
                .sort((a, b) => a.toString().localeCompare(b.toString()))
                .filter((item, pos, ary) => !pos || item.toString() !== ary[pos - 1].toString());
            const mateRecordPromises = [];
            const mateFeatPromises = [];
            const mateTotalSize = mateChunks
                .map(s => s.sliceBytes)
                .reduce((a, b) => a + b, 0);
            if (mateTotalSize > this.fetchSizeLimit) {
                throw new Error(`mate data size of ${mateTotalSize.toLocaleString()} bytes exceeded fetch size limit of ${this.fetchSizeLimit.toLocaleString()} bytes`);
            }
            mateChunks.forEach(c => {
                let recordPromise = this.cram.featureCache.get(c.toString());
                if (!recordPromise) {
                    recordPromise = this.getRecordsInSlice(c, () => true);
                    this.cram.featureCache.set(c.toString(), recordPromise);
                }
                mateRecordPromises.push(recordPromise);
                const featPromise = recordPromise.then(feats => {
                    const mateRecs = [];
                    for (let i = 0; i < feats.length; i += 1) {
                        const feature = feats[i];
                        if (unmatedPairs[feature.readName] && !readIds[feature.uniqueId]) {
                            mateRecs.push(feature);
                        }
                    }
                    return mateRecs;
                });
                mateFeatPromises.push(featPromise);
            });
            const newMateFeats = await Promise.all(mateFeatPromises);
            if (newMateFeats.length) {
                const newMates = newMateFeats.reduce((result, current) => result.concat(current));
                ret = ret.concat(newMates);
            }
        }
        return ret;
    }
    getRecordsInSlice({ containerStart, sliceStart, sliceBytes }, filterFunction) {
        const container = this.cram.getContainerAtPosition(containerStart);
        const slice = container.getSlice(sliceStart, sliceBytes);
        return slice.getRecords(filterFunction);
    }
    /**
     *
     * @param {number} seqId
     * @returns {Promise} true if the CRAM file contains data for the given
     * reference sequence numerical ID
     */
    hasDataForReferenceSequence(seqId) {
        return this.index.hasDataForReferenceSequence(seqId);
    }
}
//# sourceMappingURL=indexedCramFile.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/io/bufferCache.js":
/*!*******************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/io/bufferCache.js ***!
  \*******************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ BufferCache; }
/* harmony export */ });
/* harmony import */ var quick_lru__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! quick-lru */ "./node_modules/quick-lru/index.js");
/* harmony import */ var quick_lru__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(quick_lru__WEBPACK_IMPORTED_MODULE_0__);

class BufferCache {
    constructor({ fetch, size = 10000000, chunkSize = 32768 }) {
        if (!fetch) {
            throw new Error('fetch function required');
        }
        this.fetch = fetch;
        this.chunkSize = chunkSize;
        this.lruCache = new (quick_lru__WEBPACK_IMPORTED_MODULE_0___default())({ maxSize: Math.floor(size / chunkSize) });
    }
    async get(outputBuffer, offset, length, position) {
        if (outputBuffer.length < offset + length) {
            throw new Error('output buffer not big enough for request');
        }
        // calculate the list of chunks involved in this fetch
        const firstChunk = Math.floor(position / this.chunkSize);
        const lastChunk = Math.floor((position + length) / this.chunkSize);
        // fetch them all as necessary
        const fetches = new Array(lastChunk - firstChunk + 1);
        for (let chunk = firstChunk; chunk <= lastChunk; chunk += 1) {
            fetches[chunk - firstChunk] = this._getChunk(chunk).then(data => ({
                data,
                chunkNumber: chunk,
            }));
        }
        // stitch together the response buffer using them
        const chunks = await Promise.all(fetches);
        const chunksOffset = position - chunks[0].chunkNumber * this.chunkSize;
        chunks.forEach(({ data, chunkNumber }) => {
            const chunkPositionStart = chunkNumber * this.chunkSize;
            let copyStart = 0;
            let copyEnd = this.chunkSize;
            let copyOffset = offset + (chunkNumber - firstChunk) * this.chunkSize - chunksOffset;
            if (chunkNumber === firstChunk) {
                copyOffset = offset;
                copyStart = chunksOffset;
            }
            if (chunkNumber === lastChunk) {
                copyEnd = position + length - chunkPositionStart;
            }
            data.copy(outputBuffer, copyOffset, copyStart, copyEnd);
        });
    }
    _getChunk(chunkNumber) {
        const cachedPromise = this.lruCache.get(chunkNumber);
        if (cachedPromise) {
            return cachedPromise;
        }
        const freshPromise = this.fetch(chunkNumber * this.chunkSize, this.chunkSize);
        this.lruCache.set(chunkNumber, freshPromise);
        return freshPromise;
    }
}
//# sourceMappingURL=bufferCache.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/io/index.js":
/*!*************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/io/index.js ***!
  \*************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "LocalFile": function() { return /* reexport default from dynamic */ _localFile__WEBPACK_IMPORTED_MODULE_2___default.a; },
/* harmony export */   "RemoteFile": function() { return /* reexport safe */ _remoteFile__WEBPACK_IMPORTED_MODULE_1__["default"]; },
/* harmony export */   "fromUrl": function() { return /* binding */ fromUrl; },
/* harmony export */   "open": function() { return /* binding */ open; }
/* harmony export */ });
/* harmony import */ var url__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! url */ "./node_modules/url/url.js");
/* harmony import */ var _remoteFile__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./remoteFile */ "./node_modules/@gmod/cram/esm/io/remoteFile.js");
/* harmony import */ var _localFile__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./localFile */ "?3e2e");
/* harmony import */ var _localFile__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_localFile__WEBPACK_IMPORTED_MODULE_2__);



function fromUrl(source) {
    const { protocol, pathname } = url__WEBPACK_IMPORTED_MODULE_0__.parse(source);
    if (protocol === 'file:') {
        return new (_localFile__WEBPACK_IMPORTED_MODULE_2___default())(unescape(pathname));
    }
    return new _remoteFile__WEBPACK_IMPORTED_MODULE_1__["default"](source);
}
function open(maybeUrl, maybePath, maybeFilehandle) {
    if (maybeFilehandle) {
        return maybeFilehandle;
    }
    if (maybeUrl) {
        return fromUrl(maybeUrl);
    }
    if (maybePath) {
        return new (_localFile__WEBPACK_IMPORTED_MODULE_2___default())(maybePath);
    }
    throw new Error('no url, path, or filehandle provided, cannot open');
}

//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/io/remoteFile.js":
/*!******************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/io/remoteFile.js ***!
  \******************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ RemoteFile; }
/* harmony export */ });
/* harmony import */ var cross_fetch__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! cross-fetch */ "./node_modules/cross-fetch/dist/browser-ponyfill.js");
/* harmony import */ var cross_fetch__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(cross_fetch__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _bufferCache__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./bufferCache */ "./node_modules/@gmod/cram/esm/io/bufferCache.js");
/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];


class RemoteFile {
    constructor(source) {
        this.position = 0;
        this.url = source;
        this.cache = new _bufferCache__WEBPACK_IMPORTED_MODULE_1__["default"]({
            fetch: (start, length) => this._fetch(start, length),
        });
    }
    async _fetch(position, length) {
        const headers = {};
        if (length < Infinity) {
            headers.range = `bytes=${position}-${position + length}`;
        }
        else if (length === Infinity && position !== 0) {
            headers.range = `bytes=${position}-`;
        }
        const response = await cross_fetch__WEBPACK_IMPORTED_MODULE_0___default()(this.url, {
            method: 'GET',
            headers,
            redirect: 'follow',
            mode: 'cors',
        });
        if ((response.status === 200 && position === 0) ||
            response.status === 206) {
            const nodeBuffer = Buffer.from(await response.arrayBuffer());
            // try to parse out the size of the remote file
            const sizeMatch = /\/(\d+)$/.exec(response.headers.get('content-range'));
            if (sizeMatch[1]) {
                this._stat = { size: parseInt(sizeMatch[1], 10) };
            }
            return nodeBuffer;
        }
        throw new Error(`HTTP ${response.status} fetching ${this.url}`);
    }
    read(buffer, offset = 0, length = Infinity, position = 0) {
        let readPosition = position;
        if (readPosition === null) {
            readPosition = this.position;
            this.position += length;
        }
        return this.cache.get(buffer, offset, length, position);
    }
    async readFile() {
        const response = await cross_fetch__WEBPACK_IMPORTED_MODULE_0___default()(this.url, {
            method: 'GET',
            redirect: 'follow',
            mode: 'cors',
        });
        return Buffer.from(await response.arrayBuffer());
    }
    async stat() {
        if (!this._stat) {
            const buf = Buffer.allocUnsafe(10);
            await this.read(buf, 0, 10, 0);
            if (!this._stat) {
                throw new Error(`unable to determine size of file at ${this.url}`);
            }
        }
        return this._stat;
    }
}
//# sourceMappingURL=remoteFile.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/rans/constants.js":
/*!*******************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/rans/constants.js ***!
  \*******************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "RANS_BYTE_L": function() { return /* binding */ RANS_BYTE_L; },
/* harmony export */   "TF_SHIFT": function() { return /* binding */ TF_SHIFT; },
/* harmony export */   "TOTFREQ": function() { return /* binding */ TOTFREQ; }
/* harmony export */ });
const TF_SHIFT = 12;
const TOTFREQ = 1 << TF_SHIFT;
const RANS_BYTE_L = 1 << 23;

//# sourceMappingURL=constants.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/rans/d04.js":
/*!*************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/rans/d04.js ***!
  \*************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ uncompress; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./constants */ "./node_modules/@gmod/cram/esm/rans/constants.js");
/* harmony import */ var _decoding__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./decoding */ "./node_modules/@gmod/cram/esm/rans/decoding.js");



function uncompress(
/* ByteBuffer */ input, 
/* Decoding.AriDecoder */ D, 
/* Decoding.Symbol[] */ syms, 
/* ByteBuffer */ out) {
    let rans0 = input.getInt();
    let rans1 = input.getInt();
    let rans2 = input.getInt();
    let rans3 = input.getInt();
    const /* int */ outputSize = out.remaining();
    const /* int */ outputEnd = outputSize & ~3;
    for (let i = 0; i < outputEnd; i += 4) {
        const /* byte */ c0 = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans0, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
        const /* byte */ c1 = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans1, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
        const /* byte */ c2 = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans2, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
        const /* byte */ c3 = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans3, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
        out.putAt(i, c0);
        out.putAt(i + 1, c1);
        out.putAt(i + 2, c2);
        out.putAt(i + 3, c3);
        rans0 = _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbolStep(rans0, syms[0xff & c0], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
        rans1 = _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbolStep(rans1, syms[0xff & c1], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
        rans2 = _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbolStep(rans2, syms[0xff & c2], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
        rans3 = _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbolStep(rans3, syms[0xff & c3], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
        rans0 = _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].renormalize(rans0, input);
        rans1 = _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].renormalize(rans1, input);
        rans2 = _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].renormalize(rans2, input);
        rans3 = _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].renormalize(rans3, input);
    }
    out.setPosition(outputEnd);
    let /* byte */ c;
    switch (outputSize & 3) {
        case 0:
            break;
        case 1:
            c = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans0, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
            _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbol(rans0, input, syms[0xff & c], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
            out.put(c);
            break;
        case 2:
            c = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans0, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
            _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbol(rans0, input, syms[0xff & c], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
            out.put(c);
            c = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans1, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
            _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbol(rans1, input, syms[0xff & c], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
            out.put(c);
            break;
        case 3:
            c = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans0, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
            _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbol(rans0, input, syms[0xff & c], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
            out.put(c);
            c = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans1, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
            _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbol(rans1, input, syms[0xff & c], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
            out.put(c);
            c = D.R[_decoding__WEBPACK_IMPORTED_MODULE_2__["default"].get(rans2, _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT)];
            _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].advanceSymbol(rans2, input, syms[0xff & c], _constants__WEBPACK_IMPORTED_MODULE_1__.TF_SHIFT);
            out.put(c);
            break;
        default:
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('invalid output size encountered during rANS decoding');
    }
    out.setPosition(0);
}
//# sourceMappingURL=d04.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/rans/d14.js":
/*!*************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/rans/d14.js ***!
  \*************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ uncompress; }
/* harmony export */ });
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./constants */ "./node_modules/@gmod/cram/esm/rans/constants.js");
/* harmony import */ var _decoding__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./decoding */ "./node_modules/@gmod/cram/esm/rans/decoding.js");


function uncompress(
/* ByteBuffer */ input, 
/* ByteBuffer */ output, 
/* Decoding.AriDecoder[] */ D, 
/* Decoding.Symbol[][] */ syms) {
    const /* int */ outputSize = output.remaining();
    let rans0 = input.getInt();
    let rans1 = input.getInt();
    let rans2 = input.getInt();
    let rans7 = input.getInt();
    const /* int */ isz4 = outputSize >> 2;
    let /* int */ i0 = 0;
    let /* int */ i1 = isz4;
    let /* int */ i2 = 2 * isz4;
    let /* int */ i7 = 3 * isz4;
    let /* int */ l0 = 0;
    let /* int */ l1 = 0;
    let /* int */ l2 = 0;
    let /* int */ l7 = 0;
    for (; i0 < isz4; i0 += 1, i1 += 1, i2 += 1, i7 += 1) {
        const /* int */ c0 = 0xff & D[l0].R[_decoding__WEBPACK_IMPORTED_MODULE_1__["default"].get(rans0, _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT)];
        const /* int */ c1 = 0xff & D[l1].R[_decoding__WEBPACK_IMPORTED_MODULE_1__["default"].get(rans1, _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT)];
        const /* int */ c2 = 0xff & D[l2].R[_decoding__WEBPACK_IMPORTED_MODULE_1__["default"].get(rans2, _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT)];
        const /* int */ c7 = 0xff & D[l7].R[_decoding__WEBPACK_IMPORTED_MODULE_1__["default"].get(rans7, _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT)];
        output.putAt(i0, c0);
        output.putAt(i1, c1);
        output.putAt(i2, c2);
        output.putAt(i7, c7);
        rans0 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].advanceSymbolStep(rans0, syms[l0][c0], _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT);
        rans1 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].advanceSymbolStep(rans1, syms[l1][c1], _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT);
        rans2 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].advanceSymbolStep(rans2, syms[l2][c2], _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT);
        rans7 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].advanceSymbolStep(rans7, syms[l7][c7], _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT);
        rans0 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].renormalize(rans0, input);
        rans1 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].renormalize(rans1, input);
        rans2 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].renormalize(rans2, input);
        rans7 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].renormalize(rans7, input);
        l0 = c0;
        l1 = c1;
        l2 = c2;
        l7 = c7;
    }
    // Remainder
    for (; i7 < outputSize; i7 += 1) {
        const /* int */ c7 = 0xff & D[l7].R[_decoding__WEBPACK_IMPORTED_MODULE_1__["default"].get(rans7, _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT)];
        output.putAt(i7, c7);
        rans7 = _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].advanceSymbol(rans7, input, syms[l7][c7], _constants__WEBPACK_IMPORTED_MODULE_0__.TF_SHIFT);
        l7 = c7;
    }
}
//# sourceMappingURL=d14.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/rans/decoding.js":
/*!******************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/rans/decoding.js ***!
  \******************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./constants */ "./node_modules/@gmod/cram/esm/rans/constants.js");


class FC {
    // int F, C;
    constructor() {
        this.F = undefined;
        this.C = undefined;
    }
}
class AriDecoder {
    // final FC[] fc = new FC[256];
    // byte[] R;
    constructor() {
        this.fc = new Array(256);
        for (let i = 0; i < this.fc.length; i += 1) {
            this.fc[i] = new FC();
        }
        this.R = null;
    }
}
class Symbol {
    // int start; // Start of range.
    // int freq; // Symbol frequency.
    constructor() {
        this.start = undefined;
        this.freq = undefined;
    }
}
// Initialize a decoder symbol to start "start" and frequency "freq"
function symbolInit(sym, start, freq) {
    if (!(start <= 1 << 16)) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`assertion failed: start <= 1<<16`);
    }
    if (!(freq <= (1 << 16) - start)) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`assertion failed: freq <= 1<<16`);
    }
    sym.start = start;
    sym.freq = freq;
}
// Advances in the bit stream by "popping" a single symbol with range start
// "start" and frequency "freq". All frequencies are assumed to sum to
// "1 << scaleBits".
// No renormalization or output happens.
/* private static int */ function advanceStep(
/* final int */ r, 
/* final int */ start, 
/* final int */ freq, 
/* final int */ scaleBits) {
    /* final int */ const mask = (1 << scaleBits) - 1;
    // s, x = D(x)
    return freq * (r >> scaleBits) + (r & mask) - start;
}
// Equivalent to RansDecAdvanceStep that takes a symbol.
/* static int  */ function advanceSymbolStep(
/* final int */ r, 
/* final RansDecSymbol */ sym, 
/* final int */ scaleBits) {
    return advanceStep(r, sym.start, sym.freq, scaleBits);
}
// Returns the current cumulative frequency (map it to a symbol yourself!)
/* static int */ function get(/* final int */ r, /* final int */ scaleBits) {
    return r & ((1 << scaleBits) - 1);
}
// Advances in the bit stream by "popping" a single symbol with range start
// "start" and frequency "freq". All frequencies are assumed to sum to
// "1 << scaleBits",
// and the resulting bytes get written to ptr (which is updated).
/* private static int */ function advance(
/* int */ r, 
/* final ByteBuffer */ pptr, 
/* final int */ start, 
/* final int */ freq, 
/* final int */ scaleBits) {
    /* final int */ const mask = (1 << scaleBits) - 1;
    // s, x = D(x)
    r = freq * (r >> scaleBits) + (r & mask) - start;
    // re-normalize
    if (r < _constants__WEBPACK_IMPORTED_MODULE_1__.RANS_BYTE_L) {
        do {
            /* final int */ const b = 0xff & pptr.get();
            r = (r << 8) | b;
        } while (r < _constants__WEBPACK_IMPORTED_MODULE_1__.RANS_BYTE_L);
    }
    return r;
}
// Equivalent to RansDecAdvance that takes a symbol.
/*  static int */ function advanceSymbol(
/* final int */ r, 
/* final ByteBuffer */ pptr, 
/* final RansDecSymbol */ sym, 
/* final int */ scaleBits) {
    return advance(r, pptr, sym.start, sym.freq, scaleBits);
}
// Re-normalize.
/*  static int */ function renormalize(
/* int */ r, 
/* final ByteBuffer */ pptr) {
    // re-normalize
    if (r < _constants__WEBPACK_IMPORTED_MODULE_1__.RANS_BYTE_L) {
        do {
            r = (r << 8) | (0xff & pptr.get());
        } while (r < _constants__WEBPACK_IMPORTED_MODULE_1__.RANS_BYTE_L);
    }
    return r;
}
const Decode = {
    FC,
    AriDecoder,
    Symbol,
    symbolInit,
    advanceStep,
    advanceSymbolStep,
    get,
    advanceSymbol,
    renormalize,
};
/* harmony default export */ __webpack_exports__["default"] = (Decode);
//# sourceMappingURL=decoding.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/rans/frequencies.js":
/*!*********************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/rans/frequencies.js ***!
  \*********************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "readStatsO0": function() { return /* binding */ readStatsO0; },
/* harmony export */   "readStatsO1": function() { return /* binding */ readStatsO1; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./constants */ "./node_modules/@gmod/cram/esm/rans/constants.js");
/* harmony import */ var _decoding__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./decoding */ "./node_modules/@gmod/cram/esm/rans/decoding.js");



function assert(result) {
    if (!result) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('assertion failed');
    }
}
function readStatsO0(
/* ByteBuffer */ cp, 
/* Decoding.AriDecoder */ decoder, 
/* Decoding.RansDecSymbol[] */ syms) {
    // Pre-compute reverse lookup of frequency.
    let rle = 0;
    let x = 0;
    let j = cp.get() & 0xff;
    do {
        if (decoder.fc[j] == null) {
            decoder.fc[j] = new _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].FC();
        }
        decoder.fc[j].F = cp.get() & 0xff;
        if (decoder.fc[j].F >= 128) {
            decoder.fc[j].F &= ~128;
            decoder.fc[j].F = ((decoder.fc[j].F & 127) << 8) | (cp.get() & 0xff);
        }
        decoder.fc[j].C = x;
        _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].symbolInit(syms[j], decoder.fc[j].C, decoder.fc[j].F);
        /* Build reverse lookup table */
        if (!decoder.R) {
            decoder.R = new Array(_constants__WEBPACK_IMPORTED_MODULE_1__.TOTFREQ);
        }
        decoder.R.fill(j, x, x + decoder.fc[j].F);
        x += decoder.fc[j].F;
        if (rle === 0 && j + 1 === (0xff & cp.getByteAt(cp.position()))) {
            j = cp.get() & 0xff;
            rle = cp.get() & 0xff;
        }
        else if (rle !== 0) {
            rle -= 1;
            j += 1;
        }
        else {
            j = cp.get() & 0xff;
        }
    } while (j !== 0);
    assert(x < _constants__WEBPACK_IMPORTED_MODULE_1__.TOTFREQ);
}
function readStatsO1(
/* ByteBuffer */ cp, 
/*  Decoding.AriDecoder[] */ D, 
/* Decoding.RansDecSymbol[][] */ syms) {
    let rlei = 0;
    let i = 0xff & cp.get();
    do {
        let rlej = 0;
        let x = 0;
        let j = 0xff & cp.get();
        if (D[i] == null) {
            D[i] = new _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].AriDecoder();
        }
        do {
            if (D[i].fc[j] == null) {
                D[i].fc[j] = new _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].FC();
            }
            D[i].fc[j].F = 0xff & cp.get();
            if (D[i].fc[j].F >= 128) {
                D[i].fc[j].F &= ~128;
                D[i].fc[j].F = ((D[i].fc[j].F & 127) << 8) | (0xff & cp.get());
            }
            D[i].fc[j].C = x;
            if (D[i].fc[j].F === 0) {
                D[i].fc[j].F = _constants__WEBPACK_IMPORTED_MODULE_1__.TOTFREQ;
            }
            if (syms[i][j] == null) {
                syms[i][j] = new _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].RansDecSymbol();
            }
            _decoding__WEBPACK_IMPORTED_MODULE_2__["default"].symbolInit(syms[i][j], D[i].fc[j].C, D[i].fc[j].F);
            /* Build reverse lookup table */
            if (D[i].R == null) {
                D[i].R = new Array(_constants__WEBPACK_IMPORTED_MODULE_1__.TOTFREQ);
            }
            D[i].R.fill(j, x, x + D[i].fc[j].F);
            x += D[i].fc[j].F;
            assert(x <= _constants__WEBPACK_IMPORTED_MODULE_1__.TOTFREQ);
            if (rlej === 0 && j + 1 === (0xff & cp.getByteAt(cp.position()))) {
                j = 0xff & cp.get();
                rlej = 0xff & cp.get();
            }
            else if (rlej !== 0) {
                rlej -= 1;
                j += 1;
            }
            else {
                j = 0xff & cp.get();
            }
        } while (j !== 0);
        if (rlei === 0 && i + 1 === (0xff & cp.getByteAt(cp.position()))) {
            i = 0xff & cp.get();
            rlei = 0xff & cp.get();
        }
        else if (rlei !== 0) {
            rlei -= 1;
            i += 1;
        }
        else {
            i = 0xff & cp.get();
        }
    } while (i !== 0);
}
//# sourceMappingURL=frequencies.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/rans/index.js":
/*!***************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/rans/index.js ***!
  \***************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ uncompress; }
/* harmony export */ });
/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../errors */ "./node_modules/@gmod/cram/esm/errors.js");
/* harmony import */ var _decoding__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./decoding */ "./node_modules/@gmod/cram/esm/rans/decoding.js");
/* harmony import */ var _frequencies__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./frequencies */ "./node_modules/@gmod/cram/esm/rans/frequencies.js");
/* harmony import */ var _d04__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./d04 */ "./node_modules/@gmod/cram/esm/rans/d04.js");
/* harmony import */ var _d14__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./d14 */ "./node_modules/@gmod/cram/esm/rans/d14.js");
/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];





// const /* int */ ORDER_BYTE_LENGTH = 1
// const /* int */ COMPRESSED_BYTE_LENGTH = 4
const /* int */ RAW_BYTE_LENGTH = 4;
// const /* int */ PREFIX_BYTE_LENGTH =
//   ORDER_BYTE_LENGTH + COMPRESSED_BYTE_LENGTH + RAW_BYTE_LENGTH
// enum ORDER {
//     ZERO, ONE;
//     static ORDER fromInt(const /* int */ value) {
//         try {
//             return ORDER.values()[value];
//         } catch (const ArrayIndexOutOfBoundsException e) {
//             throw new RuntimeException("Unknown rANS order: " + value);
//         }
//     }
// }
// static ByteBuffer compress(const ByteBuffer input, const ORDER order, const ByteBuffer out) {
//     if (input.remaining() == 0)
//         return EMPTY_BUFFER;
//     if (input.remaining() < 4)
//         return encode_order0_way4(input, out);
//     switch (order) {
//         case ZERO:
//             return encode_order0_way4(input, out);
//         case ONE:
//             return encode_order1_way4(input, out);
//         default:
//             throw new RuntimeException("Unknown rANS order: " + order);
//     }
// }
// static /* ByteBuffer */ allocateIfNeeded(/* const int */ in_size,
//                                            /* const ByteBuffer */ out_buf) {
//     const /* int */ compressedSize = (/* int */) (1.05 * in_size + 257 * 257 * 3 + 4);
//     if (out_buf == null)
//         return ByteBuffer.allocate(compressedSize);
//     if (out_buf.remaining() < compressedSize)
//         throw new RuntimeException("Insufficient buffer size.");
//     out_buf.order(ByteOrder.LITTLE_ENDIAN);
//     return out_buf;
// }
// static ByteBuffer encode_order0_way4(const ByteBuffer input,
//                                              ByteBuffer out_buf) {
//     const /* int */ in_size = input.remaining();
//     out_buf = allocateIfNeeded(in_size, out_buf);
//     const /* int */ freqTableStart = PREFIX_BYTE_LENGTH;
//     out_buf.position(freqTableStart);
//     const /* int */[] F = Frequencies.calcFrequencies_o0(in);
//     const RansEncSymbol[] syms = Frequencies.buildSyms_o0(F);
//     const ByteBuffer cp = out_buf.slice();
//     const /* int */ frequencyTable_size = Frequencies.writeFrequencies_o0(cp, F);
//     input.rewind();
//     const /* int */ compressedBlob_size = E04.compress(input, syms, cp);
//     finalizeCompressed(0, out_buf, in_size, frequencyTable_size,
//             compressedBlob_size);
//     return out_buf;
// }
// static ByteBuffer encode_order1_way4(const ByteBuffer input,
//                                              ByteBuffer out_buf) {
//     const /* int */ in_size = input.remaining();
//     out_buf = allocateIfNeeded(in_size, out_buf);
//     const /* int */ freqTableStart = PREFIX_BYTE_LENGTH;
//     out_buf.position(freqTableStart);
//     const /* int */[][] F = Frequencies.calcFrequencies_o1(in);
//     const RansEncSymbol[][] syms = Frequencies.buildSyms_o1(F);
//     const ByteBuffer cp = out_buf.slice();
//     const /* int */ frequencyTable_size = Frequencies.writeFrequencies_o1(cp, F);
//     input.rewind();
//     const /* int */ compressedBlob_size = E14.compress(input, syms, cp);
//     finalizeCompressed(1, out_buf, in_size, frequencyTable_size,
//             compressedBlob_size);
//     return out_buf;
// }
// static void finalizeCompressed(const /* int */ order, const ByteBuffer out_buf,
//                                        const /* int */ in_size, const /* int */ frequencyTable_size, const /* int */ compressedBlob_size) {
//     out_buf.limit(PREFIX_BYTE_LENGTH + frequencyTable_size
//             + compressedBlob_size);
//     out_buf.put(0, (byte) order);
//     out_buf.order(ByteOrder.LITTLE_ENDIAN);
//     const /* int */ compressedSizeOffset = ORDER_BYTE_LENGTH;
//     out_buf.putInt(compressedSizeOffset, frequencyTable_size
//             + compressedBlob_size);
//     const /* int */ rawSizeOffset = ORDER_BYTE_LENGTH + COMPRESSED_BYTE_LENGTH;
//     out_buf.putInt(rawSizeOffset, in_size);
//     out_buf.rewind();
// }
function uncompressOrder0Way4(
/* const ByteBuffer  */ input, 
/* const ByteBuffer  */ out) {
    // input.order(ByteOrder.LITTLE_ENDIAN);
    const D = new _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].AriDecoder();
    const syms = new Array(256);
    for (let i = 0; i < syms.length; i += 1) {
        syms[i] = new _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].Symbol();
    }
    (0,_frequencies__WEBPACK_IMPORTED_MODULE_2__.readStatsO0)(input, D, syms);
    (0,_d04__WEBPACK_IMPORTED_MODULE_3__["default"])(input, D, syms, out);
    return out;
}
function uncompressOrder1Way4(
/* const ByteBuffer */ input, 
/* const ByteBuffer */ output) {
    const D = new Array(256);
    for (let i = 0; i < D.length; i += 1) {
        D[i] = new _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].AriDecoder();
    }
    const /* Decoding.RansDecSymbol[][]  */ syms = new Array(256);
    for (let i = 0; i < syms.length; i += 1) {
        syms[i] = new Array(256);
        for (let j = 0; j < syms[i].length; j += 1) {
            syms[i][j] = new _decoding__WEBPACK_IMPORTED_MODULE_1__["default"].Symbol();
        }
    }
    (0,_frequencies__WEBPACK_IMPORTED_MODULE_2__.readStatsO1)(input, D, syms);
    (0,_d14__WEBPACK_IMPORTED_MODULE_4__["default"])(input, output, D, syms);
    return output;
}
/* compat layer to make a node buffer act like a java ByteBuffer */
class ByteBuffer {
    constructor(nodeBuffer, initialInputPosition = 0) {
        this._buffer = nodeBuffer;
        this._position = initialInputPosition;
        this.length = nodeBuffer.length;
    }
    get() {
        const b = this._buffer[this._position];
        this._position += 1;
        return b;
    }
    getByte() {
        return this.get();
    }
    getByteAt(position) {
        return this._buffer[position];
    }
    position() {
        return this._position;
    }
    put(val) {
        this._buffer[this._position] = val;
        this._position += 1;
        return val;
    }
    putAt(position, val) {
        this._buffer[position] = val;
        return val;
    }
    setPosition(pos) {
        this._position = pos;
        return pos;
    }
    getInt() {
        const i = this._buffer.readInt32LE(this._position);
        this._position += 4;
        return i;
    }
    remaining() {
        return this._buffer.length - this._position;
    }
}
// static /* const */ ByteBuffer EMPTY_BUFFER = ByteBuffer.allocate(0);
function uncompress(inputBuffer, outputBuffer, initialInputPosition = 0) {
    if (inputBuffer.length === 0) {
        outputBuffer.fill(0);
        return outputBuffer;
    }
    const input = new ByteBuffer(inputBuffer, initialInputPosition);
    // input.order(ByteOrder.LITTLE_ENDIAN);
    const order = input.get();
    if (order !== 0 && order !== 1) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`Invalid rANS order ${order}`);
    }
    const /* int */ inputSize = input.getInt();
    if (inputSize !== input.remaining() - RAW_BYTE_LENGTH) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError('Incorrect input length.');
    }
    const /* int */ outputSize = input.getInt();
    const output = new ByteBuffer(outputBuffer || Buffer.allocUnsafe(outputSize));
    // TODO output.limit(outputSize)
    if (output.length < outputSize) {
        throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`Output buffer too small to fit ${outputSize} bytes.`);
    }
    switch (order) {
        case 0:
            return uncompressOrder0Way4(input, output);
        case 1:
            return uncompressOrder1Way4(input, output);
        default:
            throw new _errors__WEBPACK_IMPORTED_MODULE_0__.CramMalformedError(`Invalid rANS order: ${order}`);
    }
}
//# sourceMappingURL=index.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/sam.js":
/*!********************************************!*\
  !*** ./node_modules/@gmod/cram/esm/sam.js ***!
  \********************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "parseHeaderText": function() { return /* binding */ parseHeaderText; }
/* harmony export */ });
function parseHeaderText(text) {
    const lines = text.split(/\r?\n/);
    const data = [];
    lines.forEach(line => {
        const [tag, ...fields] = line.split(/\t/);
        const parsedFields = fields.map(f => {
            const [fieldTag, value] = f.split(':', 2);
            return { tag: fieldTag, value };
        });
        if (tag) {
            data.push({ tag: tag.substr(1), data: parsedFields });
        }
    });
    return data;
}
//# sourceMappingURL=sam.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/esm/unzip-pako.js":
/*!***************************************************!*\
  !*** ./node_modules/@gmod/cram/esm/unzip-pako.js ***!
  \***************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "unzip": function() { return /* binding */ unzip; }
/* harmony export */ });
/* harmony import */ var pako__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! pako */ "./node_modules/@gmod/cram/node_modules/pako/index.js");
/* harmony import */ var pako__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(pako__WEBPACK_IMPORTED_MODULE_0__);
/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];

function unzip(input) {
    return Buffer.from((0,pako__WEBPACK_IMPORTED_MODULE_0__.inflate)(input));
}
//# sourceMappingURL=unzip-pako.js.map

/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/index.js":
/*!************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/index.js ***!
  \************************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";
// Top level file is just a mixin of submodules & constants


var assign    = (__webpack_require__(/*! ./lib/utils/common */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js").assign);

var deflate   = __webpack_require__(/*! ./lib/deflate */ "./node_modules/@gmod/cram/node_modules/pako/lib/deflate.js");
var inflate   = __webpack_require__(/*! ./lib/inflate */ "./node_modules/@gmod/cram/node_modules/pako/lib/inflate.js");
var constants = __webpack_require__(/*! ./lib/zlib/constants */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/constants.js");

var pako = {};

assign(pako, deflate, inflate, constants);

module.exports = pako;


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/deflate.js":
/*!******************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/deflate.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";



var zlib_deflate = __webpack_require__(/*! ./zlib/deflate */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/deflate.js");
var utils        = __webpack_require__(/*! ./utils/common */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js");
var strings      = __webpack_require__(/*! ./utils/strings */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/strings.js");
var msg          = __webpack_require__(/*! ./zlib/messages */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/messages.js");
var ZStream      = __webpack_require__(/*! ./zlib/zstream */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/zstream.js");

var toString = Object.prototype.toString;

/* Public constants ==========================================================*/
/* ===========================================================================*/

var Z_NO_FLUSH      = 0;
var Z_FINISH        = 4;

var Z_OK            = 0;
var Z_STREAM_END    = 1;
var Z_SYNC_FLUSH    = 2;

var Z_DEFAULT_COMPRESSION = -1;

var Z_DEFAULT_STRATEGY    = 0;

var Z_DEFLATED  = 8;

/* ===========================================================================*/


/**
 * class Deflate
 *
 * Generic JS-style wrapper for zlib calls. If you don't need
 * streaming behaviour - use more simple functions: [[deflate]],
 * [[deflateRaw]] and [[gzip]].
 **/

/* internal
 * Deflate.chunks -> Array
 *
 * Chunks of output data, if [[Deflate#onData]] not overridden.
 **/

/**
 * Deflate.result -> Uint8Array|Array
 *
 * Compressed result, generated by default [[Deflate#onData]]
 * and [[Deflate#onEnd]] handlers. Filled after you push last chunk
 * (call [[Deflate#push]] with `Z_FINISH` / `true` param)  or if you
 * push a chunk with explicit flush (call [[Deflate#push]] with
 * `Z_SYNC_FLUSH` param).
 **/

/**
 * Deflate.err -> Number
 *
 * Error code after deflate finished. 0 (Z_OK) on success.
 * You will not need it in real life, because deflate errors
 * are possible only on wrong options or bad `onData` / `onEnd`
 * custom handlers.
 **/

/**
 * Deflate.msg -> String
 *
 * Error message, if [[Deflate.err]] != 0
 **/


/**
 * new Deflate(options)
 * - options (Object): zlib deflate options.
 *
 * Creates new deflator instance with specified params. Throws exception
 * on bad params. Supported options:
 *
 * - `level`
 * - `windowBits`
 * - `memLevel`
 * - `strategy`
 * - `dictionary`
 *
 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
 * for more information on these.
 *
 * Additional options, for internal needs:
 *
 * - `chunkSize` - size of generated data chunks (16K by default)
 * - `raw` (Boolean) - do raw deflate
 * - `gzip` (Boolean) - create gzip wrapper
 * - `to` (String) - if equal to 'string', then result will be "binary string"
 *    (each char code [0..255])
 * - `header` (Object) - custom header for gzip
 *   - `text` (Boolean) - true if compressed data believed to be text
 *   - `time` (Number) - modification time, unix timestamp
 *   - `os` (Number) - operation system code
 *   - `extra` (Array) - array of bytes with extra data (max 65536)
 *   - `name` (String) - file name (binary string)
 *   - `comment` (String) - comment (binary string)
 *   - `hcrc` (Boolean) - true if header crc should be added
 *
 * ##### Example:
 *
 * ```javascript
 * var pako = require('pako')
 *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])
 *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);
 *
 * var deflate = new pako.Deflate({ level: 3});
 *
 * deflate.push(chunk1, false);
 * deflate.push(chunk2, true);  // true -> last chunk
 *
 * if (deflate.err) { throw new Error(deflate.err); }
 *
 * console.log(deflate.result);
 * ```
 **/
function Deflate(options) {
  if (!(this instanceof Deflate)) return new Deflate(options);

  this.options = utils.assign({
    level: Z_DEFAULT_COMPRESSION,
    method: Z_DEFLATED,
    chunkSize: 16384,
    windowBits: 15,
    memLevel: 8,
    strategy: Z_DEFAULT_STRATEGY,
    to: ''
  }, options || {});

  var opt = this.options;

  if (opt.raw && (opt.windowBits > 0)) {
    opt.windowBits = -opt.windowBits;
  }

  else if (opt.gzip && (opt.windowBits > 0) && (opt.windowBits < 16)) {
    opt.windowBits += 16;
  }

  this.err    = 0;      // error code, if happens (0 = Z_OK)
  this.msg    = '';     // error message
  this.ended  = false;  // used to avoid multiple onEnd() calls
  this.chunks = [];     // chunks of compressed data

  this.strm = new ZStream();
  this.strm.avail_out = 0;

  var status = zlib_deflate.deflateInit2(
    this.strm,
    opt.level,
    opt.method,
    opt.windowBits,
    opt.memLevel,
    opt.strategy
  );

  if (status !== Z_OK) {
    throw new Error(msg[status]);
  }

  if (opt.header) {
    zlib_deflate.deflateSetHeader(this.strm, opt.header);
  }

  if (opt.dictionary) {
    var dict;
    // Convert data if needed
    if (typeof opt.dictionary === 'string') {
      // If we need to compress text, change encoding to utf8.
      dict = strings.string2buf(opt.dictionary);
    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {
      dict = new Uint8Array(opt.dictionary);
    } else {
      dict = opt.dictionary;
    }

    status = zlib_deflate.deflateSetDictionary(this.strm, dict);

    if (status !== Z_OK) {
      throw new Error(msg[status]);
    }

    this._dict_set = true;
  }
}

/**
 * Deflate#push(data[, mode]) -> Boolean
 * - data (Uint8Array|Array|ArrayBuffer|String): input data. Strings will be
 *   converted to utf8 byte sequence.
 * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.
 *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.
 *
 * Sends input data to deflate pipe, generating [[Deflate#onData]] calls with
 * new compressed chunks. Returns `true` on success. The last data block must have
 * mode Z_FINISH (or `true`). That will flush internal pending buffers and call
 * [[Deflate#onEnd]]. For interim explicit flushes (without ending the stream) you
 * can use mode Z_SYNC_FLUSH, keeping the compression context.
 *
 * On fail call [[Deflate#onEnd]] with error code and return false.
 *
 * We strongly recommend to use `Uint8Array` on input for best speed (output
 * array format is detected automatically). Also, don't skip last param and always
 * use the same type in your code (boolean or number). That will improve JS speed.
 *
 * For regular `Array`-s make sure all elements are [0..255].
 *
 * ##### Example
 *
 * ```javascript
 * push(chunk, false); // push one of data chunks
 * ...
 * push(chunk, true);  // push last chunk
 * ```
 **/
Deflate.prototype.push = function (data, mode) {
  var strm = this.strm;
  var chunkSize = this.options.chunkSize;
  var status, _mode;

  if (this.ended) { return false; }

  _mode = (mode === ~~mode) ? mode : ((mode === true) ? Z_FINISH : Z_NO_FLUSH);

  // Convert data if needed
  if (typeof data === 'string') {
    // If we need to compress text, change encoding to utf8.
    strm.input = strings.string2buf(data);
  } else if (toString.call(data) === '[object ArrayBuffer]') {
    strm.input = new Uint8Array(data);
  } else {
    strm.input = data;
  }

  strm.next_in = 0;
  strm.avail_in = strm.input.length;

  do {
    if (strm.avail_out === 0) {
      strm.output = new utils.Buf8(chunkSize);
      strm.next_out = 0;
      strm.avail_out = chunkSize;
    }
    status = zlib_deflate.deflate(strm, _mode);    /* no bad return value */

    if (status !== Z_STREAM_END && status !== Z_OK) {
      this.onEnd(status);
      this.ended = true;
      return false;
    }
    if (strm.avail_out === 0 || (strm.avail_in === 0 && (_mode === Z_FINISH || _mode === Z_SYNC_FLUSH))) {
      if (this.options.to === 'string') {
        this.onData(strings.buf2binstring(utils.shrinkBuf(strm.output, strm.next_out)));
      } else {
        this.onData(utils.shrinkBuf(strm.output, strm.next_out));
      }
    }
  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== Z_STREAM_END);

  // Finalize on the last chunk.
  if (_mode === Z_FINISH) {
    status = zlib_deflate.deflateEnd(this.strm);
    this.onEnd(status);
    this.ended = true;
    return status === Z_OK;
  }

  // callback interim results if Z_SYNC_FLUSH.
  if (_mode === Z_SYNC_FLUSH) {
    this.onEnd(Z_OK);
    strm.avail_out = 0;
    return true;
  }

  return true;
};


/**
 * Deflate#onData(chunk) -> Void
 * - chunk (Uint8Array|Array|String): output data. Type of array depends
 *   on js engine support. When string output requested, each chunk
 *   will be string.
 *
 * By default, stores data blocks in `chunks[]` property and glue
 * those in `onEnd`. Override this handler, if you need another behaviour.
 **/
Deflate.prototype.onData = function (chunk) {
  this.chunks.push(chunk);
};


/**
 * Deflate#onEnd(status) -> Void
 * - status (Number): deflate status. 0 (Z_OK) on success,
 *   other if not.
 *
 * Called once after you tell deflate that the input stream is
 * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)
 * or if an error happened. By default - join collected chunks,
 * free memory and fill `results` / `err` properties.
 **/
Deflate.prototype.onEnd = function (status) {
  // On success - join
  if (status === Z_OK) {
    if (this.options.to === 'string') {
      this.result = this.chunks.join('');
    } else {
      this.result = utils.flattenChunks(this.chunks);
    }
  }
  this.chunks = [];
  this.err = status;
  this.msg = this.strm.msg;
};


/**
 * deflate(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to compress.
 * - options (Object): zlib deflate options.
 *
 * Compress `data` with deflate algorithm and `options`.
 *
 * Supported options are:
 *
 * - level
 * - windowBits
 * - memLevel
 * - strategy
 * - dictionary
 *
 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
 * for more information on these.
 *
 * Sugar (options):
 *
 * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify
 *   negative windowBits implicitly.
 * - `to` (String) - if equal to 'string', then result will be "binary string"
 *    (each char code [0..255])
 *
 * ##### Example:
 *
 * ```javascript
 * var pako = require('pako')
 *   , data = Uint8Array([1,2,3,4,5,6,7,8,9]);
 *
 * console.log(pako.deflate(data));
 * ```
 **/
function deflate(input, options) {
  var deflator = new Deflate(options);

  deflator.push(input, true);

  // That will never happens, if you don't cheat with options :)
  if (deflator.err) { throw deflator.msg || msg[deflator.err]; }

  return deflator.result;
}


/**
 * deflateRaw(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to compress.
 * - options (Object): zlib deflate options.
 *
 * The same as [[deflate]], but creates raw data, without wrapper
 * (header and adler32 crc).
 **/
function deflateRaw(input, options) {
  options = options || {};
  options.raw = true;
  return deflate(input, options);
}


/**
 * gzip(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to compress.
 * - options (Object): zlib deflate options.
 *
 * The same as [[deflate]], but create gzip wrapper instead of
 * deflate one.
 **/
function gzip(input, options) {
  options = options || {};
  options.gzip = true;
  return deflate(input, options);
}


exports.Deflate = Deflate;
exports.deflate = deflate;
exports.deflateRaw = deflateRaw;
exports.gzip = gzip;


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/inflate.js":
/*!******************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/inflate.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";



var zlib_inflate = __webpack_require__(/*! ./zlib/inflate */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inflate.js");
var utils        = __webpack_require__(/*! ./utils/common */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js");
var strings      = __webpack_require__(/*! ./utils/strings */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/strings.js");
var c            = __webpack_require__(/*! ./zlib/constants */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/constants.js");
var msg          = __webpack_require__(/*! ./zlib/messages */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/messages.js");
var ZStream      = __webpack_require__(/*! ./zlib/zstream */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/zstream.js");
var GZheader     = __webpack_require__(/*! ./zlib/gzheader */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/gzheader.js");

var toString = Object.prototype.toString;

/**
 * class Inflate
 *
 * Generic JS-style wrapper for zlib calls. If you don't need
 * streaming behaviour - use more simple functions: [[inflate]]
 * and [[inflateRaw]].
 **/

/* internal
 * inflate.chunks -> Array
 *
 * Chunks of output data, if [[Inflate#onData]] not overridden.
 **/

/**
 * Inflate.result -> Uint8Array|Array|String
 *
 * Uncompressed result, generated by default [[Inflate#onData]]
 * and [[Inflate#onEnd]] handlers. Filled after you push last chunk
 * (call [[Inflate#push]] with `Z_FINISH` / `true` param) or if you
 * push a chunk with explicit flush (call [[Inflate#push]] with
 * `Z_SYNC_FLUSH` param).
 **/

/**
 * Inflate.err -> Number
 *
 * Error code after inflate finished. 0 (Z_OK) on success.
 * Should be checked if broken data possible.
 **/

/**
 * Inflate.msg -> String
 *
 * Error message, if [[Inflate.err]] != 0
 **/


/**
 * new Inflate(options)
 * - options (Object): zlib inflate options.
 *
 * Creates new inflator instance with specified params. Throws exception
 * on bad params. Supported options:
 *
 * - `windowBits`
 * - `dictionary`
 *
 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
 * for more information on these.
 *
 * Additional options, for internal needs:
 *
 * - `chunkSize` - size of generated data chunks (16K by default)
 * - `raw` (Boolean) - do raw inflate
 * - `to` (String) - if equal to 'string', then result will be converted
 *   from utf8 to utf16 (javascript) string. When string output requested,
 *   chunk length can differ from `chunkSize`, depending on content.
 *
 * By default, when no options set, autodetect deflate/gzip data format via
 * wrapper header.
 *
 * ##### Example:
 *
 * ```javascript
 * var pako = require('pako')
 *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])
 *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);
 *
 * var inflate = new pako.Inflate({ level: 3});
 *
 * inflate.push(chunk1, false);
 * inflate.push(chunk2, true);  // true -> last chunk
 *
 * if (inflate.err) { throw new Error(inflate.err); }
 *
 * console.log(inflate.result);
 * ```
 **/
function Inflate(options) {
  if (!(this instanceof Inflate)) return new Inflate(options);

  this.options = utils.assign({
    chunkSize: 16384,
    windowBits: 0,
    to: ''
  }, options || {});

  var opt = this.options;

  // Force window size for `raw` data, if not set directly,
  // because we have no header for autodetect.
  if (opt.raw && (opt.windowBits >= 0) && (opt.windowBits < 16)) {
    opt.windowBits = -opt.windowBits;
    if (opt.windowBits === 0) { opt.windowBits = -15; }
  }

  // If `windowBits` not defined (and mode not raw) - set autodetect flag for gzip/deflate
  if ((opt.windowBits >= 0) && (opt.windowBits < 16) &&
      !(options && options.windowBits)) {
    opt.windowBits += 32;
  }

  // Gzip header has no info about windows size, we can do autodetect only
  // for deflate. So, if window size not set, force it to max when gzip possible
  if ((opt.windowBits > 15) && (opt.windowBits < 48)) {
    // bit 3 (16) -> gzipped data
    // bit 4 (32) -> autodetect gzip/deflate
    if ((opt.windowBits & 15) === 0) {
      opt.windowBits |= 15;
    }
  }

  this.err    = 0;      // error code, if happens (0 = Z_OK)
  this.msg    = '';     // error message
  this.ended  = false;  // used to avoid multiple onEnd() calls
  this.chunks = [];     // chunks of compressed data

  this.strm   = new ZStream();
  this.strm.avail_out = 0;

  var status  = zlib_inflate.inflateInit2(
    this.strm,
    opt.windowBits
  );

  if (status !== c.Z_OK) {
    throw new Error(msg[status]);
  }

  this.header = new GZheader();

  zlib_inflate.inflateGetHeader(this.strm, this.header);

  // Setup dictionary
  if (opt.dictionary) {
    // Convert data if needed
    if (typeof opt.dictionary === 'string') {
      opt.dictionary = strings.string2buf(opt.dictionary);
    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {
      opt.dictionary = new Uint8Array(opt.dictionary);
    }
    if (opt.raw) { //In raw mode we need to set the dictionary early
      status = zlib_inflate.inflateSetDictionary(this.strm, opt.dictionary);
      if (status !== c.Z_OK) {
        throw new Error(msg[status]);
      }
    }
  }
}

/**
 * Inflate#push(data[, mode]) -> Boolean
 * - data (Uint8Array|Array|ArrayBuffer|String): input data
 * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.
 *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.
 *
 * Sends input data to inflate pipe, generating [[Inflate#onData]] calls with
 * new output chunks. Returns `true` on success. The last data block must have
 * mode Z_FINISH (or `true`). That will flush internal pending buffers and call
 * [[Inflate#onEnd]]. For interim explicit flushes (without ending the stream) you
 * can use mode Z_SYNC_FLUSH, keeping the decompression context.
 *
 * On fail call [[Inflate#onEnd]] with error code and return false.
 *
 * We strongly recommend to use `Uint8Array` on input for best speed (output
 * format is detected automatically). Also, don't skip last param and always
 * use the same type in your code (boolean or number). That will improve JS speed.
 *
 * For regular `Array`-s make sure all elements are [0..255].
 *
 * ##### Example
 *
 * ```javascript
 * push(chunk, false); // push one of data chunks
 * ...
 * push(chunk, true);  // push last chunk
 * ```
 **/
Inflate.prototype.push = function (data, mode) {
  var strm = this.strm;
  var chunkSize = this.options.chunkSize;
  var dictionary = this.options.dictionary;
  var status, _mode;
  var next_out_utf8, tail, utf8str;

  // Flag to properly process Z_BUF_ERROR on testing inflate call
  // when we check that all output data was flushed.
  var allowBufError = false;

  if (this.ended) { return false; }
  _mode = (mode === ~~mode) ? mode : ((mode === true) ? c.Z_FINISH : c.Z_NO_FLUSH);

  // Convert data if needed
  if (typeof data === 'string') {
    // Only binary strings can be decompressed on practice
    strm.input = strings.binstring2buf(data);
  } else if (toString.call(data) === '[object ArrayBuffer]') {
    strm.input = new Uint8Array(data);
  } else {
    strm.input = data;
  }

  strm.next_in = 0;
  strm.avail_in = strm.input.length;

  do {
    if (strm.avail_out === 0) {
      strm.output = new utils.Buf8(chunkSize);
      strm.next_out = 0;
      strm.avail_out = chunkSize;
    }

    status = zlib_inflate.inflate(strm, c.Z_NO_FLUSH);    /* no bad return value */

    if (status === c.Z_NEED_DICT && dictionary) {
      status = zlib_inflate.inflateSetDictionary(this.strm, dictionary);
    }

    if (status === c.Z_BUF_ERROR && allowBufError === true) {
      status = c.Z_OK;
      allowBufError = false;
    }

    if (status !== c.Z_STREAM_END && status !== c.Z_OK) {
      this.onEnd(status);
      this.ended = true;
      return false;
    }

    if (strm.next_out) {
      if (strm.avail_out === 0 || status === c.Z_STREAM_END || (strm.avail_in === 0 && (_mode === c.Z_FINISH || _mode === c.Z_SYNC_FLUSH))) {

        if (this.options.to === 'string') {

          next_out_utf8 = strings.utf8border(strm.output, strm.next_out);

          tail = strm.next_out - next_out_utf8;
          utf8str = strings.buf2string(strm.output, next_out_utf8);

          // move tail
          strm.next_out = tail;
          strm.avail_out = chunkSize - tail;
          if (tail) { utils.arraySet(strm.output, strm.output, next_out_utf8, tail, 0); }

          this.onData(utf8str);

        } else {
          this.onData(utils.shrinkBuf(strm.output, strm.next_out));
        }
      }
    }

    // When no more input data, we should check that internal inflate buffers
    // are flushed. The only way to do it when avail_out = 0 - run one more
    // inflate pass. But if output data not exists, inflate return Z_BUF_ERROR.
    // Here we set flag to process this error properly.
    //
    // NOTE. Deflate does not return error in this case and does not needs such
    // logic.
    if (strm.avail_in === 0 && strm.avail_out === 0) {
      allowBufError = true;
    }

  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== c.Z_STREAM_END);

  if (status === c.Z_STREAM_END) {
    _mode = c.Z_FINISH;
  }

  // Finalize on the last chunk.
  if (_mode === c.Z_FINISH) {
    status = zlib_inflate.inflateEnd(this.strm);
    this.onEnd(status);
    this.ended = true;
    return status === c.Z_OK;
  }

  // callback interim results if Z_SYNC_FLUSH.
  if (_mode === c.Z_SYNC_FLUSH) {
    this.onEnd(c.Z_OK);
    strm.avail_out = 0;
    return true;
  }

  return true;
};


/**
 * Inflate#onData(chunk) -> Void
 * - chunk (Uint8Array|Array|String): output data. Type of array depends
 *   on js engine support. When string output requested, each chunk
 *   will be string.
 *
 * By default, stores data blocks in `chunks[]` property and glue
 * those in `onEnd`. Override this handler, if you need another behaviour.
 **/
Inflate.prototype.onData = function (chunk) {
  this.chunks.push(chunk);
};


/**
 * Inflate#onEnd(status) -> Void
 * - status (Number): inflate status. 0 (Z_OK) on success,
 *   other if not.
 *
 * Called either after you tell inflate that the input stream is
 * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)
 * or if an error happened. By default - join collected chunks,
 * free memory and fill `results` / `err` properties.
 **/
Inflate.prototype.onEnd = function (status) {
  // On success - join
  if (status === c.Z_OK) {
    if (this.options.to === 'string') {
      // Glue & convert here, until we teach pako to send
      // utf8 aligned strings to onData
      this.result = this.chunks.join('');
    } else {
      this.result = utils.flattenChunks(this.chunks);
    }
  }
  this.chunks = [];
  this.err = status;
  this.msg = this.strm.msg;
};


/**
 * inflate(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to decompress.
 * - options (Object): zlib inflate options.
 *
 * Decompress `data` with inflate/ungzip and `options`. Autodetect
 * format via wrapper header by default. That's why we don't provide
 * separate `ungzip` method.
 *
 * Supported options are:
 *
 * - windowBits
 *
 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
 * for more information.
 *
 * Sugar (options):
 *
 * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify
 *   negative windowBits implicitly.
 * - `to` (String) - if equal to 'string', then result will be converted
 *   from utf8 to utf16 (javascript) string. When string output requested,
 *   chunk length can differ from `chunkSize`, depending on content.
 *
 *
 * ##### Example:
 *
 * ```javascript
 * var pako = require('pako')
 *   , input = pako.deflate([1,2,3,4,5,6,7,8,9])
 *   , output;
 *
 * try {
 *   output = pako.inflate(input);
 * } catch (err)
 *   console.log(err);
 * }
 * ```
 **/
function inflate(input, options) {
  var inflator = new Inflate(options);

  inflator.push(input, true);

  // That will never happens, if you don't cheat with options :)
  if (inflator.err) { throw inflator.msg || msg[inflator.err]; }

  return inflator.result;
}


/**
 * inflateRaw(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to decompress.
 * - options (Object): zlib inflate options.
 *
 * The same as [[inflate]], but creates raw data, without wrapper
 * (header and adler32 crc).
 **/
function inflateRaw(input, options) {
  options = options || {};
  options.raw = true;
  return inflate(input, options);
}


/**
 * ungzip(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to decompress.
 * - options (Object): zlib inflate options.
 *
 * Just shortcut to [[inflate]], because it autodetects format
 * by header.content. Done for convenience.
 **/


exports.Inflate = Inflate;
exports.inflate = inflate;
exports.inflateRaw = inflateRaw;
exports.ungzip  = inflate;


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js ***!
  \***********************************************************************/
/***/ (function(__unused_webpack_module, exports) {

"use strict";



var TYPED_OK =  (typeof Uint8Array !== 'undefined') &&
                (typeof Uint16Array !== 'undefined') &&
                (typeof Int32Array !== 'undefined');

function _has(obj, key) {
  return Object.prototype.hasOwnProperty.call(obj, key);
}

exports.assign = function (obj /*from1, from2, from3, ...*/) {
  var sources = Array.prototype.slice.call(arguments, 1);
  while (sources.length) {
    var source = sources.shift();
    if (!source) { continue; }

    if (typeof source !== 'object') {
      throw new TypeError(source + 'must be non-object');
    }

    for (var p in source) {
      if (_has(source, p)) {
        obj[p] = source[p];
      }
    }
  }

  return obj;
};


// reduce buffer size, avoiding mem copy
exports.shrinkBuf = function (buf, size) {
  if (buf.length === size) { return buf; }
  if (buf.subarray) { return buf.subarray(0, size); }
  buf.length = size;
  return buf;
};


var fnTyped = {
  arraySet: function (dest, src, src_offs, len, dest_offs) {
    if (src.subarray && dest.subarray) {
      dest.set(src.subarray(src_offs, src_offs + len), dest_offs);
      return;
    }
    // Fallback to ordinary array
    for (var i = 0; i < len; i++) {
      dest[dest_offs + i] = src[src_offs + i];
    }
  },
  // Join array of chunks to single array.
  flattenChunks: function (chunks) {
    var i, l, len, pos, chunk, result;

    // calculate data length
    len = 0;
    for (i = 0, l = chunks.length; i < l; i++) {
      len += chunks[i].length;
    }

    // join chunks
    result = new Uint8Array(len);
    pos = 0;
    for (i = 0, l = chunks.length; i < l; i++) {
      chunk = chunks[i];
      result.set(chunk, pos);
      pos += chunk.length;
    }

    return result;
  }
};

var fnUntyped = {
  arraySet: function (dest, src, src_offs, len, dest_offs) {
    for (var i = 0; i < len; i++) {
      dest[dest_offs + i] = src[src_offs + i];
    }
  },
  // Join array of chunks to single array.
  flattenChunks: function (chunks) {
    return [].concat.apply([], chunks);
  }
};


// Enable/Disable typed arrays use, for testing
//
exports.setTyped = function (on) {
  if (on) {
    exports.Buf8  = Uint8Array;
    exports.Buf16 = Uint16Array;
    exports.Buf32 = Int32Array;
    exports.assign(exports, fnTyped);
  } else {
    exports.Buf8  = Array;
    exports.Buf16 = Array;
    exports.Buf32 = Array;
    exports.assign(exports, fnUntyped);
  }
};

exports.setTyped(TYPED_OK);


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/strings.js":
/*!************************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/utils/strings.js ***!
  \************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
// String encode/decode helpers



var utils = __webpack_require__(/*! ./common */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js");


// Quick check if we can use fast array to bin string conversion
//
// - apply(Array) can fail on Android 2.2
// - apply(Uint8Array) can fail on iOS 5.1 Safari
//
var STR_APPLY_OK = true;
var STR_APPLY_UIA_OK = true;

try { String.fromCharCode.apply(null, [ 0 ]); } catch (__) { STR_APPLY_OK = false; }
try { String.fromCharCode.apply(null, new Uint8Array(1)); } catch (__) { STR_APPLY_UIA_OK = false; }


// Table with utf8 lengths (calculated by first byte of sequence)
// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,
// because max possible codepoint is 0x10ffff
var _utf8len = new utils.Buf8(256);
for (var q = 0; q < 256; q++) {
  _utf8len[q] = (q >= 252 ? 6 : q >= 248 ? 5 : q >= 240 ? 4 : q >= 224 ? 3 : q >= 192 ? 2 : 1);
}
_utf8len[254] = _utf8len[254] = 1; // Invalid sequence start


// convert string to array (typed, when possible)
exports.string2buf = function (str) {
  var buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;

  // count binary size
  for (m_pos = 0; m_pos < str_len; m_pos++) {
    c = str.charCodeAt(m_pos);
    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {
      c2 = str.charCodeAt(m_pos + 1);
      if ((c2 & 0xfc00) === 0xdc00) {
        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);
        m_pos++;
      }
    }
    buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;
  }

  // allocate buffer
  buf = new utils.Buf8(buf_len);

  // convert
  for (i = 0, m_pos = 0; i < buf_len; m_pos++) {
    c = str.charCodeAt(m_pos);
    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {
      c2 = str.charCodeAt(m_pos + 1);
      if ((c2 & 0xfc00) === 0xdc00) {
        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);
        m_pos++;
      }
    }
    if (c < 0x80) {
      /* one byte */
      buf[i++] = c;
    } else if (c < 0x800) {
      /* two bytes */
      buf[i++] = 0xC0 | (c >>> 6);
      buf[i++] = 0x80 | (c & 0x3f);
    } else if (c < 0x10000) {
      /* three bytes */
      buf[i++] = 0xE0 | (c >>> 12);
      buf[i++] = 0x80 | (c >>> 6 & 0x3f);
      buf[i++] = 0x80 | (c & 0x3f);
    } else {
      /* four bytes */
      buf[i++] = 0xf0 | (c >>> 18);
      buf[i++] = 0x80 | (c >>> 12 & 0x3f);
      buf[i++] = 0x80 | (c >>> 6 & 0x3f);
      buf[i++] = 0x80 | (c & 0x3f);
    }
  }

  return buf;
};

// Helper (used in 2 places)
function buf2binstring(buf, len) {
  // On Chrome, the arguments in a function call that are allowed is `65534`.
  // If the length of the buffer is smaller than that, we can use this optimization,
  // otherwise we will take a slower path.
  if (len < 65534) {
    if ((buf.subarray && STR_APPLY_UIA_OK) || (!buf.subarray && STR_APPLY_OK)) {
      return String.fromCharCode.apply(null, utils.shrinkBuf(buf, len));
    }
  }

  var result = '';
  for (var i = 0; i < len; i++) {
    result += String.fromCharCode(buf[i]);
  }
  return result;
}


// Convert byte array to binary string
exports.buf2binstring = function (buf) {
  return buf2binstring(buf, buf.length);
};


// Convert binary string (typed, when possible)
exports.binstring2buf = function (str) {
  var buf = new utils.Buf8(str.length);
  for (var i = 0, len = buf.length; i < len; i++) {
    buf[i] = str.charCodeAt(i);
  }
  return buf;
};


// convert array to string
exports.buf2string = function (buf, max) {
  var i, out, c, c_len;
  var len = max || buf.length;

  // Reserve max possible length (2 words per char)
  // NB: by unknown reasons, Array is significantly faster for
  //     String.fromCharCode.apply than Uint16Array.
  var utf16buf = new Array(len * 2);

  for (out = 0, i = 0; i < len;) {
    c = buf[i++];
    // quick process ascii
    if (c < 0x80) { utf16buf[out++] = c; continue; }

    c_len = _utf8len[c];
    // skip 5 & 6 byte codes
    if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len - 1; continue; }

    // apply mask on first byte
    c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;
    // join the rest
    while (c_len > 1 && i < len) {
      c = (c << 6) | (buf[i++] & 0x3f);
      c_len--;
    }

    // terminated by end of string?
    if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }

    if (c < 0x10000) {
      utf16buf[out++] = c;
    } else {
      c -= 0x10000;
      utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);
      utf16buf[out++] = 0xdc00 | (c & 0x3ff);
    }
  }

  return buf2binstring(utf16buf, out);
};


// Calculate max possible position in utf8 buffer,
// that will not break sequence. If that's not possible
// - (very small limits) return max size as is.
//
// buf[] - utf8 bytes array
// max   - length limit (mandatory);
exports.utf8border = function (buf, max) {
  var pos;

  max = max || buf.length;
  if (max > buf.length) { max = buf.length; }

  // go back from last position, until start of sequence found
  pos = max - 1;
  while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }

  // Very small and broken sequence,
  // return max, because we should return something anyway.
  if (pos < 0) { return max; }

  // If we came to start of buffer - that means buffer is too small,
  // return max too.
  if (pos === 0) { return max; }

  return (pos + _utf8len[buf[pos]] > max) ? pos : max;
};


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/adler32.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/adler32.js ***!
  \***********************************************************************/
/***/ (function(module) {

"use strict";


// Note: adler32 takes 12% for level 0 and 2% for level 6.
// It isn't worth it to make additional optimizations as in original.
// Small size is preferable.

// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

function adler32(adler, buf, len, pos) {
  var s1 = (adler & 0xffff) |0,
      s2 = ((adler >>> 16) & 0xffff) |0,
      n = 0;

  while (len !== 0) {
    // Set limit ~ twice less than 5552, to keep
    // s2 in 31-bits, because we force signed ints.
    // in other case %= will fail.
    n = len > 2000 ? 2000 : len;
    len -= n;

    do {
      s1 = (s1 + buf[pos++]) |0;
      s2 = (s2 + s1) |0;
    } while (--n);

    s1 %= 65521;
    s2 %= 65521;
  }

  return (s1 | (s2 << 16)) |0;
}


module.exports = adler32;


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/constants.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/constants.js ***!
  \*************************************************************************/
/***/ (function(module) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

module.exports = {

  /* Allowed flush values; see deflate() and inflate() below for details */
  Z_NO_FLUSH:         0,
  Z_PARTIAL_FLUSH:    1,
  Z_SYNC_FLUSH:       2,
  Z_FULL_FLUSH:       3,
  Z_FINISH:           4,
  Z_BLOCK:            5,
  Z_TREES:            6,

  /* Return codes for the compression/decompression functions. Negative values
  * are errors, positive values are used for special but normal events.
  */
  Z_OK:               0,
  Z_STREAM_END:       1,
  Z_NEED_DICT:        2,
  Z_ERRNO:           -1,
  Z_STREAM_ERROR:    -2,
  Z_DATA_ERROR:      -3,
  //Z_MEM_ERROR:     -4,
  Z_BUF_ERROR:       -5,
  //Z_VERSION_ERROR: -6,

  /* compression levels */
  Z_NO_COMPRESSION:         0,
  Z_BEST_SPEED:             1,
  Z_BEST_COMPRESSION:       9,
  Z_DEFAULT_COMPRESSION:   -1,


  Z_FILTERED:               1,
  Z_HUFFMAN_ONLY:           2,
  Z_RLE:                    3,
  Z_FIXED:                  4,
  Z_DEFAULT_STRATEGY:       0,

  /* Possible values of the data_type field (though see inflate()) */
  Z_BINARY:                 0,
  Z_TEXT:                   1,
  //Z_ASCII:                1, // = Z_TEXT (deprecated)
  Z_UNKNOWN:                2,

  /* The deflate compression method */
  Z_DEFLATED:               8
  //Z_NULL:                 null // Use -1 or null inline, depending on var type
};


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/crc32.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/crc32.js ***!
  \*********************************************************************/
/***/ (function(module) {

"use strict";


// Note: we can't get significant speed boost here.
// So write code to minimize size - no pregenerated tables
// and array tools dependencies.

// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

// Use ordinary array, since untyped makes no boost here
function makeTable() {
  var c, table = [];

  for (var n = 0; n < 256; n++) {
    c = n;
    for (var k = 0; k < 8; k++) {
      c = ((c & 1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));
    }
    table[n] = c;
  }

  return table;
}

// Create table on load. Just 255 signed longs. Not a problem.
var crcTable = makeTable();


function crc32(crc, buf, len, pos) {
  var t = crcTable,
      end = pos + len;

  crc ^= -1;

  for (var i = pos; i < end; i++) {
    crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];
  }

  return (crc ^ (-1)); // >>> 0;
}


module.exports = crc32;


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/deflate.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/deflate.js ***!
  \***********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

var utils   = __webpack_require__(/*! ../utils/common */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js");
var trees   = __webpack_require__(/*! ./trees */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/trees.js");
var adler32 = __webpack_require__(/*! ./adler32 */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/adler32.js");
var crc32   = __webpack_require__(/*! ./crc32 */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/crc32.js");
var msg     = __webpack_require__(/*! ./messages */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/messages.js");

/* Public constants ==========================================================*/
/* ===========================================================================*/


/* Allowed flush values; see deflate() and inflate() below for details */
var Z_NO_FLUSH      = 0;
var Z_PARTIAL_FLUSH = 1;
//var Z_SYNC_FLUSH    = 2;
var Z_FULL_FLUSH    = 3;
var Z_FINISH        = 4;
var Z_BLOCK         = 5;
//var Z_TREES         = 6;


/* Return codes for the compression/decompression functions. Negative values
 * are errors, positive values are used for special but normal events.
 */
var Z_OK            = 0;
var Z_STREAM_END    = 1;
//var Z_NEED_DICT     = 2;
//var Z_ERRNO         = -1;
var Z_STREAM_ERROR  = -2;
var Z_DATA_ERROR    = -3;
//var Z_MEM_ERROR     = -4;
var Z_BUF_ERROR     = -5;
//var Z_VERSION_ERROR = -6;


/* compression levels */
//var Z_NO_COMPRESSION      = 0;
//var Z_BEST_SPEED          = 1;
//var Z_BEST_COMPRESSION    = 9;
var Z_DEFAULT_COMPRESSION = -1;


var Z_FILTERED            = 1;
var Z_HUFFMAN_ONLY        = 2;
var Z_RLE                 = 3;
var Z_FIXED               = 4;
var Z_DEFAULT_STRATEGY    = 0;

/* Possible values of the data_type field (though see inflate()) */
//var Z_BINARY              = 0;
//var Z_TEXT                = 1;
//var Z_ASCII               = 1; // = Z_TEXT
var Z_UNKNOWN             = 2;


/* The deflate compression method */
var Z_DEFLATED  = 8;

/*============================================================================*/


var MAX_MEM_LEVEL = 9;
/* Maximum value for memLevel in deflateInit2 */
var MAX_WBITS = 15;
/* 32K LZ77 window */
var DEF_MEM_LEVEL = 8;


var LENGTH_CODES  = 29;
/* number of length codes, not counting the special END_BLOCK code */
var LITERALS      = 256;
/* number of literal bytes 0..255 */
var L_CODES       = LITERALS + 1 + LENGTH_CODES;
/* number of Literal or Length codes, including the END_BLOCK code */
var D_CODES       = 30;
/* number of distance codes */
var BL_CODES      = 19;
/* number of codes used to transfer the bit lengths */
var HEAP_SIZE     = 2 * L_CODES + 1;
/* maximum heap size */
var MAX_BITS  = 15;
/* All codes must not exceed MAX_BITS bits */

var MIN_MATCH = 3;
var MAX_MATCH = 258;
var MIN_LOOKAHEAD = (MAX_MATCH + MIN_MATCH + 1);

var PRESET_DICT = 0x20;

var INIT_STATE = 42;
var EXTRA_STATE = 69;
var NAME_STATE = 73;
var COMMENT_STATE = 91;
var HCRC_STATE = 103;
var BUSY_STATE = 113;
var FINISH_STATE = 666;

var BS_NEED_MORE      = 1; /* block not completed, need more input or more output */
var BS_BLOCK_DONE     = 2; /* block flush performed */
var BS_FINISH_STARTED = 3; /* finish started, need only more output at next deflate */
var BS_FINISH_DONE    = 4; /* finish done, accept no more input or output */

var OS_CODE = 0x03; // Unix :) . Don't detect, use this default.

function err(strm, errorCode) {
  strm.msg = msg[errorCode];
  return errorCode;
}

function rank(f) {
  return ((f) << 1) - ((f) > 4 ? 9 : 0);
}

function zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }


/* =========================================================================
 * Flush as much pending output as possible. All deflate() output goes
 * through this function so some applications may wish to modify it
 * to avoid allocating a large strm->output buffer and copying into it.
 * (See also read_buf()).
 */
function flush_pending(strm) {
  var s = strm.state;

  //_tr_flush_bits(s);
  var len = s.pending;
  if (len > strm.avail_out) {
    len = strm.avail_out;
  }
  if (len === 0) { return; }

  utils.arraySet(strm.output, s.pending_buf, s.pending_out, len, strm.next_out);
  strm.next_out += len;
  s.pending_out += len;
  strm.total_out += len;
  strm.avail_out -= len;
  s.pending -= len;
  if (s.pending === 0) {
    s.pending_out = 0;
  }
}


function flush_block_only(s, last) {
  trees._tr_flush_block(s, (s.block_start >= 0 ? s.block_start : -1), s.strstart - s.block_start, last);
  s.block_start = s.strstart;
  flush_pending(s.strm);
}


function put_byte(s, b) {
  s.pending_buf[s.pending++] = b;
}


/* =========================================================================
 * Put a short in the pending buffer. The 16-bit value is put in MSB order.
 * IN assertion: the stream state is correct and there is enough room in
 * pending_buf.
 */
function putShortMSB(s, b) {
//  put_byte(s, (Byte)(b >> 8));
//  put_byte(s, (Byte)(b & 0xff));
  s.pending_buf[s.pending++] = (b >>> 8) & 0xff;
  s.pending_buf[s.pending++] = b & 0xff;
}


/* ===========================================================================
 * Read a new buffer from the current input stream, update the adler32
 * and total number of bytes read.  All deflate() input goes through
 * this function so some applications may wish to modify it to avoid
 * allocating a large strm->input buffer and copying from it.
 * (See also flush_pending()).
 */
function read_buf(strm, buf, start, size) {
  var len = strm.avail_in;

  if (len > size) { len = size; }
  if (len === 0) { return 0; }

  strm.avail_in -= len;

  // zmemcpy(buf, strm->next_in, len);
  utils.arraySet(buf, strm.input, strm.next_in, len, start);
  if (strm.state.wrap === 1) {
    strm.adler = adler32(strm.adler, buf, len, start);
  }

  else if (strm.state.wrap === 2) {
    strm.adler = crc32(strm.adler, buf, len, start);
  }

  strm.next_in += len;
  strm.total_in += len;

  return len;
}


/* ===========================================================================
 * Set match_start to the longest match starting at the given string and
 * return its length. Matches shorter or equal to prev_length are discarded,
 * in which case the result is equal to prev_length and match_start is
 * garbage.
 * IN assertions: cur_match is the head of the hash chain for the current
 *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1
 * OUT assertion: the match length is not greater than s->lookahead.
 */
function longest_match(s, cur_match) {
  var chain_length = s.max_chain_length;      /* max hash chain length */
  var scan = s.strstart; /* current string */
  var match;                       /* matched string */
  var len;                           /* length of current match */
  var best_len = s.prev_length;              /* best match length so far */
  var nice_match = s.nice_match;             /* stop if match long enough */
  var limit = (s.strstart > (s.w_size - MIN_LOOKAHEAD)) ?
      s.strstart - (s.w_size - MIN_LOOKAHEAD) : 0/*NIL*/;

  var _win = s.window; // shortcut

  var wmask = s.w_mask;
  var prev  = s.prev;

  /* Stop when cur_match becomes <= limit. To simplify the code,
   * we prevent matches with the string of window index 0.
   */

  var strend = s.strstart + MAX_MATCH;
  var scan_end1  = _win[scan + best_len - 1];
  var scan_end   = _win[scan + best_len];

  /* The code is optimized for HASH_BITS >= 8 and MAX_MATCH-2 multiple of 16.
   * It is easy to get rid of this optimization if necessary.
   */
  // Assert(s->hash_bits >= 8 && MAX_MATCH == 258, "Code too clever");

  /* Do not waste too much time if we already have a good match: */
  if (s.prev_length >= s.good_match) {
    chain_length >>= 2;
  }
  /* Do not look for matches beyond the end of the input. This is necessary
   * to make deflate deterministic.
   */
  if (nice_match > s.lookahead) { nice_match = s.lookahead; }

  // Assert((ulg)s->strstart <= s->window_size-MIN_LOOKAHEAD, "need lookahead");

  do {
    // Assert(cur_match < s->strstart, "no future");
    match = cur_match;

    /* Skip to next match if the match length cannot increase
     * or if the match length is less than 2.  Note that the checks below
     * for insufficient lookahead only occur occasionally for performance
     * reasons.  Therefore uninitialized memory will be accessed, and
     * conditional jumps will be made that depend on those values.
     * However the length of the match is limited to the lookahead, so
     * the output of deflate is not affected by the uninitialized values.
     */

    if (_win[match + best_len]     !== scan_end  ||
        _win[match + best_len - 1] !== scan_end1 ||
        _win[match]                !== _win[scan] ||
        _win[++match]              !== _win[scan + 1]) {
      continue;
    }

    /* The check at best_len-1 can be removed because it will be made
     * again later. (This heuristic is not always a win.)
     * It is not necessary to compare scan[2] and match[2] since they
     * are always equal when the other bytes match, given that
     * the hash keys are equal and that HASH_BITS >= 8.
     */
    scan += 2;
    match++;
    // Assert(*scan == *match, "match[2]?");

    /* We check for insufficient lookahead only every 8th comparison;
     * the 256th check will be made at strstart+258.
     */
    do {
      /*jshint noempty:false*/
    } while (_win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&
             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&
             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&
             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&
             scan < strend);

    // Assert(scan <= s->window+(unsigned)(s->window_size-1), "wild scan");

    len = MAX_MATCH - (strend - scan);
    scan = strend - MAX_MATCH;

    if (len > best_len) {
      s.match_start = cur_match;
      best_len = len;
      if (len >= nice_match) {
        break;
      }
      scan_end1  = _win[scan + best_len - 1];
      scan_end   = _win[scan + best_len];
    }
  } while ((cur_match = prev[cur_match & wmask]) > limit && --chain_length !== 0);

  if (best_len <= s.lookahead) {
    return best_len;
  }
  return s.lookahead;
}


/* ===========================================================================
 * Fill the window when the lookahead becomes insufficient.
 * Updates strstart and lookahead.
 *
 * IN assertion: lookahead < MIN_LOOKAHEAD
 * OUT assertions: strstart <= window_size-MIN_LOOKAHEAD
 *    At least one byte has been read, or avail_in == 0; reads are
 *    performed for at least two bytes (required for the zip translate_eol
 *    option -- not supported here).
 */
function fill_window(s) {
  var _w_size = s.w_size;
  var p, n, m, more, str;

  //Assert(s->lookahead < MIN_LOOKAHEAD, "already enough lookahead");

  do {
    more = s.window_size - s.lookahead - s.strstart;

    // JS ints have 32 bit, block below not needed
    /* Deal with !@#$% 64K limit: */
    //if (sizeof(int) <= 2) {
    //    if (more == 0 && s->strstart == 0 && s->lookahead == 0) {
    //        more = wsize;
    //
    //  } else if (more == (unsigned)(-1)) {
    //        /* Very unlikely, but possible on 16 bit machine if
    //         * strstart == 0 && lookahead == 1 (input done a byte at time)
    //         */
    //        more--;
    //    }
    //}


    /* If the window is almost full and there is insufficient lookahead,
     * move the upper half to the lower one to make room in the upper half.
     */
    if (s.strstart >= _w_size + (_w_size - MIN_LOOKAHEAD)) {

      utils.arraySet(s.window, s.window, _w_size, _w_size, 0);
      s.match_start -= _w_size;
      s.strstart -= _w_size;
      /* we now have strstart >= MAX_DIST */
      s.block_start -= _w_size;

      /* Slide the hash table (could be avoided with 32 bit values
       at the expense of memory usage). We slide even when level == 0
       to keep the hash table consistent if we switch back to level > 0
       later. (Using level 0 permanently is not an optimal usage of
       zlib, so we don't care about this pathological case.)
       */

      n = s.hash_size;
      p = n;
      do {
        m = s.head[--p];
        s.head[p] = (m >= _w_size ? m - _w_size : 0);
      } while (--n);

      n = _w_size;
      p = n;
      do {
        m = s.prev[--p];
        s.prev[p] = (m >= _w_size ? m - _w_size : 0);
        /* If n is not on any hash chain, prev[n] is garbage but
         * its value will never be used.
         */
      } while (--n);

      more += _w_size;
    }
    if (s.strm.avail_in === 0) {
      break;
    }

    /* If there was no sliding:
     *    strstart <= WSIZE+MAX_DIST-1 && lookahead <= MIN_LOOKAHEAD - 1 &&
     *    more == window_size - lookahead - strstart
     * => more >= window_size - (MIN_LOOKAHEAD-1 + WSIZE + MAX_DIST-1)
     * => more >= window_size - 2*WSIZE + 2
     * In the BIG_MEM or MMAP case (not yet supported),
     *   window_size == input_size + MIN_LOOKAHEAD  &&
     *   strstart + s->lookahead <= input_size => more >= MIN_LOOKAHEAD.
     * Otherwise, window_size == 2*WSIZE so more >= 2.
     * If there was sliding, more >= WSIZE. So in all cases, more >= 2.
     */
    //Assert(more >= 2, "more < 2");
    n = read_buf(s.strm, s.window, s.strstart + s.lookahead, more);
    s.lookahead += n;

    /* Initialize the hash value now that we have some input: */
    if (s.lookahead + s.insert >= MIN_MATCH) {
      str = s.strstart - s.insert;
      s.ins_h = s.window[str];

      /* UPDATE_HASH(s, s->ins_h, s->window[str + 1]); */
      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + 1]) & s.hash_mask;
//#if MIN_MATCH != 3
//        Call update_hash() MIN_MATCH-3 more times
//#endif
      while (s.insert) {
        /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */
        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;

        s.prev[str & s.w_mask] = s.head[s.ins_h];
        s.head[s.ins_h] = str;
        str++;
        s.insert--;
        if (s.lookahead + s.insert < MIN_MATCH) {
          break;
        }
      }
    }
    /* If the whole input has less than MIN_MATCH bytes, ins_h is garbage,
     * but this is not important since only literal bytes will be emitted.
     */

  } while (s.lookahead < MIN_LOOKAHEAD && s.strm.avail_in !== 0);

  /* If the WIN_INIT bytes after the end of the current data have never been
   * written, then zero those bytes in order to avoid memory check reports of
   * the use of uninitialized (or uninitialised as Julian writes) bytes by
   * the longest match routines.  Update the high water mark for the next
   * time through here.  WIN_INIT is set to MAX_MATCH since the longest match
   * routines allow scanning to strstart + MAX_MATCH, ignoring lookahead.
   */
//  if (s.high_water < s.window_size) {
//    var curr = s.strstart + s.lookahead;
//    var init = 0;
//
//    if (s.high_water < curr) {
//      /* Previous high water mark below current data -- zero WIN_INIT
//       * bytes or up to end of window, whichever is less.
//       */
//      init = s.window_size - curr;
//      if (init > WIN_INIT)
//        init = WIN_INIT;
//      zmemzero(s->window + curr, (unsigned)init);
//      s->high_water = curr + init;
//    }
//    else if (s->high_water < (ulg)curr + WIN_INIT) {
//      /* High water mark at or above current data, but below current data
//       * plus WIN_INIT -- zero out to current data plus WIN_INIT, or up
//       * to end of window, whichever is less.
//       */
//      init = (ulg)curr + WIN_INIT - s->high_water;
//      if (init > s->window_size - s->high_water)
//        init = s->window_size - s->high_water;
//      zmemzero(s->window + s->high_water, (unsigned)init);
//      s->high_water += init;
//    }
//  }
//
//  Assert((ulg)s->strstart <= s->window_size - MIN_LOOKAHEAD,
//    "not enough room for search");
}

/* ===========================================================================
 * Copy without compression as much as possible from the input stream, return
 * the current block state.
 * This function does not insert new strings in the dictionary since
 * uncompressible data is probably not useful. This function is used
 * only for the level=0 compression option.
 * NOTE: this function should be optimized to avoid extra copying from
 * window to pending_buf.
 */
function deflate_stored(s, flush) {
  /* Stored blocks are limited to 0xffff bytes, pending_buf is limited
   * to pending_buf_size, and each stored block has a 5 byte header:
   */
  var max_block_size = 0xffff;

  if (max_block_size > s.pending_buf_size - 5) {
    max_block_size = s.pending_buf_size - 5;
  }

  /* Copy as much as possible from input to output: */
  for (;;) {
    /* Fill the window as much as possible: */
    if (s.lookahead <= 1) {

      //Assert(s->strstart < s->w_size+MAX_DIST(s) ||
      //  s->block_start >= (long)s->w_size, "slide too late");
//      if (!(s.strstart < s.w_size + (s.w_size - MIN_LOOKAHEAD) ||
//        s.block_start >= s.w_size)) {
//        throw  new Error("slide too late");
//      }

      fill_window(s);
      if (s.lookahead === 0 && flush === Z_NO_FLUSH) {
        return BS_NEED_MORE;
      }

      if (s.lookahead === 0) {
        break;
      }
      /* flush the current block */
    }
    //Assert(s->block_start >= 0L, "block gone");
//    if (s.block_start < 0) throw new Error("block gone");

    s.strstart += s.lookahead;
    s.lookahead = 0;

    /* Emit a stored block if pending_buf will be full: */
    var max_start = s.block_start + max_block_size;

    if (s.strstart === 0 || s.strstart >= max_start) {
      /* strstart == 0 is possible when wraparound on 16-bit machine */
      s.lookahead = s.strstart - max_start;
      s.strstart = max_start;
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/


    }
    /* Flush if we may have to slide, otherwise block_start may become
     * negative and the data will be gone:
     */
    if (s.strstart - s.block_start >= (s.w_size - MIN_LOOKAHEAD)) {
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/
    }
  }

  s.insert = 0;

  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }

  if (s.strstart > s.block_start) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }

  return BS_NEED_MORE;
}

/* ===========================================================================
 * Compress as much as possible from the input stream, return the current
 * block state.
 * This function does not perform lazy evaluation of matches and inserts
 * new strings in the dictionary only for unmatched strings or for short
 * matches. It is used only for the fast compression options.
 */
function deflate_fast(s, flush) {
  var hash_head;        /* head of the hash chain */
  var bflush;           /* set if current block must be flushed */

  for (;;) {
    /* Make sure that we always have enough lookahead, except
     * at the end of the input file. We need MAX_MATCH bytes
     * for the next match, plus MIN_MATCH bytes to insert the
     * string following the next match.
     */
    if (s.lookahead < MIN_LOOKAHEAD) {
      fill_window(s);
      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {
        return BS_NEED_MORE;
      }
      if (s.lookahead === 0) {
        break; /* flush the current block */
      }
    }

    /* Insert the string window[strstart .. strstart+2] in the
     * dictionary, and set hash_head to the head of the hash chain:
     */
    hash_head = 0/*NIL*/;
    if (s.lookahead >= MIN_MATCH) {
      /*** INSERT_STRING(s, s.strstart, hash_head); ***/
      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;
      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];
      s.head[s.ins_h] = s.strstart;
      /***/
    }

    /* Find the longest match, discarding those <= prev_length.
     * At this point we have always match_length < MIN_MATCH
     */
    if (hash_head !== 0/*NIL*/ && ((s.strstart - hash_head) <= (s.w_size - MIN_LOOKAHEAD))) {
      /* To simplify the code, we prevent matches with the string
       * of window index 0 (in particular we have to avoid a match
       * of the string with itself at the start of the input file).
       */
      s.match_length = longest_match(s, hash_head);
      /* longest_match() sets match_start */
    }
    if (s.match_length >= MIN_MATCH) {
      // check_match(s, s.strstart, s.match_start, s.match_length); // for debug only

      /*** _tr_tally_dist(s, s.strstart - s.match_start,
                     s.match_length - MIN_MATCH, bflush); ***/
      bflush = trees._tr_tally(s, s.strstart - s.match_start, s.match_length - MIN_MATCH);

      s.lookahead -= s.match_length;

      /* Insert new strings in the hash table only if the match length
       * is not too large. This saves time but degrades compression.
       */
      if (s.match_length <= s.max_lazy_match/*max_insert_length*/ && s.lookahead >= MIN_MATCH) {
        s.match_length--; /* string at strstart already in table */
        do {
          s.strstart++;
          /*** INSERT_STRING(s, s.strstart, hash_head); ***/
          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;
          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];
          s.head[s.ins_h] = s.strstart;
          /***/
          /* strstart never exceeds WSIZE-MAX_MATCH, so there are
           * always MIN_MATCH bytes ahead.
           */
        } while (--s.match_length !== 0);
        s.strstart++;
      } else
      {
        s.strstart += s.match_length;
        s.match_length = 0;
        s.ins_h = s.window[s.strstart];
        /* UPDATE_HASH(s, s.ins_h, s.window[s.strstart+1]); */
        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + 1]) & s.hash_mask;

//#if MIN_MATCH != 3
//                Call UPDATE_HASH() MIN_MATCH-3 more times
//#endif
        /* If lookahead < MIN_MATCH, ins_h is garbage, but it does not
         * matter since it will be recomputed at next deflate call.
         */
      }
    } else {
      /* No match, output a literal byte */
      //Tracevv((stderr,"%c", s.window[s.strstart]));
      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/
      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);

      s.lookahead--;
      s.strstart++;
    }
    if (bflush) {
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/
    }
  }
  s.insert = ((s.strstart < (MIN_MATCH - 1)) ? s.strstart : MIN_MATCH - 1);
  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }
  if (s.last_lit) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }
  return BS_BLOCK_DONE;
}

/* ===========================================================================
 * Same as above, but achieves better compression. We use a lazy
 * evaluation for matches: a match is finally adopted only if there is
 * no better match at the next window position.
 */
function deflate_slow(s, flush) {
  var hash_head;          /* head of hash chain */
  var bflush;              /* set if current block must be flushed */

  var max_insert;

  /* Process the input block. */
  for (;;) {
    /* Make sure that we always have enough lookahead, except
     * at the end of the input file. We need MAX_MATCH bytes
     * for the next match, plus MIN_MATCH bytes to insert the
     * string following the next match.
     */
    if (s.lookahead < MIN_LOOKAHEAD) {
      fill_window(s);
      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {
        return BS_NEED_MORE;
      }
      if (s.lookahead === 0) { break; } /* flush the current block */
    }

    /* Insert the string window[strstart .. strstart+2] in the
     * dictionary, and set hash_head to the head of the hash chain:
     */
    hash_head = 0/*NIL*/;
    if (s.lookahead >= MIN_MATCH) {
      /*** INSERT_STRING(s, s.strstart, hash_head); ***/
      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;
      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];
      s.head[s.ins_h] = s.strstart;
      /***/
    }

    /* Find the longest match, discarding those <= prev_length.
     */
    s.prev_length = s.match_length;
    s.prev_match = s.match_start;
    s.match_length = MIN_MATCH - 1;

    if (hash_head !== 0/*NIL*/ && s.prev_length < s.max_lazy_match &&
        s.strstart - hash_head <= (s.w_size - MIN_LOOKAHEAD)/*MAX_DIST(s)*/) {
      /* To simplify the code, we prevent matches with the string
       * of window index 0 (in particular we have to avoid a match
       * of the string with itself at the start of the input file).
       */
      s.match_length = longest_match(s, hash_head);
      /* longest_match() sets match_start */

      if (s.match_length <= 5 &&
         (s.strategy === Z_FILTERED || (s.match_length === MIN_MATCH && s.strstart - s.match_start > 4096/*TOO_FAR*/))) {

        /* If prev_match is also MIN_MATCH, match_start is garbage
         * but we will ignore the current match anyway.
         */
        s.match_length = MIN_MATCH - 1;
      }
    }
    /* If there was a match at the previous step and the current
     * match is not better, output the previous match:
     */
    if (s.prev_length >= MIN_MATCH && s.match_length <= s.prev_length) {
      max_insert = s.strstart + s.lookahead - MIN_MATCH;
      /* Do not insert strings in hash table beyond this. */

      //check_match(s, s.strstart-1, s.prev_match, s.prev_length);

      /***_tr_tally_dist(s, s.strstart - 1 - s.prev_match,
                     s.prev_length - MIN_MATCH, bflush);***/
      bflush = trees._tr_tally(s, s.strstart - 1 - s.prev_match, s.prev_length - MIN_MATCH);
      /* Insert in hash table all strings up to the end of the match.
       * strstart-1 and strstart are already inserted. If there is not
       * enough lookahead, the last two strings are not inserted in
       * the hash table.
       */
      s.lookahead -= s.prev_length - 1;
      s.prev_length -= 2;
      do {
        if (++s.strstart <= max_insert) {
          /*** INSERT_STRING(s, s.strstart, hash_head); ***/
          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;
          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];
          s.head[s.ins_h] = s.strstart;
          /***/
        }
      } while (--s.prev_length !== 0);
      s.match_available = 0;
      s.match_length = MIN_MATCH - 1;
      s.strstart++;

      if (bflush) {
        /*** FLUSH_BLOCK(s, 0); ***/
        flush_block_only(s, false);
        if (s.strm.avail_out === 0) {
          return BS_NEED_MORE;
        }
        /***/
      }

    } else if (s.match_available) {
      /* If there was no match at the previous position, output a
       * single literal. If there was a match but the current match
       * is longer, truncate the previous match to a single literal.
       */
      //Tracevv((stderr,"%c", s->window[s->strstart-1]));
      /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/
      bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);

      if (bflush) {
        /*** FLUSH_BLOCK_ONLY(s, 0) ***/
        flush_block_only(s, false);
        /***/
      }
      s.strstart++;
      s.lookahead--;
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
    } else {
      /* There is no previous match to compare with, wait for
       * the next step to decide.
       */
      s.match_available = 1;
      s.strstart++;
      s.lookahead--;
    }
  }
  //Assert (flush != Z_NO_FLUSH, "no flush?");
  if (s.match_available) {
    //Tracevv((stderr,"%c", s->window[s->strstart-1]));
    /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/
    bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);

    s.match_available = 0;
  }
  s.insert = s.strstart < MIN_MATCH - 1 ? s.strstart : MIN_MATCH - 1;
  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }
  if (s.last_lit) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }

  return BS_BLOCK_DONE;
}


/* ===========================================================================
 * For Z_RLE, simply look for runs of bytes, generate matches only of distance
 * one.  Do not maintain a hash table.  (It will be regenerated if this run of
 * deflate switches away from Z_RLE.)
 */
function deflate_rle(s, flush) {
  var bflush;            /* set if current block must be flushed */
  var prev;              /* byte at distance one to match */
  var scan, strend;      /* scan goes up to strend for length of run */

  var _win = s.window;

  for (;;) {
    /* Make sure that we always have enough lookahead, except
     * at the end of the input file. We need MAX_MATCH bytes
     * for the longest run, plus one for the unrolled loop.
     */
    if (s.lookahead <= MAX_MATCH) {
      fill_window(s);
      if (s.lookahead <= MAX_MATCH && flush === Z_NO_FLUSH) {
        return BS_NEED_MORE;
      }
      if (s.lookahead === 0) { break; } /* flush the current block */
    }

    /* See how many times the previous byte repeats */
    s.match_length = 0;
    if (s.lookahead >= MIN_MATCH && s.strstart > 0) {
      scan = s.strstart - 1;
      prev = _win[scan];
      if (prev === _win[++scan] && prev === _win[++scan] && prev === _win[++scan]) {
        strend = s.strstart + MAX_MATCH;
        do {
          /*jshint noempty:false*/
        } while (prev === _win[++scan] && prev === _win[++scan] &&
                 prev === _win[++scan] && prev === _win[++scan] &&
                 prev === _win[++scan] && prev === _win[++scan] &&
                 prev === _win[++scan] && prev === _win[++scan] &&
                 scan < strend);
        s.match_length = MAX_MATCH - (strend - scan);
        if (s.match_length > s.lookahead) {
          s.match_length = s.lookahead;
        }
      }
      //Assert(scan <= s->window+(uInt)(s->window_size-1), "wild scan");
    }

    /* Emit match if have run of MIN_MATCH or longer, else emit literal */
    if (s.match_length >= MIN_MATCH) {
      //check_match(s, s.strstart, s.strstart - 1, s.match_length);

      /*** _tr_tally_dist(s, 1, s.match_length - MIN_MATCH, bflush); ***/
      bflush = trees._tr_tally(s, 1, s.match_length - MIN_MATCH);

      s.lookahead -= s.match_length;
      s.strstart += s.match_length;
      s.match_length = 0;
    } else {
      /* No match, output a literal byte */
      //Tracevv((stderr,"%c", s->window[s->strstart]));
      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/
      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);

      s.lookahead--;
      s.strstart++;
    }
    if (bflush) {
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/
    }
  }
  s.insert = 0;
  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }
  if (s.last_lit) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }
  return BS_BLOCK_DONE;
}

/* ===========================================================================
 * For Z_HUFFMAN_ONLY, do not look for matches.  Do not maintain a hash table.
 * (It will be regenerated if this run of deflate switches away from Huffman.)
 */
function deflate_huff(s, flush) {
  var bflush;             /* set if current block must be flushed */

  for (;;) {
    /* Make sure that we have a literal to write. */
    if (s.lookahead === 0) {
      fill_window(s);
      if (s.lookahead === 0) {
        if (flush === Z_NO_FLUSH) {
          return BS_NEED_MORE;
        }
        break;      /* flush the current block */
      }
    }

    /* Output a literal byte */
    s.match_length = 0;
    //Tracevv((stderr,"%c", s->window[s->strstart]));
    /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/
    bflush = trees._tr_tally(s, 0, s.window[s.strstart]);
    s.lookahead--;
    s.strstart++;
    if (bflush) {
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/
    }
  }
  s.insert = 0;
  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }
  if (s.last_lit) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }
  return BS_BLOCK_DONE;
}

/* Values for max_lazy_match, good_match and max_chain_length, depending on
 * the desired pack level (0..9). The values given below have been tuned to
 * exclude worst case performance for pathological files. Better values may be
 * found for specific files.
 */
function Config(good_length, max_lazy, nice_length, max_chain, func) {
  this.good_length = good_length;
  this.max_lazy = max_lazy;
  this.nice_length = nice_length;
  this.max_chain = max_chain;
  this.func = func;
}

var configuration_table;

configuration_table = [
  /*      good lazy nice chain */
  new Config(0, 0, 0, 0, deflate_stored),          /* 0 store only */
  new Config(4, 4, 8, 4, deflate_fast),            /* 1 max speed, no lazy matches */
  new Config(4, 5, 16, 8, deflate_fast),           /* 2 */
  new Config(4, 6, 32, 32, deflate_fast),          /* 3 */

  new Config(4, 4, 16, 16, deflate_slow),          /* 4 lazy matches */
  new Config(8, 16, 32, 32, deflate_slow),         /* 5 */
  new Config(8, 16, 128, 128, deflate_slow),       /* 6 */
  new Config(8, 32, 128, 256, deflate_slow),       /* 7 */
  new Config(32, 128, 258, 1024, deflate_slow),    /* 8 */
  new Config(32, 258, 258, 4096, deflate_slow)     /* 9 max compression */
];


/* ===========================================================================
 * Initialize the "longest match" routines for a new zlib stream
 */
function lm_init(s) {
  s.window_size = 2 * s.w_size;

  /*** CLEAR_HASH(s); ***/
  zero(s.head); // Fill with NIL (= 0);

  /* Set the default configuration parameters:
   */
  s.max_lazy_match = configuration_table[s.level].max_lazy;
  s.good_match = configuration_table[s.level].good_length;
  s.nice_match = configuration_table[s.level].nice_length;
  s.max_chain_length = configuration_table[s.level].max_chain;

  s.strstart = 0;
  s.block_start = 0;
  s.lookahead = 0;
  s.insert = 0;
  s.match_length = s.prev_length = MIN_MATCH - 1;
  s.match_available = 0;
  s.ins_h = 0;
}


function DeflateState() {
  this.strm = null;            /* pointer back to this zlib stream */
  this.status = 0;            /* as the name implies */
  this.pending_buf = null;      /* output still pending */
  this.pending_buf_size = 0;  /* size of pending_buf */
  this.pending_out = 0;       /* next pending byte to output to the stream */
  this.pending = 0;           /* nb of bytes in the pending buffer */
  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */
  this.gzhead = null;         /* gzip header information to write */
  this.gzindex = 0;           /* where in extra, name, or comment */
  this.method = Z_DEFLATED; /* can only be DEFLATED */
  this.last_flush = -1;   /* value of flush param for previous deflate call */

  this.w_size = 0;  /* LZ77 window size (32K by default) */
  this.w_bits = 0;  /* log2(w_size)  (8..16) */
  this.w_mask = 0;  /* w_size - 1 */

  this.window = null;
  /* Sliding window. Input bytes are read into the second half of the window,
   * and move to the first half later to keep a dictionary of at least wSize
   * bytes. With this organization, matches are limited to a distance of
   * wSize-MAX_MATCH bytes, but this ensures that IO is always
   * performed with a length multiple of the block size.
   */

  this.window_size = 0;
  /* Actual size of window: 2*wSize, except when the user input buffer
   * is directly used as sliding window.
   */

  this.prev = null;
  /* Link to older string with same hash index. To limit the size of this
   * array to 64K, this link is maintained only for the last 32K strings.
   * An index in this array is thus a window index modulo 32K.
   */

  this.head = null;   /* Heads of the hash chains or NIL. */

  this.ins_h = 0;       /* hash index of string to be inserted */
  this.hash_size = 0;   /* number of elements in hash table */
  this.hash_bits = 0;   /* log2(hash_size) */
  this.hash_mask = 0;   /* hash_size-1 */

  this.hash_shift = 0;
  /* Number of bits by which ins_h must be shifted at each input
   * step. It must be such that after MIN_MATCH steps, the oldest
   * byte no longer takes part in the hash key, that is:
   *   hash_shift * MIN_MATCH >= hash_bits
   */

  this.block_start = 0;
  /* Window position at the beginning of the current output block. Gets
   * negative when the window is moved backwards.
   */

  this.match_length = 0;      /* length of best match */
  this.prev_match = 0;        /* previous match */
  this.match_available = 0;   /* set if previous match exists */
  this.strstart = 0;          /* start of string to insert */
  this.match_start = 0;       /* start of matching string */
  this.lookahead = 0;         /* number of valid bytes ahead in window */

  this.prev_length = 0;
  /* Length of the best match at previous step. Matches not greater than this
   * are discarded. This is used in the lazy match evaluation.
   */

  this.max_chain_length = 0;
  /* To speed up deflation, hash chains are never searched beyond this
   * length.  A higher limit improves compression ratio but degrades the
   * speed.
   */

  this.max_lazy_match = 0;
  /* Attempt to find a better match only when the current match is strictly
   * smaller than this value. This mechanism is used only for compression
   * levels >= 4.
   */
  // That's alias to max_lazy_match, don't use directly
  //this.max_insert_length = 0;
  /* Insert new strings in the hash table only if the match length is not
   * greater than this length. This saves time but degrades compression.
   * max_insert_length is used only for compression levels <= 3.
   */

  this.level = 0;     /* compression level (1..9) */
  this.strategy = 0;  /* favor or force Huffman coding*/

  this.good_match = 0;
  /* Use a faster search when the previous match is longer than this */

  this.nice_match = 0; /* Stop searching when current match exceeds this */

              /* used by trees.c: */

  /* Didn't use ct_data typedef below to suppress compiler warning */

  // struct ct_data_s dyn_ltree[HEAP_SIZE];   /* literal and length tree */
  // struct ct_data_s dyn_dtree[2*D_CODES+1]; /* distance tree */
  // struct ct_data_s bl_tree[2*BL_CODES+1];  /* Huffman tree for bit lengths */

  // Use flat array of DOUBLE size, with interleaved fata,
  // because JS does not support effective
  this.dyn_ltree  = new utils.Buf16(HEAP_SIZE * 2);
  this.dyn_dtree  = new utils.Buf16((2 * D_CODES + 1) * 2);
  this.bl_tree    = new utils.Buf16((2 * BL_CODES + 1) * 2);
  zero(this.dyn_ltree);
  zero(this.dyn_dtree);
  zero(this.bl_tree);

  this.l_desc   = null;         /* desc. for literal tree */
  this.d_desc   = null;         /* desc. for distance tree */
  this.bl_desc  = null;         /* desc. for bit length tree */

  //ush bl_count[MAX_BITS+1];
  this.bl_count = new utils.Buf16(MAX_BITS + 1);
  /* number of codes at each bit length for an optimal tree */

  //int heap[2*L_CODES+1];      /* heap used to build the Huffman trees */
  this.heap = new utils.Buf16(2 * L_CODES + 1);  /* heap used to build the Huffman trees */
  zero(this.heap);

  this.heap_len = 0;               /* number of elements in the heap */
  this.heap_max = 0;               /* element of largest frequency */
  /* The sons of heap[n] are heap[2*n] and heap[2*n+1]. heap[0] is not used.
   * The same heap array is used to build all trees.
   */

  this.depth = new utils.Buf16(2 * L_CODES + 1); //uch depth[2*L_CODES+1];
  zero(this.depth);
  /* Depth of each subtree used as tie breaker for trees of equal frequency
   */

  this.l_buf = 0;          /* buffer index for literals or lengths */

  this.lit_bufsize = 0;
  /* Size of match buffer for literals/lengths.  There are 4 reasons for
   * limiting lit_bufsize to 64K:
   *   - frequencies can be kept in 16 bit counters
   *   - if compression is not successful for the first block, all input
   *     data is still in the window so we can still emit a stored block even
   *     when input comes from standard input.  (This can also be done for
   *     all blocks if lit_bufsize is not greater than 32K.)
   *   - if compression is not successful for a file smaller than 64K, we can
   *     even emit a stored file instead of a stored block (saving 5 bytes).
   *     This is applicable only for zip (not gzip or zlib).
   *   - creating new Huffman trees less frequently may not provide fast
   *     adaptation to changes in the input data statistics. (Take for
   *     example a binary file with poorly compressible code followed by
   *     a highly compressible string table.) Smaller buffer sizes give
   *     fast adaptation but have of course the overhead of transmitting
   *     trees more frequently.
   *   - I can't count above 4
   */

  this.last_lit = 0;      /* running index in l_buf */

  this.d_buf = 0;
  /* Buffer index for distances. To simplify the code, d_buf and l_buf have
   * the same number of elements. To use different lengths, an extra flag
   * array would be necessary.
   */

  this.opt_len = 0;       /* bit length of current block with optimal trees */
  this.static_len = 0;    /* bit length of current block with static trees */
  this.matches = 0;       /* number of string matches in current block */
  this.insert = 0;        /* bytes at end of window left to insert */


  this.bi_buf = 0;
  /* Output buffer. bits are inserted starting at the bottom (least
   * significant bits).
   */
  this.bi_valid = 0;
  /* Number of valid bits in bi_buf.  All bits above the last valid bit
   * are always zero.
   */

  // Used for window memory init. We safely ignore it for JS. That makes
  // sense only for pointers and memory check tools.
  //this.high_water = 0;
  /* High water mark offset in window for initialized bytes -- bytes above
   * this are set to zero in order to avoid memory check warnings when
   * longest match routines access bytes past the input.  This is then
   * updated to the new high water mark.
   */
}


function deflateResetKeep(strm) {
  var s;

  if (!strm || !strm.state) {
    return err(strm, Z_STREAM_ERROR);
  }

  strm.total_in = strm.total_out = 0;
  strm.data_type = Z_UNKNOWN;

  s = strm.state;
  s.pending = 0;
  s.pending_out = 0;

  if (s.wrap < 0) {
    s.wrap = -s.wrap;
    /* was made negative by deflate(..., Z_FINISH); */
  }
  s.status = (s.wrap ? INIT_STATE : BUSY_STATE);
  strm.adler = (s.wrap === 2) ?
    0  // crc32(0, Z_NULL, 0)
  :
    1; // adler32(0, Z_NULL, 0)
  s.last_flush = Z_NO_FLUSH;
  trees._tr_init(s);
  return Z_OK;
}


function deflateReset(strm) {
  var ret = deflateResetKeep(strm);
  if (ret === Z_OK) {
    lm_init(strm.state);
  }
  return ret;
}


function deflateSetHeader(strm, head) {
  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  if (strm.state.wrap !== 2) { return Z_STREAM_ERROR; }
  strm.state.gzhead = head;
  return Z_OK;
}


function deflateInit2(strm, level, method, windowBits, memLevel, strategy) {
  if (!strm) { // === Z_NULL
    return Z_STREAM_ERROR;
  }
  var wrap = 1;

  if (level === Z_DEFAULT_COMPRESSION) {
    level = 6;
  }

  if (windowBits < 0) { /* suppress zlib wrapper */
    wrap = 0;
    windowBits = -windowBits;
  }

  else if (windowBits > 15) {
    wrap = 2;           /* write gzip wrapper instead */
    windowBits -= 16;
  }


  if (memLevel < 1 || memLevel > MAX_MEM_LEVEL || method !== Z_DEFLATED ||
    windowBits < 8 || windowBits > 15 || level < 0 || level > 9 ||
    strategy < 0 || strategy > Z_FIXED) {
    return err(strm, Z_STREAM_ERROR);
  }


  if (windowBits === 8) {
    windowBits = 9;
  }
  /* until 256-byte window bug fixed */

  var s = new DeflateState();

  strm.state = s;
  s.strm = strm;

  s.wrap = wrap;
  s.gzhead = null;
  s.w_bits = windowBits;
  s.w_size = 1 << s.w_bits;
  s.w_mask = s.w_size - 1;

  s.hash_bits = memLevel + 7;
  s.hash_size = 1 << s.hash_bits;
  s.hash_mask = s.hash_size - 1;
  s.hash_shift = ~~((s.hash_bits + MIN_MATCH - 1) / MIN_MATCH);

  s.window = new utils.Buf8(s.w_size * 2);
  s.head = new utils.Buf16(s.hash_size);
  s.prev = new utils.Buf16(s.w_size);

  // Don't need mem init magic for JS.
  //s.high_water = 0;  /* nothing written to s->window yet */

  s.lit_bufsize = 1 << (memLevel + 6); /* 16K elements by default */

  s.pending_buf_size = s.lit_bufsize * 4;

  //overlay = (ushf *) ZALLOC(strm, s->lit_bufsize, sizeof(ush)+2);
  //s->pending_buf = (uchf *) overlay;
  s.pending_buf = new utils.Buf8(s.pending_buf_size);

  // It is offset from `s.pending_buf` (size is `s.lit_bufsize * 2`)
  //s->d_buf = overlay + s->lit_bufsize/sizeof(ush);
  s.d_buf = 1 * s.lit_bufsize;

  //s->l_buf = s->pending_buf + (1+sizeof(ush))*s->lit_bufsize;
  s.l_buf = (1 + 2) * s.lit_bufsize;

  s.level = level;
  s.strategy = strategy;
  s.method = method;

  return deflateReset(strm);
}

function deflateInit(strm, level) {
  return deflateInit2(strm, level, Z_DEFLATED, MAX_WBITS, DEF_MEM_LEVEL, Z_DEFAULT_STRATEGY);
}


function deflate(strm, flush) {
  var old_flush, s;
  var beg, val; // for gzip header write only

  if (!strm || !strm.state ||
    flush > Z_BLOCK || flush < 0) {
    return strm ? err(strm, Z_STREAM_ERROR) : Z_STREAM_ERROR;
  }

  s = strm.state;

  if (!strm.output ||
      (!strm.input && strm.avail_in !== 0) ||
      (s.status === FINISH_STATE && flush !== Z_FINISH)) {
    return err(strm, (strm.avail_out === 0) ? Z_BUF_ERROR : Z_STREAM_ERROR);
  }

  s.strm = strm; /* just in case */
  old_flush = s.last_flush;
  s.last_flush = flush;

  /* Write the header */
  if (s.status === INIT_STATE) {

    if (s.wrap === 2) { // GZIP header
      strm.adler = 0;  //crc32(0L, Z_NULL, 0);
      put_byte(s, 31);
      put_byte(s, 139);
      put_byte(s, 8);
      if (!s.gzhead) { // s->gzhead == Z_NULL
        put_byte(s, 0);
        put_byte(s, 0);
        put_byte(s, 0);
        put_byte(s, 0);
        put_byte(s, 0);
        put_byte(s, s.level === 9 ? 2 :
                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?
                     4 : 0));
        put_byte(s, OS_CODE);
        s.status = BUSY_STATE;
      }
      else {
        put_byte(s, (s.gzhead.text ? 1 : 0) +
                    (s.gzhead.hcrc ? 2 : 0) +
                    (!s.gzhead.extra ? 0 : 4) +
                    (!s.gzhead.name ? 0 : 8) +
                    (!s.gzhead.comment ? 0 : 16)
        );
        put_byte(s, s.gzhead.time & 0xff);
        put_byte(s, (s.gzhead.time >> 8) & 0xff);
        put_byte(s, (s.gzhead.time >> 16) & 0xff);
        put_byte(s, (s.gzhead.time >> 24) & 0xff);
        put_byte(s, s.level === 9 ? 2 :
                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?
                     4 : 0));
        put_byte(s, s.gzhead.os & 0xff);
        if (s.gzhead.extra && s.gzhead.extra.length) {
          put_byte(s, s.gzhead.extra.length & 0xff);
          put_byte(s, (s.gzhead.extra.length >> 8) & 0xff);
        }
        if (s.gzhead.hcrc) {
          strm.adler = crc32(strm.adler, s.pending_buf, s.pending, 0);
        }
        s.gzindex = 0;
        s.status = EXTRA_STATE;
      }
    }
    else // DEFLATE header
    {
      var header = (Z_DEFLATED + ((s.w_bits - 8) << 4)) << 8;
      var level_flags = -1;

      if (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2) {
        level_flags = 0;
      } else if (s.level < 6) {
        level_flags = 1;
      } else if (s.level === 6) {
        level_flags = 2;
      } else {
        level_flags = 3;
      }
      header |= (level_flags << 6);
      if (s.strstart !== 0) { header |= PRESET_DICT; }
      header += 31 - (header % 31);

      s.status = BUSY_STATE;
      putShortMSB(s, header);

      /* Save the adler32 of the preset dictionary: */
      if (s.strstart !== 0) {
        putShortMSB(s, strm.adler >>> 16);
        putShortMSB(s, strm.adler & 0xffff);
      }
      strm.adler = 1; // adler32(0L, Z_NULL, 0);
    }
  }

//#ifdef GZIP
  if (s.status === EXTRA_STATE) {
    if (s.gzhead.extra/* != Z_NULL*/) {
      beg = s.pending;  /* start of bytes to update crc */

      while (s.gzindex < (s.gzhead.extra.length & 0xffff)) {
        if (s.pending === s.pending_buf_size) {
          if (s.gzhead.hcrc && s.pending > beg) {
            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
          }
          flush_pending(strm);
          beg = s.pending;
          if (s.pending === s.pending_buf_size) {
            break;
          }
        }
        put_byte(s, s.gzhead.extra[s.gzindex] & 0xff);
        s.gzindex++;
      }
      if (s.gzhead.hcrc && s.pending > beg) {
        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
      }
      if (s.gzindex === s.gzhead.extra.length) {
        s.gzindex = 0;
        s.status = NAME_STATE;
      }
    }
    else {
      s.status = NAME_STATE;
    }
  }
  if (s.status === NAME_STATE) {
    if (s.gzhead.name/* != Z_NULL*/) {
      beg = s.pending;  /* start of bytes to update crc */
      //int val;

      do {
        if (s.pending === s.pending_buf_size) {
          if (s.gzhead.hcrc && s.pending > beg) {
            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
          }
          flush_pending(strm);
          beg = s.pending;
          if (s.pending === s.pending_buf_size) {
            val = 1;
            break;
          }
        }
        // JS specific: little magic to add zero terminator to end of string
        if (s.gzindex < s.gzhead.name.length) {
          val = s.gzhead.name.charCodeAt(s.gzindex++) & 0xff;
        } else {
          val = 0;
        }
        put_byte(s, val);
      } while (val !== 0);

      if (s.gzhead.hcrc && s.pending > beg) {
        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
      }
      if (val === 0) {
        s.gzindex = 0;
        s.status = COMMENT_STATE;
      }
    }
    else {
      s.status = COMMENT_STATE;
    }
  }
  if (s.status === COMMENT_STATE) {
    if (s.gzhead.comment/* != Z_NULL*/) {
      beg = s.pending;  /* start of bytes to update crc */
      //int val;

      do {
        if (s.pending === s.pending_buf_size) {
          if (s.gzhead.hcrc && s.pending > beg) {
            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
          }
          flush_pending(strm);
          beg = s.pending;
          if (s.pending === s.pending_buf_size) {
            val = 1;
            break;
          }
        }
        // JS specific: little magic to add zero terminator to end of string
        if (s.gzindex < s.gzhead.comment.length) {
          val = s.gzhead.comment.charCodeAt(s.gzindex++) & 0xff;
        } else {
          val = 0;
        }
        put_byte(s, val);
      } while (val !== 0);

      if (s.gzhead.hcrc && s.pending > beg) {
        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
      }
      if (val === 0) {
        s.status = HCRC_STATE;
      }
    }
    else {
      s.status = HCRC_STATE;
    }
  }
  if (s.status === HCRC_STATE) {
    if (s.gzhead.hcrc) {
      if (s.pending + 2 > s.pending_buf_size) {
        flush_pending(strm);
      }
      if (s.pending + 2 <= s.pending_buf_size) {
        put_byte(s, strm.adler & 0xff);
        put_byte(s, (strm.adler >> 8) & 0xff);
        strm.adler = 0; //crc32(0L, Z_NULL, 0);
        s.status = BUSY_STATE;
      }
    }
    else {
      s.status = BUSY_STATE;
    }
  }
//#endif

  /* Flush as much pending output as possible */
  if (s.pending !== 0) {
    flush_pending(strm);
    if (strm.avail_out === 0) {
      /* Since avail_out is 0, deflate will be called again with
       * more output space, but possibly with both pending and
       * avail_in equal to zero. There won't be anything to do,
       * but this is not an error situation so make sure we
       * return OK instead of BUF_ERROR at next call of deflate:
       */
      s.last_flush = -1;
      return Z_OK;
    }

    /* Make sure there is something to do and avoid duplicate consecutive
     * flushes. For repeated and useless calls with Z_FINISH, we keep
     * returning Z_STREAM_END instead of Z_BUF_ERROR.
     */
  } else if (strm.avail_in === 0 && rank(flush) <= rank(old_flush) &&
    flush !== Z_FINISH) {
    return err(strm, Z_BUF_ERROR);
  }

  /* User must not provide more input after the first FINISH: */
  if (s.status === FINISH_STATE && strm.avail_in !== 0) {
    return err(strm, Z_BUF_ERROR);
  }

  /* Start a new block or continue the current one.
   */
  if (strm.avail_in !== 0 || s.lookahead !== 0 ||
    (flush !== Z_NO_FLUSH && s.status !== FINISH_STATE)) {
    var bstate = (s.strategy === Z_HUFFMAN_ONLY) ? deflate_huff(s, flush) :
      (s.strategy === Z_RLE ? deflate_rle(s, flush) :
        configuration_table[s.level].func(s, flush));

    if (bstate === BS_FINISH_STARTED || bstate === BS_FINISH_DONE) {
      s.status = FINISH_STATE;
    }
    if (bstate === BS_NEED_MORE || bstate === BS_FINISH_STARTED) {
      if (strm.avail_out === 0) {
        s.last_flush = -1;
        /* avoid BUF_ERROR next call, see above */
      }
      return Z_OK;
      /* If flush != Z_NO_FLUSH && avail_out == 0, the next call
       * of deflate should use the same flush parameter to make sure
       * that the flush is complete. So we don't have to output an
       * empty block here, this will be done at next call. This also
       * ensures that for a very small output buffer, we emit at most
       * one empty block.
       */
    }
    if (bstate === BS_BLOCK_DONE) {
      if (flush === Z_PARTIAL_FLUSH) {
        trees._tr_align(s);
      }
      else if (flush !== Z_BLOCK) { /* FULL_FLUSH or SYNC_FLUSH */

        trees._tr_stored_block(s, 0, 0, false);
        /* For a full flush, this empty block will be recognized
         * as a special marker by inflate_sync().
         */
        if (flush === Z_FULL_FLUSH) {
          /*** CLEAR_HASH(s); ***/             /* forget history */
          zero(s.head); // Fill with NIL (= 0);

          if (s.lookahead === 0) {
            s.strstart = 0;
            s.block_start = 0;
            s.insert = 0;
          }
        }
      }
      flush_pending(strm);
      if (strm.avail_out === 0) {
        s.last_flush = -1; /* avoid BUF_ERROR at next call, see above */
        return Z_OK;
      }
    }
  }
  //Assert(strm->avail_out > 0, "bug2");
  //if (strm.avail_out <= 0) { throw new Error("bug2");}

  if (flush !== Z_FINISH) { return Z_OK; }
  if (s.wrap <= 0) { return Z_STREAM_END; }

  /* Write the trailer */
  if (s.wrap === 2) {
    put_byte(s, strm.adler & 0xff);
    put_byte(s, (strm.adler >> 8) & 0xff);
    put_byte(s, (strm.adler >> 16) & 0xff);
    put_byte(s, (strm.adler >> 24) & 0xff);
    put_byte(s, strm.total_in & 0xff);
    put_byte(s, (strm.total_in >> 8) & 0xff);
    put_byte(s, (strm.total_in >> 16) & 0xff);
    put_byte(s, (strm.total_in >> 24) & 0xff);
  }
  else
  {
    putShortMSB(s, strm.adler >>> 16);
    putShortMSB(s, strm.adler & 0xffff);
  }

  flush_pending(strm);
  /* If avail_out is zero, the application will call deflate again
   * to flush the rest.
   */
  if (s.wrap > 0) { s.wrap = -s.wrap; }
  /* write the trailer only once! */
  return s.pending !== 0 ? Z_OK : Z_STREAM_END;
}

function deflateEnd(strm) {
  var status;

  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {
    return Z_STREAM_ERROR;
  }

  status = strm.state.status;
  if (status !== INIT_STATE &&
    status !== EXTRA_STATE &&
    status !== NAME_STATE &&
    status !== COMMENT_STATE &&
    status !== HCRC_STATE &&
    status !== BUSY_STATE &&
    status !== FINISH_STATE
  ) {
    return err(strm, Z_STREAM_ERROR);
  }

  strm.state = null;

  return status === BUSY_STATE ? err(strm, Z_DATA_ERROR) : Z_OK;
}


/* =========================================================================
 * Initializes the compression dictionary from the given byte
 * sequence without producing any compressed output.
 */
function deflateSetDictionary(strm, dictionary) {
  var dictLength = dictionary.length;

  var s;
  var str, n;
  var wrap;
  var avail;
  var next;
  var input;
  var tmpDict;

  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {
    return Z_STREAM_ERROR;
  }

  s = strm.state;
  wrap = s.wrap;

  if (wrap === 2 || (wrap === 1 && s.status !== INIT_STATE) || s.lookahead) {
    return Z_STREAM_ERROR;
  }

  /* when using zlib wrappers, compute Adler-32 for provided dictionary */
  if (wrap === 1) {
    /* adler32(strm->adler, dictionary, dictLength); */
    strm.adler = adler32(strm.adler, dictionary, dictLength, 0);
  }

  s.wrap = 0;   /* avoid computing Adler-32 in read_buf */

  /* if dictionary would fill window, just replace the history */
  if (dictLength >= s.w_size) {
    if (wrap === 0) {            /* already empty otherwise */
      /*** CLEAR_HASH(s); ***/
      zero(s.head); // Fill with NIL (= 0);
      s.strstart = 0;
      s.block_start = 0;
      s.insert = 0;
    }
    /* use the tail */
    // dictionary = dictionary.slice(dictLength - s.w_size);
    tmpDict = new utils.Buf8(s.w_size);
    utils.arraySet(tmpDict, dictionary, dictLength - s.w_size, s.w_size, 0);
    dictionary = tmpDict;
    dictLength = s.w_size;
  }
  /* insert dictionary into window and hash */
  avail = strm.avail_in;
  next = strm.next_in;
  input = strm.input;
  strm.avail_in = dictLength;
  strm.next_in = 0;
  strm.input = dictionary;
  fill_window(s);
  while (s.lookahead >= MIN_MATCH) {
    str = s.strstart;
    n = s.lookahead - (MIN_MATCH - 1);
    do {
      /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */
      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;

      s.prev[str & s.w_mask] = s.head[s.ins_h];

      s.head[s.ins_h] = str;
      str++;
    } while (--n);
    s.strstart = str;
    s.lookahead = MIN_MATCH - 1;
    fill_window(s);
  }
  s.strstart += s.lookahead;
  s.block_start = s.strstart;
  s.insert = s.lookahead;
  s.lookahead = 0;
  s.match_length = s.prev_length = MIN_MATCH - 1;
  s.match_available = 0;
  strm.next_in = next;
  strm.input = input;
  strm.avail_in = avail;
  s.wrap = wrap;
  return Z_OK;
}


exports.deflateInit = deflateInit;
exports.deflateInit2 = deflateInit2;
exports.deflateReset = deflateReset;
exports.deflateResetKeep = deflateResetKeep;
exports.deflateSetHeader = deflateSetHeader;
exports.deflate = deflate;
exports.deflateEnd = deflateEnd;
exports.deflateSetDictionary = deflateSetDictionary;
exports.deflateInfo = 'pako deflate (from Nodeca project)';

/* Not implemented
exports.deflateBound = deflateBound;
exports.deflateCopy = deflateCopy;
exports.deflateParams = deflateParams;
exports.deflatePending = deflatePending;
exports.deflatePrime = deflatePrime;
exports.deflateTune = deflateTune;
*/


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/gzheader.js":
/*!************************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/gzheader.js ***!
  \************************************************************************/
/***/ (function(module) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

function GZheader() {
  /* true if compressed data believed to be text */
  this.text       = 0;
  /* modification time */
  this.time       = 0;
  /* extra flags (not used when writing a gzip file) */
  this.xflags     = 0;
  /* operating system */
  this.os         = 0;
  /* pointer to extra field or Z_NULL if none */
  this.extra      = null;
  /* extra field length (valid if extra != Z_NULL) */
  this.extra_len  = 0; // Actually, we don't need it in JS,
                       // but leave for few code modifications

  //
  // Setup limits is not necessary because in js we should not preallocate memory
  // for inflate use constant limit in 65536 bytes
  //

  /* space at extra (only when reading header) */
  // this.extra_max  = 0;
  /* pointer to zero-terminated file name or Z_NULL */
  this.name       = '';
  /* space at name (only when reading header) */
  // this.name_max   = 0;
  /* pointer to zero-terminated comment or Z_NULL */
  this.comment    = '';
  /* space at comment (only when reading header) */
  // this.comm_max   = 0;
  /* true if there was or will be a header crc */
  this.hcrc       = 0;
  /* true when done reading gzip header (not used when writing a gzip file) */
  this.done       = false;
}

module.exports = GZheader;


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inffast.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inffast.js ***!
  \***********************************************************************/
/***/ (function(module) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

// See state defs from inflate.js
var BAD = 30;       /* got a data error -- remain here until reset */
var TYPE = 12;      /* i: waiting for type bits, including last-flag bit */

/*
   Decode literal, length, and distance codes and write out the resulting
   literal and match bytes until either not enough input or output is
   available, an end-of-block is encountered, or a data error is encountered.
   When large enough input and output buffers are supplied to inflate(), for
   example, a 16K input buffer and a 64K output buffer, more than 95% of the
   inflate execution time is spent in this routine.

   Entry assumptions:

        state.mode === LEN
        strm.avail_in >= 6
        strm.avail_out >= 258
        start >= strm.avail_out
        state.bits < 8

   On return, state.mode is one of:

        LEN -- ran out of enough output space or enough available input
        TYPE -- reached end of block code, inflate() to interpret next block
        BAD -- error in block data

   Notes:

    - The maximum input bits used by a length/distance pair is 15 bits for the
      length code, 5 bits for the length extra, 15 bits for the distance code,
      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.
      Therefore if strm.avail_in >= 6, then there is enough input to avoid
      checking for available input while decoding.

    - The maximum bytes that a single length/distance pair can output is 258
      bytes, which is the maximum length that can be coded.  inflate_fast()
      requires strm.avail_out >= 258 for each loop to avoid checking for
      output space.
 */
module.exports = function inflate_fast(strm, start) {
  var state;
  var _in;                    /* local strm.input */
  var last;                   /* have enough input while in < last */
  var _out;                   /* local strm.output */
  var beg;                    /* inflate()'s initial strm.output */
  var end;                    /* while out < end, enough space available */
//#ifdef INFLATE_STRICT
  var dmax;                   /* maximum distance from zlib header */
//#endif
  var wsize;                  /* window size or zero if not using window */
  var whave;                  /* valid bytes in the window */
  var wnext;                  /* window write index */
  // Use `s_window` instead `window`, avoid conflict with instrumentation tools
  var s_window;               /* allocated sliding window, if wsize != 0 */
  var hold;                   /* local strm.hold */
  var bits;                   /* local strm.bits */
  var lcode;                  /* local strm.lencode */
  var dcode;                  /* local strm.distcode */
  var lmask;                  /* mask for first level of length codes */
  var dmask;                  /* mask for first level of distance codes */
  var here;                   /* retrieved table entry */
  var op;                     /* code bits, operation, extra bits, or */
                              /*  window position, window bytes to copy */
  var len;                    /* match length, unused bytes */
  var dist;                   /* match distance */
  var from;                   /* where to copy match from */
  var from_source;


  var input, output; // JS specific, because we have no pointers

  /* copy state to local variables */
  state = strm.state;
  //here = state.here;
  _in = strm.next_in;
  input = strm.input;
  last = _in + (strm.avail_in - 5);
  _out = strm.next_out;
  output = strm.output;
  beg = _out - (start - strm.avail_out);
  end = _out + (strm.avail_out - 257);
//#ifdef INFLATE_STRICT
  dmax = state.dmax;
//#endif
  wsize = state.wsize;
  whave = state.whave;
  wnext = state.wnext;
  s_window = state.window;
  hold = state.hold;
  bits = state.bits;
  lcode = state.lencode;
  dcode = state.distcode;
  lmask = (1 << state.lenbits) - 1;
  dmask = (1 << state.distbits) - 1;


  /* decode literals and length/distances until end-of-block or not enough
     input data or output space */

  top:
  do {
    if (bits < 15) {
      hold += input[_in++] << bits;
      bits += 8;
      hold += input[_in++] << bits;
      bits += 8;
    }

    here = lcode[hold & lmask];

    dolen:
    for (;;) { // Goto emulation
      op = here >>> 24/*here.bits*/;
      hold >>>= op;
      bits -= op;
      op = (here >>> 16) & 0xff/*here.op*/;
      if (op === 0) {                          /* literal */
        //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?
        //        "inflate:         literal '%c'\n" :
        //        "inflate:         literal 0x%02x\n", here.val));
        output[_out++] = here & 0xffff/*here.val*/;
      }
      else if (op & 16) {                     /* length base */
        len = here & 0xffff/*here.val*/;
        op &= 15;                           /* number of extra bits */
        if (op) {
          if (bits < op) {
            hold += input[_in++] << bits;
            bits += 8;
          }
          len += hold & ((1 << op) - 1);
          hold >>>= op;
          bits -= op;
        }
        //Tracevv((stderr, "inflate:         length %u\n", len));
        if (bits < 15) {
          hold += input[_in++] << bits;
          bits += 8;
          hold += input[_in++] << bits;
          bits += 8;
        }
        here = dcode[hold & dmask];

        dodist:
        for (;;) { // goto emulation
          op = here >>> 24/*here.bits*/;
          hold >>>= op;
          bits -= op;
          op = (here >>> 16) & 0xff/*here.op*/;

          if (op & 16) {                      /* distance base */
            dist = here & 0xffff/*here.val*/;
            op &= 15;                       /* number of extra bits */
            if (bits < op) {
              hold += input[_in++] << bits;
              bits += 8;
              if (bits < op) {
                hold += input[_in++] << bits;
                bits += 8;
              }
            }
            dist += hold & ((1 << op) - 1);
//#ifdef INFLATE_STRICT
            if (dist > dmax) {
              strm.msg = 'invalid distance too far back';
              state.mode = BAD;
              break top;
            }
//#endif
            hold >>>= op;
            bits -= op;
            //Tracevv((stderr, "inflate:         distance %u\n", dist));
            op = _out - beg;                /* max distance in output */
            if (dist > op) {                /* see if copy from window */
              op = dist - op;               /* distance back in window */
              if (op > whave) {
                if (state.sane) {
                  strm.msg = 'invalid distance too far back';
                  state.mode = BAD;
                  break top;
                }

// (!) This block is disabled in zlib defaults,
// don't enable it for binary compatibility
//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR
//                if (len <= op - whave) {
//                  do {
//                    output[_out++] = 0;
//                  } while (--len);
//                  continue top;
//                }
//                len -= op - whave;
//                do {
//                  output[_out++] = 0;
//                } while (--op > whave);
//                if (op === 0) {
//                  from = _out - dist;
//                  do {
//                    output[_out++] = output[from++];
//                  } while (--len);
//                  continue top;
//                }
//#endif
              }
              from = 0; // window index
              from_source = s_window;
              if (wnext === 0) {           /* very common case */
                from += wsize - op;
                if (op < len) {         /* some from window */
                  len -= op;
                  do {
                    output[_out++] = s_window[from++];
                  } while (--op);
                  from = _out - dist;  /* rest from output */
                  from_source = output;
                }
              }
              else if (wnext < op) {      /* wrap around window */
                from += wsize + wnext - op;
                op -= wnext;
                if (op < len) {         /* some from end of window */
                  len -= op;
                  do {
                    output[_out++] = s_window[from++];
                  } while (--op);
                  from = 0;
                  if (wnext < len) {  /* some from start of window */
                    op = wnext;
                    len -= op;
                    do {
                      output[_out++] = s_window[from++];
                    } while (--op);
                    from = _out - dist;      /* rest from output */
                    from_source = output;
                  }
                }
              }
              else {                      /* contiguous in window */
                from += wnext - op;
                if (op < len) {         /* some from window */
                  len -= op;
                  do {
                    output[_out++] = s_window[from++];
                  } while (--op);
                  from = _out - dist;  /* rest from output */
                  from_source = output;
                }
              }
              while (len > 2) {
                output[_out++] = from_source[from++];
                output[_out++] = from_source[from++];
                output[_out++] = from_source[from++];
                len -= 3;
              }
              if (len) {
                output[_out++] = from_source[from++];
                if (len > 1) {
                  output[_out++] = from_source[from++];
                }
              }
            }
            else {
              from = _out - dist;          /* copy direct from output */
              do {                        /* minimum length is three */
                output[_out++] = output[from++];
                output[_out++] = output[from++];
                output[_out++] = output[from++];
                len -= 3;
              } while (len > 2);
              if (len) {
                output[_out++] = output[from++];
                if (len > 1) {
                  output[_out++] = output[from++];
                }
              }
            }
          }
          else if ((op & 64) === 0) {          /* 2nd level distance code */
            here = dcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];
            continue dodist;
          }
          else {
            strm.msg = 'invalid distance code';
            state.mode = BAD;
            break top;
          }

          break; // need to emulate goto via "continue"
        }
      }
      else if ((op & 64) === 0) {              /* 2nd level length code */
        here = lcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];
        continue dolen;
      }
      else if (op & 32) {                     /* end-of-block */
        //Tracevv((stderr, "inflate:         end of block\n"));
        state.mode = TYPE;
        break top;
      }
      else {
        strm.msg = 'invalid literal/length code';
        state.mode = BAD;
        break top;
      }

      break; // need to emulate goto via "continue"
    }
  } while (_in < last && _out < end);

  /* return unused bytes (on entry, bits < 8, so in won't go too far back) */
  len = bits >> 3;
  _in -= len;
  bits -= len << 3;
  hold &= (1 << bits) - 1;

  /* update state and return */
  strm.next_in = _in;
  strm.next_out = _out;
  strm.avail_in = (_in < last ? 5 + (last - _in) : 5 - (_in - last));
  strm.avail_out = (_out < end ? 257 + (end - _out) : 257 - (_out - end));
  state.hold = hold;
  state.bits = bits;
  return;
};


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inflate.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inflate.js ***!
  \***********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

var utils         = __webpack_require__(/*! ../utils/common */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js");
var adler32       = __webpack_require__(/*! ./adler32 */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/adler32.js");
var crc32         = __webpack_require__(/*! ./crc32 */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/crc32.js");
var inflate_fast  = __webpack_require__(/*! ./inffast */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inffast.js");
var inflate_table = __webpack_require__(/*! ./inftrees */ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inftrees.js");

var CODES = 0;
var LENS = 1;
var DISTS = 2;

/* Public constants ==========================================================*/
/* ===========================================================================*/


/* Allowed flush values; see deflate() and inflate() below for details */
//var Z_NO_FLUSH      = 0;
//var Z_PARTIAL_FLUSH = 1;
//var Z_SYNC_FLUSH    = 2;
//var Z_FULL_FLUSH    = 3;
var Z_FINISH        = 4;
var Z_BLOCK         = 5;
var Z_TREES         = 6;


/* Return codes for the compression/decompression functions. Negative values
 * are errors, positive values are used for special but normal events.
 */
var Z_OK            = 0;
var Z_STREAM_END    = 1;
var Z_NEED_DICT     = 2;
//var Z_ERRNO         = -1;
var Z_STREAM_ERROR  = -2;
var Z_DATA_ERROR    = -3;
var Z_MEM_ERROR     = -4;
var Z_BUF_ERROR     = -5;
//var Z_VERSION_ERROR = -6;

/* The deflate compression method */
var Z_DEFLATED  = 8;


/* STATES ====================================================================*/
/* ===========================================================================*/


var    HEAD = 1;       /* i: waiting for magic header */
var    FLAGS = 2;      /* i: waiting for method and flags (gzip) */
var    TIME = 3;       /* i: waiting for modification time (gzip) */
var    OS = 4;         /* i: waiting for extra flags and operating system (gzip) */
var    EXLEN = 5;      /* i: waiting for extra length (gzip) */
var    EXTRA = 6;      /* i: waiting for extra bytes (gzip) */
var    NAME = 7;       /* i: waiting for end of file name (gzip) */
var    COMMENT = 8;    /* i: waiting for end of comment (gzip) */
var    HCRC = 9;       /* i: waiting for header crc (gzip) */
var    DICTID = 10;    /* i: waiting for dictionary check value */
var    DICT = 11;      /* waiting for inflateSetDictionary() call */
var        TYPE = 12;      /* i: waiting for type bits, including last-flag bit */
var        TYPEDO = 13;    /* i: same, but skip check to exit inflate on new block */
var        STORED = 14;    /* i: waiting for stored size (length and complement) */
var        COPY_ = 15;     /* i/o: same as COPY below, but only first time in */
var        COPY = 16;      /* i/o: waiting for input or output to copy stored block */
var        TABLE = 17;     /* i: waiting for dynamic block table lengths */
var        LENLENS = 18;   /* i: waiting for code length code lengths */
var        CODELENS = 19;  /* i: waiting for length/lit and distance code lengths */
var            LEN_ = 20;      /* i: same as LEN below, but only first time in */
var            LEN = 21;       /* i: waiting for length/lit/eob code */
var            LENEXT = 22;    /* i: waiting for length extra bits */
var            DIST = 23;      /* i: waiting for distance code */
var            DISTEXT = 24;   /* i: waiting for distance extra bits */
var            MATCH = 25;     /* o: waiting for output space to copy string */
var            LIT = 26;       /* o: waiting for output space to write literal */
var    CHECK = 27;     /* i: waiting for 32-bit check value */
var    LENGTH = 28;    /* i: waiting for 32-bit length (gzip) */
var    DONE = 29;      /* finished check, done -- remain here until reset */
var    BAD = 30;       /* got a data error -- remain here until reset */
var    MEM = 31;       /* got an inflate() memory error -- remain here until reset */
var    SYNC = 32;      /* looking for synchronization bytes to restart inflate() */

/* ===========================================================================*/



var ENOUGH_LENS = 852;
var ENOUGH_DISTS = 592;
//var ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);

var MAX_WBITS = 15;
/* 32K LZ77 window */
var DEF_WBITS = MAX_WBITS;


function zswap32(q) {
  return  (((q >>> 24) & 0xff) +
          ((q >>> 8) & 0xff00) +
          ((q & 0xff00) << 8) +
          ((q & 0xff) << 24));
}


function InflateState() {
  this.mode = 0;             /* current inflate mode */
  this.last = false;          /* true if processing last block */
  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */
  this.havedict = false;      /* true if dictionary provided */
  this.flags = 0;             /* gzip header method and flags (0 if zlib) */
  this.dmax = 0;              /* zlib header max distance (INFLATE_STRICT) */
  this.check = 0;             /* protected copy of check value */
  this.total = 0;             /* protected copy of output count */
  // TODO: may be {}
  this.head = null;           /* where to save gzip header information */

  /* sliding window */
  this.wbits = 0;             /* log base 2 of requested window size */
  this.wsize = 0;             /* window size or zero if not using window */
  this.whave = 0;             /* valid bytes in the window */
  this.wnext = 0;             /* window write index */
  this.window = null;         /* allocated sliding window, if needed */

  /* bit accumulator */
  this.hold = 0;              /* input bit accumulator */
  this.bits = 0;              /* number of bits in "in" */

  /* for string and stored block copying */
  this.length = 0;            /* literal or length of data to copy */
  this.offset = 0;            /* distance back to copy string from */

  /* for table and code decoding */
  this.extra = 0;             /* extra bits needed */

  /* fixed and dynamic code tables */
  this.lencode = null;          /* starting table for length/literal codes */
  this.distcode = null;         /* starting table for distance codes */
  this.lenbits = 0;           /* index bits for lencode */
  this.distbits = 0;          /* index bits for distcode */

  /* dynamic table building */
  this.ncode = 0;             /* number of code length code lengths */
  this.nlen = 0;              /* number of length code lengths */
  this.ndist = 0;             /* number of distance code lengths */
  this.have = 0;              /* number of code lengths in lens[] */
  this.next = null;              /* next available space in codes[] */

  this.lens = new utils.Buf16(320); /* temporary storage for code lengths */
  this.work = new utils.Buf16(288); /* work area for code table building */

  /*
   because we don't have pointers in js, we use lencode and distcode directly
   as buffers so we don't need codes
  */
  //this.codes = new utils.Buf32(ENOUGH);       /* space for code tables */
  this.lendyn = null;              /* dynamic table for length/literal codes (JS specific) */
  this.distdyn = null;             /* dynamic table for distance codes (JS specific) */
  this.sane = 0;                   /* if false, allow invalid distance too far */
  this.back = 0;                   /* bits back of last unprocessed length/lit */
  this.was = 0;                    /* initial length of match */
}

function inflateResetKeep(strm) {
  var state;

  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  state = strm.state;
  strm.total_in = strm.total_out = state.total = 0;
  strm.msg = ''; /*Z_NULL*/
  if (state.wrap) {       /* to support ill-conceived Java test suite */
    strm.adler = state.wrap & 1;
  }
  state.mode = HEAD;
  state.last = 0;
  state.havedict = 0;
  state.dmax = 32768;
  state.head = null/*Z_NULL*/;
  state.hold = 0;
  state.bits = 0;
  //state.lencode = state.distcode = state.next = state.codes;
  state.lencode = state.lendyn = new utils.Buf32(ENOUGH_LENS);
  state.distcode = state.distdyn = new utils.Buf32(ENOUGH_DISTS);

  state.sane = 1;
  state.back = -1;
  //Tracev((stderr, "inflate: reset\n"));
  return Z_OK;
}

function inflateReset(strm) {
  var state;

  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  state = strm.state;
  state.wsize = 0;
  state.whave = 0;
  state.wnext = 0;
  return inflateResetKeep(strm);

}

function inflateReset2(strm, windowBits) {
  var wrap;
  var state;

  /* get the state */
  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  state = strm.state;

  /* extract wrap request from windowBits parameter */
  if (windowBits < 0) {
    wrap = 0;
    windowBits = -windowBits;
  }
  else {
    wrap = (windowBits >> 4) + 1;
    if (windowBits < 48) {
      windowBits &= 15;
    }
  }

  /* set number of window bits, free window if different */
  if (windowBits && (windowBits < 8 || windowBits > 15)) {
    return Z_STREAM_ERROR;
  }
  if (state.window !== null && state.wbits !== windowBits) {
    state.window = null;
  }

  /* update state and reset the rest of it */
  state.wrap = wrap;
  state.wbits = windowBits;
  return inflateReset(strm);
}

function inflateInit2(strm, windowBits) {
  var ret;
  var state;

  if (!strm) { return Z_STREAM_ERROR; }
  //strm.msg = Z_NULL;                 /* in case we return an error */

  state = new InflateState();

  //if (state === Z_NULL) return Z_MEM_ERROR;
  //Tracev((stderr, "inflate: allocated\n"));
  strm.state = state;
  state.window = null/*Z_NULL*/;
  ret = inflateReset2(strm, windowBits);
  if (ret !== Z_OK) {
    strm.state = null/*Z_NULL*/;
  }
  return ret;
}

function inflateInit(strm) {
  return inflateInit2(strm, DEF_WBITS);
}


/*
 Return state with length and distance decoding tables and index sizes set to
 fixed code decoding.  Normally this returns fixed tables from inffixed.h.
 If BUILDFIXED is defined, then instead this routine builds the tables the
 first time it's called, and returns those tables the first time and
 thereafter.  This reduces the size of the code by about 2K bytes, in
 exchange for a little execution time.  However, BUILDFIXED should not be
 used for threaded applications, since the rewriting of the tables and virgin
 may not be thread-safe.
 */
var virgin = true;

var lenfix, distfix; // We have no pointers in JS, so keep tables separate

function fixedtables(state) {
  /* build fixed huffman tables if first call (may not be thread safe) */
  if (virgin) {
    var sym;

    lenfix = new utils.Buf32(512);
    distfix = new utils.Buf32(32);

    /* literal/length table */
    sym = 0;
    while (sym < 144) { state.lens[sym++] = 8; }
    while (sym < 256) { state.lens[sym++] = 9; }
    while (sym < 280) { state.lens[sym++] = 7; }
    while (sym < 288) { state.lens[sym++] = 8; }

    inflate_table(LENS,  state.lens, 0, 288, lenfix,   0, state.work, { bits: 9 });

    /* distance table */
    sym = 0;
    while (sym < 32) { state.lens[sym++] = 5; }

    inflate_table(DISTS, state.lens, 0, 32,   distfix, 0, state.work, { bits: 5 });

    /* do this just once */
    virgin = false;
  }

  state.lencode = lenfix;
  state.lenbits = 9;
  state.distcode = distfix;
  state.distbits = 5;
}


/*
 Update the window with the last wsize (normally 32K) bytes written before
 returning.  If window does not exist yet, create it.  This is only called
 when a window is already in use, or when output has been written during this
 inflate call, but the end of the deflate stream has not been reached yet.
 It is also called to create a window for dictionary data when a dictionary
 is loaded.

 Providing output buffers larger than 32K to inflate() should provide a speed
 advantage, since only the last 32K of output is copied to the sliding window
 upon return from inflate(), and since all distances after the first 32K of
 output will fall in the output data, making match copies simpler and faster.
 The advantage may be dependent on the size of the processor's data caches.
 */
function updatewindow(strm, src, end, copy) {
  var dist;
  var state = strm.state;

  /* if it hasn't been done already, allocate space for the window */
  if (state.window === null) {
    state.wsize = 1 << state.wbits;
    state.wnext = 0;
    state.whave = 0;

    state.window = new utils.Buf8(state.wsize);
  }

  /* copy state->wsize or less output bytes into the circular window */
  if (copy >= state.wsize) {
    utils.arraySet(state.window, src, end - state.wsize, state.wsize, 0);
    state.wnext = 0;
    state.whave = state.wsize;
  }
  else {
    dist = state.wsize - state.wnext;
    if (dist > copy) {
      dist = copy;
    }
    //zmemcpy(state->window + state->wnext, end - copy, dist);
    utils.arraySet(state.window, src, end - copy, dist, state.wnext);
    copy -= dist;
    if (copy) {
      //zmemcpy(state->window, end - copy, copy);
      utils.arraySet(state.window, src, end - copy, copy, 0);
      state.wnext = copy;
      state.whave = state.wsize;
    }
    else {
      state.wnext += dist;
      if (state.wnext === state.wsize) { state.wnext = 0; }
      if (state.whave < state.wsize) { state.whave += dist; }
    }
  }
  return 0;
}

function inflate(strm, flush) {
  var state;
  var input, output;          // input/output buffers
  var next;                   /* next input INDEX */
  var put;                    /* next output INDEX */
  var have, left;             /* available input and output */
  var hold;                   /* bit buffer */
  var bits;                   /* bits in bit buffer */
  var _in, _out;              /* save starting available input and output */
  var copy;                   /* number of stored or match bytes to copy */
  var from;                   /* where to copy match bytes from */
  var from_source;
  var here = 0;               /* current decoding table entry */
  var here_bits, here_op, here_val; // paked "here" denormalized (JS specific)
  //var last;                   /* parent table entry */
  var last_bits, last_op, last_val; // paked "last" denormalized (JS specific)
  var len;                    /* length to copy for repeats, bits to drop */
  var ret;                    /* return code */
  var hbuf = new utils.Buf8(4);    /* buffer for gzip header crc calculation */
  var opts;

  var n; // temporary var for NEED_BITS

  var order = /* permutation of code lengths */
    [ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ];


  if (!strm || !strm.state || !strm.output ||
      (!strm.input && strm.avail_in !== 0)) {
    return Z_STREAM_ERROR;
  }

  state = strm.state;
  if (state.mode === TYPE) { state.mode = TYPEDO; }    /* skip check */


  //--- LOAD() ---
  put = strm.next_out;
  output = strm.output;
  left = strm.avail_out;
  next = strm.next_in;
  input = strm.input;
  have = strm.avail_in;
  hold = state.hold;
  bits = state.bits;
  //---

  _in = have;
  _out = left;
  ret = Z_OK;

  inf_leave: // goto emulation
  for (;;) {
    switch (state.mode) {
      case HEAD:
        if (state.wrap === 0) {
          state.mode = TYPEDO;
          break;
        }
        //=== NEEDBITS(16);
        while (bits < 16) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        if ((state.wrap & 2) && hold === 0x8b1f) {  /* gzip header */
          state.check = 0/*crc32(0L, Z_NULL, 0)*/;
          //=== CRC2(state.check, hold);
          hbuf[0] = hold & 0xff;
          hbuf[1] = (hold >>> 8) & 0xff;
          state.check = crc32(state.check, hbuf, 2, 0);
          //===//

          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
          state.mode = FLAGS;
          break;
        }
        state.flags = 0;           /* expect zlib header */
        if (state.head) {
          state.head.done = false;
        }
        if (!(state.wrap & 1) ||   /* check if zlib header allowed */
          (((hold & 0xff)/*BITS(8)*/ << 8) + (hold >> 8)) % 31) {
          strm.msg = 'incorrect header check';
          state.mode = BAD;
          break;
        }
        if ((hold & 0x0f)/*BITS(4)*/ !== Z_DEFLATED) {
          strm.msg = 'unknown compression method';
          state.mode = BAD;
          break;
        }
        //--- DROPBITS(4) ---//
        hold >>>= 4;
        bits -= 4;
        //---//
        len = (hold & 0x0f)/*BITS(4)*/ + 8;
        if (state.wbits === 0) {
          state.wbits = len;
        }
        else if (len > state.wbits) {
          strm.msg = 'invalid window size';
          state.mode = BAD;
          break;
        }
        state.dmax = 1 << len;
        //Tracev((stderr, "inflate:   zlib header ok\n"));
        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;
        state.mode = hold & 0x200 ? DICTID : TYPE;
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        break;
      case FLAGS:
        //=== NEEDBITS(16); */
        while (bits < 16) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        state.flags = hold;
        if ((state.flags & 0xff) !== Z_DEFLATED) {
          strm.msg = 'unknown compression method';
          state.mode = BAD;
          break;
        }
        if (state.flags & 0xe000) {
          strm.msg = 'unknown header flags set';
          state.mode = BAD;
          break;
        }
        if (state.head) {
          state.head.text = ((hold >> 8) & 1);
        }
        if (state.flags & 0x0200) {
          //=== CRC2(state.check, hold);
          hbuf[0] = hold & 0xff;
          hbuf[1] = (hold >>> 8) & 0xff;
          state.check = crc32(state.check, hbuf, 2, 0);
          //===//
        }
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = TIME;
        /* falls through */
      case TIME:
        //=== NEEDBITS(32); */
        while (bits < 32) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        if (state.head) {
          state.head.time = hold;
        }
        if (state.flags & 0x0200) {
          //=== CRC4(state.check, hold)
          hbuf[0] = hold & 0xff;
          hbuf[1] = (hold >>> 8) & 0xff;
          hbuf[2] = (hold >>> 16) & 0xff;
          hbuf[3] = (hold >>> 24) & 0xff;
          state.check = crc32(state.check, hbuf, 4, 0);
          //===
        }
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = OS;
        /* falls through */
      case OS:
        //=== NEEDBITS(16); */
        while (bits < 16) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        if (state.head) {
          state.head.xflags = (hold & 0xff);
          state.head.os = (hold >> 8);
        }
        if (state.flags & 0x0200) {
          //=== CRC2(state.check, hold);
          hbuf[0] = hold & 0xff;
          hbuf[1] = (hold >>> 8) & 0xff;
          state.check = crc32(state.check, hbuf, 2, 0);
          //===//
        }
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = EXLEN;
        /* falls through */
      case EXLEN:
        if (state.flags & 0x0400) {
          //=== NEEDBITS(16); */
          while (bits < 16) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          state.length = hold;
          if (state.head) {
            state.head.extra_len = hold;
          }
          if (state.flags & 0x0200) {
            //=== CRC2(state.check, hold);
            hbuf[0] = hold & 0xff;
            hbuf[1] = (hold >>> 8) & 0xff;
            state.check = crc32(state.check, hbuf, 2, 0);
            //===//
          }
          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
        }
        else if (state.head) {
          state.head.extra = null/*Z_NULL*/;
        }
        state.mode = EXTRA;
        /* falls through */
      case EXTRA:
        if (state.flags & 0x0400) {
          copy = state.length;
          if (copy > have) { copy = have; }
          if (copy) {
            if (state.head) {
              len = state.head.extra_len - state.length;
              if (!state.head.extra) {
                // Use untyped array for more convenient processing later
                state.head.extra = new Array(state.head.extra_len);
              }
              utils.arraySet(
                state.head.extra,
                input,
                next,
                // extra field is limited to 65536 bytes
                // - no need for additional size check
                copy,
                /*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/
                len
              );
              //zmemcpy(state.head.extra + len, next,
              //        len + copy > state.head.extra_max ?
              //        state.head.extra_max - len : copy);
            }
            if (state.flags & 0x0200) {
              state.check = crc32(state.check, input, copy, next);
            }
            have -= copy;
            next += copy;
            state.length -= copy;
          }
          if (state.length) { break inf_leave; }
        }
        state.length = 0;
        state.mode = NAME;
        /* falls through */
      case NAME:
        if (state.flags & 0x0800) {
          if (have === 0) { break inf_leave; }
          copy = 0;
          do {
            // TODO: 2 or 1 bytes?
            len = input[next + copy++];
            /* use constant limit because in js we should not preallocate memory */
            if (state.head && len &&
                (state.length < 65536 /*state.head.name_max*/)) {
              state.head.name += String.fromCharCode(len);
            }
          } while (len && copy < have);

          if (state.flags & 0x0200) {
            state.check = crc32(state.check, input, copy, next);
          }
          have -= copy;
          next += copy;
          if (len) { break inf_leave; }
        }
        else if (state.head) {
          state.head.name = null;
        }
        state.length = 0;
        state.mode = COMMENT;
        /* falls through */
      case COMMENT:
        if (state.flags & 0x1000) {
          if (have === 0) { break inf_leave; }
          copy = 0;
          do {
            len = input[next + copy++];
            /* use constant limit because in js we should not preallocate memory */
            if (state.head && len &&
                (state.length < 65536 /*state.head.comm_max*/)) {
              state.head.comment += String.fromCharCode(len);
            }
          } while (len && copy < have);
          if (state.flags & 0x0200) {
            state.check = crc32(state.check, input, copy, next);
          }
          have -= copy;
          next += copy;
          if (len) { break inf_leave; }
        }
        else if (state.head) {
          state.head.comment = null;
        }
        state.mode = HCRC;
        /* falls through */
      case HCRC:
        if (state.flags & 0x0200) {
          //=== NEEDBITS(16); */
          while (bits < 16) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          if (hold !== (state.check & 0xffff)) {
            strm.msg = 'header crc mismatch';
            state.mode = BAD;
            break;
          }
          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
        }
        if (state.head) {
          state.head.hcrc = ((state.flags >> 9) & 1);
          state.head.done = true;
        }
        strm.adler = state.check = 0;
        state.mode = TYPE;
        break;
      case DICTID:
        //=== NEEDBITS(32); */
        while (bits < 32) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        strm.adler = state.check = zswap32(hold);
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = DICT;
        /* falls through */
      case DICT:
        if (state.havedict === 0) {
          //--- RESTORE() ---
          strm.next_out = put;
          strm.avail_out = left;
          strm.next_in = next;
          strm.avail_in = have;
          state.hold = hold;
          state.bits = bits;
          //---
          return Z_NEED_DICT;
        }
        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;
        state.mode = TYPE;
        /* falls through */
      case TYPE:
        if (flush === Z_BLOCK || flush === Z_TREES) { break inf_leave; }
        /* falls through */
      case TYPEDO:
        if (state.last) {
          //--- BYTEBITS() ---//
          hold >>>= bits & 7;
          bits -= bits & 7;
          //---//
          state.mode = CHECK;
          break;
        }
        //=== NEEDBITS(3); */
        while (bits < 3) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        state.last = (hold & 0x01)/*BITS(1)*/;
        //--- DROPBITS(1) ---//
        hold >>>= 1;
        bits -= 1;
        //---//

        switch ((hold & 0x03)/*BITS(2)*/) {
          case 0:                             /* stored block */
            //Tracev((stderr, "inflate:     stored block%s\n",
            //        state.last ? " (last)" : ""));
            state.mode = STORED;
            break;
          case 1:                             /* fixed block */
            fixedtables(state);
            //Tracev((stderr, "inflate:     fixed codes block%s\n",
            //        state.last ? " (last)" : ""));
            state.mode = LEN_;             /* decode codes */
            if (flush === Z_TREES) {
              //--- DROPBITS(2) ---//
              hold >>>= 2;
              bits -= 2;
              //---//
              break inf_leave;
            }
            break;
          case 2:                             /* dynamic block */
            //Tracev((stderr, "inflate:     dynamic codes block%s\n",
            //        state.last ? " (last)" : ""));
            state.mode = TABLE;
            break;
          case 3:
            strm.msg = 'invalid block type';
            state.mode = BAD;
        }
        //--- DROPBITS(2) ---//
        hold >>>= 2;
        bits -= 2;
        //---//
        break;
      case STORED:
        //--- BYTEBITS() ---// /* go to byte boundary */
        hold >>>= bits & 7;
        bits -= bits & 7;
        //---//
        //=== NEEDBITS(32); */
        while (bits < 32) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        if ((hold & 0xffff) !== ((hold >>> 16) ^ 0xffff)) {
          strm.msg = 'invalid stored block lengths';
          state.mode = BAD;
          break;
        }
        state.length = hold & 0xffff;
        //Tracev((stderr, "inflate:       stored length %u\n",
        //        state.length));
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = COPY_;
        if (flush === Z_TREES) { break inf_leave; }
        /* falls through */
      case COPY_:
        state.mode = COPY;
        /* falls through */
      case COPY:
        copy = state.length;
        if (copy) {
          if (copy > have) { copy = have; }
          if (copy > left) { copy = left; }
          if (copy === 0) { break inf_leave; }
          //--- zmemcpy(put, next, copy); ---
          utils.arraySet(output, input, next, copy, put);
          //---//
          have -= copy;
          next += copy;
          left -= copy;
          put += copy;
          state.length -= copy;
          break;
        }
        //Tracev((stderr, "inflate:       stored end\n"));
        state.mode = TYPE;
        break;
      case TABLE:
        //=== NEEDBITS(14); */
        while (bits < 14) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        state.nlen = (hold & 0x1f)/*BITS(5)*/ + 257;
        //--- DROPBITS(5) ---//
        hold >>>= 5;
        bits -= 5;
        //---//
        state.ndist = (hold & 0x1f)/*BITS(5)*/ + 1;
        //--- DROPBITS(5) ---//
        hold >>>= 5;
        bits -= 5;
        //---//
        state.ncode = (hold & 0x0f)/*BITS(4)*/ + 4;
        //--- DROPBITS(4) ---//
        hold >>>= 4;
        bits -= 4;
        //---//
//#ifndef PKZIP_BUG_WORKAROUND
        if (state.nlen > 286 || state.ndist > 30) {
          strm.msg = 'too many length or distance symbols';
          state.mode = BAD;
          break;
        }
//#endif
        //Tracev((stderr, "inflate:       table sizes ok\n"));
        state.have = 0;
        state.mode = LENLENS;
        /* falls through */
      case LENLENS:
        while (state.have < state.ncode) {
          //=== NEEDBITS(3);
          while (bits < 3) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          state.lens[order[state.have++]] = (hold & 0x07);//BITS(3);
          //--- DROPBITS(3) ---//
          hold >>>= 3;
          bits -= 3;
          //---//
        }
        while (state.have < 19) {
          state.lens[order[state.have++]] = 0;
        }
        // We have separate tables & no pointers. 2 commented lines below not needed.
        //state.next = state.codes;
        //state.lencode = state.next;
        // Switch to use dynamic table
        state.lencode = state.lendyn;
        state.lenbits = 7;

        opts = { bits: state.lenbits };
        ret = inflate_table(CODES, state.lens, 0, 19, state.lencode, 0, state.work, opts);
        state.lenbits = opts.bits;

        if (ret) {
          strm.msg = 'invalid code lengths set';
          state.mode = BAD;
          break;
        }
        //Tracev((stderr, "inflate:       code lengths ok\n"));
        state.have = 0;
        state.mode = CODELENS;
        /* falls through */
      case CODELENS:
        while (state.have < state.nlen + state.ndist) {
          for (;;) {
            here = state.lencode[hold & ((1 << state.lenbits) - 1)];/*BITS(state.lenbits)*/
            here_bits = here >>> 24;
            here_op = (here >>> 16) & 0xff;
            here_val = here & 0xffff;

            if ((here_bits) <= bits) { break; }
            //--- PULLBYTE() ---//
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
            //---//
          }
          if (here_val < 16) {
            //--- DROPBITS(here.bits) ---//
            hold >>>= here_bits;
            bits -= here_bits;
            //---//
            state.lens[state.have++] = here_val;
          }
          else {
            if (here_val === 16) {
              //=== NEEDBITS(here.bits + 2);
              n = here_bits + 2;
              while (bits < n) {
                if (have === 0) { break inf_leave; }
                have--;
                hold += input[next++] << bits;
                bits += 8;
              }
              //===//
              //--- DROPBITS(here.bits) ---//
              hold >>>= here_bits;
              bits -= here_bits;
              //---//
              if (state.have === 0) {
                strm.msg = 'invalid bit length repeat';
                state.mode = BAD;
                break;
              }
              len = state.lens[state.have - 1];
              copy = 3 + (hold & 0x03);//BITS(2);
              //--- DROPBITS(2) ---//
              hold >>>= 2;
              bits -= 2;
              //---//
            }
            else if (here_val === 17) {
              //=== NEEDBITS(here.bits + 3);
              n = here_bits + 3;
              while (bits < n) {
                if (have === 0) { break inf_leave; }
                have--;
                hold += input[next++] << bits;
                bits += 8;
              }
              //===//
              //--- DROPBITS(here.bits) ---//
              hold >>>= here_bits;
              bits -= here_bits;
              //---//
              len = 0;
              copy = 3 + (hold & 0x07);//BITS(3);
              //--- DROPBITS(3) ---//
              hold >>>= 3;
              bits -= 3;
              //---//
            }
            else {
              //=== NEEDBITS(here.bits + 7);
              n = here_bits + 7;
              while (bits < n) {
                if (have === 0) { break inf_leave; }
                have--;
                hold += input[next++] << bits;
                bits += 8;
              }
              //===//
              //--- DROPBITS(here.bits) ---//
              hold >>>= here_bits;
              bits -= here_bits;
              //---//
              len = 0;
              copy = 11 + (hold & 0x7f);//BITS(7);
              //--- DROPBITS(7) ---//
              hold >>>= 7;
              bits -= 7;
              //---//
            }
            if (state.have + copy > state.nlen + state.ndist) {
              strm.msg = 'invalid bit length repeat';
              state.mode = BAD;
              break;
            }
            while (copy--) {
              state.lens[state.have++] = len;
            }
          }
        }

        /* handle error breaks in while */
        if (state.mode === BAD) { break; }

        /* check for end-of-block code (better have one) */
        if (state.lens[256] === 0) {
          strm.msg = 'invalid code -- missing end-of-block';
          state.mode = BAD;
          break;
        }

        /* build code tables -- note: do not change the lenbits or distbits
           values here (9 and 6) without reading the comments in inftrees.h
           concerning the ENOUGH constants, which depend on those values */
        state.lenbits = 9;

        opts = { bits: state.lenbits };
        ret = inflate_table(LENS, state.lens, 0, state.nlen, state.lencode, 0, state.work, opts);
        // We have separate tables & no pointers. 2 commented lines below not needed.
        // state.next_index = opts.table_index;
        state.lenbits = opts.bits;
        // state.lencode = state.next;

        if (ret) {
          strm.msg = 'invalid literal/lengths set';
          state.mode = BAD;
          break;
        }

        state.distbits = 6;
        //state.distcode.copy(state.codes);
        // Switch to use dynamic table
        state.distcode = state.distdyn;
        opts = { bits: state.distbits };
        ret = inflate_table(DISTS, state.lens, state.nlen, state.ndist, state.distcode, 0, state.work, opts);
        // We have separate tables & no pointers. 2 commented lines below not needed.
        // state.next_index = opts.table_index;
        state.distbits = opts.bits;
        // state.distcode = state.next;

        if (ret) {
          strm.msg = 'invalid distances set';
          state.mode = BAD;
          break;
        }
        //Tracev((stderr, 'inflate:       codes ok\n'));
        state.mode = LEN_;
        if (flush === Z_TREES) { break inf_leave; }
        /* falls through */
      case LEN_:
        state.mode = LEN;
        /* falls through */
      case LEN:
        if (have >= 6 && left >= 258) {
          //--- RESTORE() ---
          strm.next_out = put;
          strm.avail_out = left;
          strm.next_in = next;
          strm.avail_in = have;
          state.hold = hold;
          state.bits = bits;
          //---
          inflate_fast(strm, _out);
          //--- LOAD() ---
          put = strm.next_out;
          output = strm.output;
          left = strm.avail_out;
          next = strm.next_in;
          input = strm.input;
          have = strm.avail_in;
          hold = state.hold;
          bits = state.bits;
          //---

          if (state.mode === TYPE) {
            state.back = -1;
          }
          break;
        }
        state.back = 0;
        for (;;) {
          here = state.lencode[hold & ((1 << state.lenbits) - 1)];  /*BITS(state.lenbits)*/
          here_bits = here >>> 24;
          here_op = (here >>> 16) & 0xff;
          here_val = here & 0xffff;

          if (here_bits <= bits) { break; }
          //--- PULLBYTE() ---//
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
          //---//
        }
        if (here_op && (here_op & 0xf0) === 0) {
          last_bits = here_bits;
          last_op = here_op;
          last_val = here_val;
          for (;;) {
            here = state.lencode[last_val +
                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];
            here_bits = here >>> 24;
            here_op = (here >>> 16) & 0xff;
            here_val = here & 0xffff;

            if ((last_bits + here_bits) <= bits) { break; }
            //--- PULLBYTE() ---//
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
            //---//
          }
          //--- DROPBITS(last.bits) ---//
          hold >>>= last_bits;
          bits -= last_bits;
          //---//
          state.back += last_bits;
        }
        //--- DROPBITS(here.bits) ---//
        hold >>>= here_bits;
        bits -= here_bits;
        //---//
        state.back += here_bits;
        state.length = here_val;
        if (here_op === 0) {
          //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?
          //        "inflate:         literal '%c'\n" :
          //        "inflate:         literal 0x%02x\n", here.val));
          state.mode = LIT;
          break;
        }
        if (here_op & 32) {
          //Tracevv((stderr, "inflate:         end of block\n"));
          state.back = -1;
          state.mode = TYPE;
          break;
        }
        if (here_op & 64) {
          strm.msg = 'invalid literal/length code';
          state.mode = BAD;
          break;
        }
        state.extra = here_op & 15;
        state.mode = LENEXT;
        /* falls through */
      case LENEXT:
        if (state.extra) {
          //=== NEEDBITS(state.extra);
          n = state.extra;
          while (bits < n) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          state.length += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;
          //--- DROPBITS(state.extra) ---//
          hold >>>= state.extra;
          bits -= state.extra;
          //---//
          state.back += state.extra;
        }
        //Tracevv((stderr, "inflate:         length %u\n", state.length));
        state.was = state.length;
        state.mode = DIST;
        /* falls through */
      case DIST:
        for (;;) {
          here = state.distcode[hold & ((1 << state.distbits) - 1)];/*BITS(state.distbits)*/
          here_bits = here >>> 24;
          here_op = (here >>> 16) & 0xff;
          here_val = here & 0xffff;

          if ((here_bits) <= bits) { break; }
          //--- PULLBYTE() ---//
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
          //---//
        }
        if ((here_op & 0xf0) === 0) {
          last_bits = here_bits;
          last_op = here_op;
          last_val = here_val;
          for (;;) {
            here = state.distcode[last_val +
                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];
            here_bits = here >>> 24;
            here_op = (here >>> 16) & 0xff;
            here_val = here & 0xffff;

            if ((last_bits + here_bits) <= bits) { break; }
            //--- PULLBYTE() ---//
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
            //---//
          }
          //--- DROPBITS(last.bits) ---//
          hold >>>= last_bits;
          bits -= last_bits;
          //---//
          state.back += last_bits;
        }
        //--- DROPBITS(here.bits) ---//
        hold >>>= here_bits;
        bits -= here_bits;
        //---//
        state.back += here_bits;
        if (here_op & 64) {
          strm.msg = 'invalid distance code';
          state.mode = BAD;
          break;
        }
        state.offset = here_val;
        state.extra = (here_op) & 15;
        state.mode = DISTEXT;
        /* falls through */
      case DISTEXT:
        if (state.extra) {
          //=== NEEDBITS(state.extra);
          n = state.extra;
          while (bits < n) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          state.offset += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;
          //--- DROPBITS(state.extra) ---//
          hold >>>= state.extra;
          bits -= state.extra;
          //---//
          state.back += state.extra;
        }
//#ifdef INFLATE_STRICT
        if (state.offset > state.dmax) {
          strm.msg = 'invalid distance too far back';
          state.mode = BAD;
          break;
        }
//#endif
        //Tracevv((stderr, "inflate:         distance %u\n", state.offset));
        state.mode = MATCH;
        /* falls through */
      case MATCH:
        if (left === 0) { break inf_leave; }
        copy = _out - left;
        if (state.offset > copy) {         /* copy from window */
          copy = state.offset - copy;
          if (copy > state.whave) {
            if (state.sane) {
              strm.msg = 'invalid distance too far back';
              state.mode = BAD;
              break;
            }
// (!) This block is disabled in zlib defaults,
// don't enable it for binary compatibility
//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR
//          Trace((stderr, "inflate.c too far\n"));
//          copy -= state.whave;
//          if (copy > state.length) { copy = state.length; }
//          if (copy > left) { copy = left; }
//          left -= copy;
//          state.length -= copy;
//          do {
//            output[put++] = 0;
//          } while (--copy);
//          if (state.length === 0) { state.mode = LEN; }
//          break;
//#endif
          }
          if (copy > state.wnext) {
            copy -= state.wnext;
            from = state.wsize - copy;
          }
          else {
            from = state.wnext - copy;
          }
          if (copy > state.length) { copy = state.length; }
          from_source = state.window;
        }
        else {                              /* copy from output */
          from_source = output;
          from = put - state.offset;
          copy = state.length;
        }
        if (copy > left) { copy = left; }
        left -= copy;
        state.length -= copy;
        do {
          output[put++] = from_source[from++];
        } while (--copy);
        if (state.length === 0) { state.mode = LEN; }
        break;
      case LIT:
        if (left === 0) { break inf_leave; }
        output[put++] = state.length;
        left--;
        state.mode = LEN;
        break;
      case CHECK:
        if (state.wrap) {
          //=== NEEDBITS(32);
          while (bits < 32) {
            if (have === 0) { break inf_leave; }
            have--;
            // Use '|' instead of '+' to make sure that result is signed
            hold |= input[next++] << bits;
            bits += 8;
          }
          //===//
          _out -= left;
          strm.total_out += _out;
          state.total += _out;
          if (_out) {
            strm.adler = state.check =
                /*UPDATE(state.check, put - _out, _out);*/
                (state.flags ? crc32(state.check, output, _out, put - _out) : adler32(state.check, output, _out, put - _out));

          }
          _out = left;
          // NB: crc32 stored as signed 32-bit int, zswap32 returns signed too
          if ((state.flags ? hold : zswap32(hold)) !== state.check) {
            strm.msg = 'incorrect data check';
            state.mode = BAD;
            break;
          }
          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
          //Tracev((stderr, "inflate:   check matches trailer\n"));
        }
        state.mode = LENGTH;
        /* falls through */
      case LENGTH:
        if (state.wrap && state.flags) {
          //=== NEEDBITS(32);
          while (bits < 32) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          if (hold !== (state.total & 0xffffffff)) {
            strm.msg = 'incorrect length check';
            state.mode = BAD;
            break;
          }
          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
          //Tracev((stderr, "inflate:   length matches trailer\n"));
        }
        state.mode = DONE;
        /* falls through */
      case DONE:
        ret = Z_STREAM_END;
        break inf_leave;
      case BAD:
        ret = Z_DATA_ERROR;
        break inf_leave;
      case MEM:
        return Z_MEM_ERROR;
      case SYNC:
        /* falls through */
      default:
        return Z_STREAM_ERROR;
    }
  }

  // inf_leave <- here is real place for "goto inf_leave", emulated via "break inf_leave"

  /*
     Return from inflate(), updating the total counts and the check value.
     If there was no progress during the inflate() call, return a buffer
     error.  Call updatewindow() to create and/or update the window state.
     Note: a memory error from inflate() is non-recoverable.
   */

  //--- RESTORE() ---
  strm.next_out = put;
  strm.avail_out = left;
  strm.next_in = next;
  strm.avail_in = have;
  state.hold = hold;
  state.bits = bits;
  //---

  if (state.wsize || (_out !== strm.avail_out && state.mode < BAD &&
                      (state.mode < CHECK || flush !== Z_FINISH))) {
    if (updatewindow(strm, strm.output, strm.next_out, _out - strm.avail_out)) {
      state.mode = MEM;
      return Z_MEM_ERROR;
    }
  }
  _in -= strm.avail_in;
  _out -= strm.avail_out;
  strm.total_in += _in;
  strm.total_out += _out;
  state.total += _out;
  if (state.wrap && _out) {
    strm.adler = state.check = /*UPDATE(state.check, strm.next_out - _out, _out);*/
      (state.flags ? crc32(state.check, output, _out, strm.next_out - _out) : adler32(state.check, output, _out, strm.next_out - _out));
  }
  strm.data_type = state.bits + (state.last ? 64 : 0) +
                    (state.mode === TYPE ? 128 : 0) +
                    (state.mode === LEN_ || state.mode === COPY_ ? 256 : 0);
  if (((_in === 0 && _out === 0) || flush === Z_FINISH) && ret === Z_OK) {
    ret = Z_BUF_ERROR;
  }
  return ret;
}

function inflateEnd(strm) {

  if (!strm || !strm.state /*|| strm->zfree == (free_func)0*/) {
    return Z_STREAM_ERROR;
  }

  var state = strm.state;
  if (state.window) {
    state.window = null;
  }
  strm.state = null;
  return Z_OK;
}

function inflateGetHeader(strm, head) {
  var state;

  /* check state */
  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  state = strm.state;
  if ((state.wrap & 2) === 0) { return Z_STREAM_ERROR; }

  /* save header structure */
  state.head = head;
  head.done = false;
  return Z_OK;
}

function inflateSetDictionary(strm, dictionary) {
  var dictLength = dictionary.length;

  var state;
  var dictid;
  var ret;

  /* check state */
  if (!strm /* == Z_NULL */ || !strm.state /* == Z_NULL */) { return Z_STREAM_ERROR; }
  state = strm.state;

  if (state.wrap !== 0 && state.mode !== DICT) {
    return Z_STREAM_ERROR;
  }

  /* check for correct dictionary identifier */
  if (state.mode === DICT) {
    dictid = 1; /* adler32(0, null, 0)*/
    /* dictid = adler32(dictid, dictionary, dictLength); */
    dictid = adler32(dictid, dictionary, dictLength, 0);
    if (dictid !== state.check) {
      return Z_DATA_ERROR;
    }
  }
  /* copy dictionary to window using updatewindow(), which will amend the
   existing dictionary if appropriate */
  ret = updatewindow(strm, dictionary, dictLength, dictLength);
  if (ret) {
    state.mode = MEM;
    return Z_MEM_ERROR;
  }
  state.havedict = 1;
  // Tracev((stderr, "inflate:   dictionary set\n"));
  return Z_OK;
}

exports.inflateReset = inflateReset;
exports.inflateReset2 = inflateReset2;
exports.inflateResetKeep = inflateResetKeep;
exports.inflateInit = inflateInit;
exports.inflateInit2 = inflateInit2;
exports.inflate = inflate;
exports.inflateEnd = inflateEnd;
exports.inflateGetHeader = inflateGetHeader;
exports.inflateSetDictionary = inflateSetDictionary;
exports.inflateInfo = 'pako inflate (from Nodeca project)';

/* Not implemented
exports.inflateCopy = inflateCopy;
exports.inflateGetDictionary = inflateGetDictionary;
exports.inflateMark = inflateMark;
exports.inflatePrime = inflatePrime;
exports.inflateSync = inflateSync;
exports.inflateSyncPoint = inflateSyncPoint;
exports.inflateUndermine = inflateUndermine;
*/


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inftrees.js":
/*!************************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/inftrees.js ***!
  \************************************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

var utils = __webpack_require__(/*! ../utils/common */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js");

var MAXBITS = 15;
var ENOUGH_LENS = 852;
var ENOUGH_DISTS = 592;
//var ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);

var CODES = 0;
var LENS = 1;
var DISTS = 2;

var lbase = [ /* Length codes 257..285 base */
  3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,
  35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0
];

var lext = [ /* Length codes 257..285 extra */
  16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,
  19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 72, 78
];

var dbase = [ /* Distance codes 0..29 base */
  1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,
  257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,
  8193, 12289, 16385, 24577, 0, 0
];

var dext = [ /* Distance codes 0..29 extra */
  16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,
  23, 23, 24, 24, 25, 25, 26, 26, 27, 27,
  28, 28, 29, 29, 64, 64
];

module.exports = function inflate_table(type, lens, lens_index, codes, table, table_index, work, opts)
{
  var bits = opts.bits;
      //here = opts.here; /* table entry for duplication */

  var len = 0;               /* a code's length in bits */
  var sym = 0;               /* index of code symbols */
  var min = 0, max = 0;          /* minimum and maximum code lengths */
  var root = 0;              /* number of index bits for root table */
  var curr = 0;              /* number of index bits for current table */
  var drop = 0;              /* code bits to drop for sub-table */
  var left = 0;                   /* number of prefix codes available */
  var used = 0;              /* code entries in table used */
  var huff = 0;              /* Huffman code */
  var incr;              /* for incrementing code, index */
  var fill;              /* index for replicating entries */
  var low;               /* low bits for current root entry */
  var mask;              /* mask for low root bits */
  var next;             /* next available space in table */
  var base = null;     /* base value table to use */
  var base_index = 0;
//  var shoextra;    /* extra bits table to use */
  var end;                    /* use base and extra for symbol > end */
  var count = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];    /* number of codes of each length */
  var offs = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];     /* offsets in table for each length */
  var extra = null;
  var extra_index = 0;

  var here_bits, here_op, here_val;

  /*
   Process a set of code lengths to create a canonical Huffman code.  The
   code lengths are lens[0..codes-1].  Each length corresponds to the
   symbols 0..codes-1.  The Huffman code is generated by first sorting the
   symbols by length from short to long, and retaining the symbol order
   for codes with equal lengths.  Then the code starts with all zero bits
   for the first code of the shortest length, and the codes are integer
   increments for the same length, and zeros are appended as the length
   increases.  For the deflate format, these bits are stored backwards
   from their more natural integer increment ordering, and so when the
   decoding tables are built in the large loop below, the integer codes
   are incremented backwards.

   This routine assumes, but does not check, that all of the entries in
   lens[] are in the range 0..MAXBITS.  The caller must assure this.
   1..MAXBITS is interpreted as that code length.  zero means that that
   symbol does not occur in this code.

   The codes are sorted by computing a count of codes for each length,
   creating from that a table of starting indices for each length in the
   sorted table, and then entering the symbols in order in the sorted
   table.  The sorted table is work[], with that space being provided by
   the caller.

   The length counts are used for other purposes as well, i.e. finding
   the minimum and maximum length codes, determining if there are any
   codes at all, checking for a valid set of lengths, and looking ahead
   at length counts to determine sub-table sizes when building the
   decoding tables.
   */

  /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */
  for (len = 0; len <= MAXBITS; len++) {
    count[len] = 0;
  }
  for (sym = 0; sym < codes; sym++) {
    count[lens[lens_index + sym]]++;
  }

  /* bound code lengths, force root to be within code lengths */
  root = bits;
  for (max = MAXBITS; max >= 1; max--) {
    if (count[max] !== 0) { break; }
  }
  if (root > max) {
    root = max;
  }
  if (max === 0) {                     /* no symbols to code at all */
    //table.op[opts.table_index] = 64;  //here.op = (var char)64;    /* invalid code marker */
    //table.bits[opts.table_index] = 1;   //here.bits = (var char)1;
    //table.val[opts.table_index++] = 0;   //here.val = (var short)0;
    table[table_index++] = (1 << 24) | (64 << 16) | 0;


    //table.op[opts.table_index] = 64;
    //table.bits[opts.table_index] = 1;
    //table.val[opts.table_index++] = 0;
    table[table_index++] = (1 << 24) | (64 << 16) | 0;

    opts.bits = 1;
    return 0;     /* no symbols, but wait for decoding to report error */
  }
  for (min = 1; min < max; min++) {
    if (count[min] !== 0) { break; }
  }
  if (root < min) {
    root = min;
  }

  /* check for an over-subscribed or incomplete set of lengths */
  left = 1;
  for (len = 1; len <= MAXBITS; len++) {
    left <<= 1;
    left -= count[len];
    if (left < 0) {
      return -1;
    }        /* over-subscribed */
  }
  if (left > 0 && (type === CODES || max !== 1)) {
    return -1;                      /* incomplete set */
  }

  /* generate offsets into symbol table for each length for sorting */
  offs[1] = 0;
  for (len = 1; len < MAXBITS; len++) {
    offs[len + 1] = offs[len] + count[len];
  }

  /* sort symbols by length, by symbol order within each length */
  for (sym = 0; sym < codes; sym++) {
    if (lens[lens_index + sym] !== 0) {
      work[offs[lens[lens_index + sym]]++] = sym;
    }
  }

  /*
   Create and fill in decoding tables.  In this loop, the table being
   filled is at next and has curr index bits.  The code being used is huff
   with length len.  That code is converted to an index by dropping drop
   bits off of the bottom.  For codes where len is less than drop + curr,
   those top drop + curr - len bits are incremented through all values to
   fill the table with replicated entries.

   root is the number of index bits for the root table.  When len exceeds
   root, sub-tables are created pointed to by the root entry with an index
   of the low root bits of huff.  This is saved in low to check for when a
   new sub-table should be started.  drop is zero when the root table is
   being filled, and drop is root when sub-tables are being filled.

   When a new sub-table is needed, it is necessary to look ahead in the
   code lengths to determine what size sub-table is needed.  The length
   counts are used for this, and so count[] is decremented as codes are
   entered in the tables.

   used keeps track of how many table entries have been allocated from the
   provided *table space.  It is checked for LENS and DIST tables against
   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in
   the initial root table size constants.  See the comments in inftrees.h
   for more information.

   sym increments through all symbols, and the loop terminates when
   all codes of length max, i.e. all codes, have been processed.  This
   routine permits incomplete codes, so another loop after this one fills
   in the rest of the decoding tables with invalid code markers.
   */

  /* set up for code type */
  // poor man optimization - use if-else instead of switch,
  // to avoid deopts in old v8
  if (type === CODES) {
    base = extra = work;    /* dummy value--not used */
    end = 19;

  } else if (type === LENS) {
    base = lbase;
    base_index -= 257;
    extra = lext;
    extra_index -= 257;
    end = 256;

  } else {                    /* DISTS */
    base = dbase;
    extra = dext;
    end = -1;
  }

  /* initialize opts for loop */
  huff = 0;                   /* starting code */
  sym = 0;                    /* starting code symbol */
  len = min;                  /* starting code length */
  next = table_index;              /* current table to fill in */
  curr = root;                /* current table index bits */
  drop = 0;                   /* current bits to drop from code for index */
  low = -1;                   /* trigger new sub-table when len > root */
  used = 1 << root;          /* use root table entries */
  mask = used - 1;            /* mask for comparing low */

  /* check available table space */
  if ((type === LENS && used > ENOUGH_LENS) ||
    (type === DISTS && used > ENOUGH_DISTS)) {
    return 1;
  }

  /* process all codes and make table entries */
  for (;;) {
    /* create table entry */
    here_bits = len - drop;
    if (work[sym] < end) {
      here_op = 0;
      here_val = work[sym];
    }
    else if (work[sym] > end) {
      here_op = extra[extra_index + work[sym]];
      here_val = base[base_index + work[sym]];
    }
    else {
      here_op = 32 + 64;         /* end of block */
      here_val = 0;
    }

    /* replicate for those indices with low len bits equal to huff */
    incr = 1 << (len - drop);
    fill = 1 << curr;
    min = fill;                 /* save offset to next table */
    do {
      fill -= incr;
      table[next + (huff >> drop) + fill] = (here_bits << 24) | (here_op << 16) | here_val |0;
    } while (fill !== 0);

    /* backwards increment the len-bit code huff */
    incr = 1 << (len - 1);
    while (huff & incr) {
      incr >>= 1;
    }
    if (incr !== 0) {
      huff &= incr - 1;
      huff += incr;
    } else {
      huff = 0;
    }

    /* go to next symbol, update count, len */
    sym++;
    if (--count[len] === 0) {
      if (len === max) { break; }
      len = lens[lens_index + work[sym]];
    }

    /* create new sub-table if needed */
    if (len > root && (huff & mask) !== low) {
      /* if first time, transition to sub-tables */
      if (drop === 0) {
        drop = root;
      }

      /* increment past last table */
      next += min;            /* here min is 1 << curr */

      /* determine length of next table */
      curr = len - drop;
      left = 1 << curr;
      while (curr + drop < max) {
        left -= count[curr + drop];
        if (left <= 0) { break; }
        curr++;
        left <<= 1;
      }

      /* check for enough space */
      used += 1 << curr;
      if ((type === LENS && used > ENOUGH_LENS) ||
        (type === DISTS && used > ENOUGH_DISTS)) {
        return 1;
      }

      /* point entry in root table to sub-table */
      low = huff & mask;
      /*table.op[low] = curr;
      table.bits[low] = root;
      table.val[low] = next - opts.table_index;*/
      table[low] = (root << 24) | (curr << 16) | (next - table_index) |0;
    }
  }

  /* fill in remaining table entry if code is incomplete (guaranteed to have
   at most one remaining entry, since if the code is incomplete, the
   maximum code length that was allowed to get this far is one bit) */
  if (huff !== 0) {
    //table.op[next + huff] = 64;            /* invalid code marker */
    //table.bits[next + huff] = len - drop;
    //table.val[next + huff] = 0;
    table[next + huff] = ((len - drop) << 24) | (64 << 16) |0;
  }

  /* set return parameters */
  //opts.table_index += used;
  opts.bits = root;
  return 0;
};


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/messages.js":
/*!************************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/messages.js ***!
  \************************************************************************/
/***/ (function(module) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

module.exports = {
  2:      'need dictionary',     /* Z_NEED_DICT       2  */
  1:      'stream end',          /* Z_STREAM_END      1  */
  0:      '',                    /* Z_OK              0  */
  '-1':   'file error',          /* Z_ERRNO         (-1) */
  '-2':   'stream error',        /* Z_STREAM_ERROR  (-2) */
  '-3':   'data error',          /* Z_DATA_ERROR    (-3) */
  '-4':   'insufficient memory', /* Z_MEM_ERROR     (-4) */
  '-5':   'buffer error',        /* Z_BUF_ERROR     (-5) */
  '-6':   'incompatible version' /* Z_VERSION_ERROR (-6) */
};


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/trees.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/trees.js ***!
  \*********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

/* eslint-disable space-unary-ops */

var utils = __webpack_require__(/*! ../utils/common */ "./node_modules/@gmod/cram/node_modules/pako/lib/utils/common.js");

/* Public constants ==========================================================*/
/* ===========================================================================*/


//var Z_FILTERED          = 1;
//var Z_HUFFMAN_ONLY      = 2;
//var Z_RLE               = 3;
var Z_FIXED               = 4;
//var Z_DEFAULT_STRATEGY  = 0;

/* Possible values of the data_type field (though see inflate()) */
var Z_BINARY              = 0;
var Z_TEXT                = 1;
//var Z_ASCII             = 1; // = Z_TEXT
var Z_UNKNOWN             = 2;

/*============================================================================*/


function zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }

// From zutil.h

var STORED_BLOCK = 0;
var STATIC_TREES = 1;
var DYN_TREES    = 2;
/* The three kinds of block type */

var MIN_MATCH    = 3;
var MAX_MATCH    = 258;
/* The minimum and maximum match lengths */

// From deflate.h
/* ===========================================================================
 * Internal compression state.
 */

var LENGTH_CODES  = 29;
/* number of length codes, not counting the special END_BLOCK code */

var LITERALS      = 256;
/* number of literal bytes 0..255 */

var L_CODES       = LITERALS + 1 + LENGTH_CODES;
/* number of Literal or Length codes, including the END_BLOCK code */

var D_CODES       = 30;
/* number of distance codes */

var BL_CODES      = 19;
/* number of codes used to transfer the bit lengths */

var HEAP_SIZE     = 2 * L_CODES + 1;
/* maximum heap size */

var MAX_BITS      = 15;
/* All codes must not exceed MAX_BITS bits */

var Buf_size      = 16;
/* size of bit buffer in bi_buf */


/* ===========================================================================
 * Constants
 */

var MAX_BL_BITS = 7;
/* Bit length codes must not exceed MAX_BL_BITS bits */

var END_BLOCK   = 256;
/* end of block literal code */

var REP_3_6     = 16;
/* repeat previous bit length 3-6 times (2 bits of repeat count) */

var REPZ_3_10   = 17;
/* repeat a zero length 3-10 times  (3 bits of repeat count) */

var REPZ_11_138 = 18;
/* repeat a zero length 11-138 times  (7 bits of repeat count) */

/* eslint-disable comma-spacing,array-bracket-spacing */
var extra_lbits =   /* extra bits for each length code */
  [0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0];

var extra_dbits =   /* extra bits for each distance code */
  [0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13];

var extra_blbits =  /* extra bits for each bit length code */
  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,7];

var bl_order =
  [16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15];
/* eslint-enable comma-spacing,array-bracket-spacing */

/* The lengths of the bit length codes are sent in order of decreasing
 * probability, to avoid transmitting the lengths for unused bit length codes.
 */

/* ===========================================================================
 * Local data. These are initialized only once.
 */

// We pre-fill arrays with 0 to avoid uninitialized gaps

var DIST_CODE_LEN = 512; /* see definition of array dist_code below */

// !!!! Use flat array instead of structure, Freq = i*2, Len = i*2+1
var static_ltree  = new Array((L_CODES + 2) * 2);
zero(static_ltree);
/* The static literal tree. Since the bit lengths are imposed, there is no
 * need for the L_CODES extra codes used during heap construction. However
 * The codes 286 and 287 are needed to build a canonical tree (see _tr_init
 * below).
 */

var static_dtree  = new Array(D_CODES * 2);
zero(static_dtree);
/* The static distance tree. (Actually a trivial tree since all codes use
 * 5 bits.)
 */

var _dist_code    = new Array(DIST_CODE_LEN);
zero(_dist_code);
/* Distance codes. The first 256 values correspond to the distances
 * 3 .. 258, the last 256 values correspond to the top 8 bits of
 * the 15 bit distances.
 */

var _length_code  = new Array(MAX_MATCH - MIN_MATCH + 1);
zero(_length_code);
/* length code for each normalized match length (0 == MIN_MATCH) */

var base_length   = new Array(LENGTH_CODES);
zero(base_length);
/* First normalized length for each code (0 = MIN_MATCH) */

var base_dist     = new Array(D_CODES);
zero(base_dist);
/* First normalized distance for each code (0 = distance of 1) */


function StaticTreeDesc(static_tree, extra_bits, extra_base, elems, max_length) {

  this.static_tree  = static_tree;  /* static tree or NULL */
  this.extra_bits   = extra_bits;   /* extra bits for each code or NULL */
  this.extra_base   = extra_base;   /* base index for extra_bits */
  this.elems        = elems;        /* max number of elements in the tree */
  this.max_length   = max_length;   /* max bit length for the codes */

  // show if `static_tree` has data or dummy - needed for monomorphic objects
  this.has_stree    = static_tree && static_tree.length;
}


var static_l_desc;
var static_d_desc;
var static_bl_desc;


function TreeDesc(dyn_tree, stat_desc) {
  this.dyn_tree = dyn_tree;     /* the dynamic tree */
  this.max_code = 0;            /* largest code with non zero frequency */
  this.stat_desc = stat_desc;   /* the corresponding static tree */
}



function d_code(dist) {
  return dist < 256 ? _dist_code[dist] : _dist_code[256 + (dist >>> 7)];
}


/* ===========================================================================
 * Output a short LSB first on the stream.
 * IN assertion: there is enough room in pendingBuf.
 */
function put_short(s, w) {
//    put_byte(s, (uch)((w) & 0xff));
//    put_byte(s, (uch)((ush)(w) >> 8));
  s.pending_buf[s.pending++] = (w) & 0xff;
  s.pending_buf[s.pending++] = (w >>> 8) & 0xff;
}


/* ===========================================================================
 * Send a value on a given number of bits.
 * IN assertion: length <= 16 and value fits in length bits.
 */
function send_bits(s, value, length) {
  if (s.bi_valid > (Buf_size - length)) {
    s.bi_buf |= (value << s.bi_valid) & 0xffff;
    put_short(s, s.bi_buf);
    s.bi_buf = value >> (Buf_size - s.bi_valid);
    s.bi_valid += length - Buf_size;
  } else {
    s.bi_buf |= (value << s.bi_valid) & 0xffff;
    s.bi_valid += length;
  }
}


function send_code(s, c, tree) {
  send_bits(s, tree[c * 2]/*.Code*/, tree[c * 2 + 1]/*.Len*/);
}


/* ===========================================================================
 * Reverse the first len bits of a code, using straightforward code (a faster
 * method would use a table)
 * IN assertion: 1 <= len <= 15
 */
function bi_reverse(code, len) {
  var res = 0;
  do {
    res |= code & 1;
    code >>>= 1;
    res <<= 1;
  } while (--len > 0);
  return res >>> 1;
}


/* ===========================================================================
 * Flush the bit buffer, keeping at most 7 bits in it.
 */
function bi_flush(s) {
  if (s.bi_valid === 16) {
    put_short(s, s.bi_buf);
    s.bi_buf = 0;
    s.bi_valid = 0;

  } else if (s.bi_valid >= 8) {
    s.pending_buf[s.pending++] = s.bi_buf & 0xff;
    s.bi_buf >>= 8;
    s.bi_valid -= 8;
  }
}


/* ===========================================================================
 * Compute the optimal bit lengths for a tree and update the total bit length
 * for the current block.
 * IN assertion: the fields freq and dad are set, heap[heap_max] and
 *    above are the tree nodes sorted by increasing frequency.
 * OUT assertions: the field len is set to the optimal bit length, the
 *     array bl_count contains the frequencies for each bit length.
 *     The length opt_len is updated; static_len is also updated if stree is
 *     not null.
 */
function gen_bitlen(s, desc)
//    deflate_state *s;
//    tree_desc *desc;    /* the tree descriptor */
{
  var tree            = desc.dyn_tree;
  var max_code        = desc.max_code;
  var stree           = desc.stat_desc.static_tree;
  var has_stree       = desc.stat_desc.has_stree;
  var extra           = desc.stat_desc.extra_bits;
  var base            = desc.stat_desc.extra_base;
  var max_length      = desc.stat_desc.max_length;
  var h;              /* heap index */
  var n, m;           /* iterate over the tree elements */
  var bits;           /* bit length */
  var xbits;          /* extra bits */
  var f;              /* frequency */
  var overflow = 0;   /* number of elements with bit length too large */

  for (bits = 0; bits <= MAX_BITS; bits++) {
    s.bl_count[bits] = 0;
  }

  /* In a first pass, compute the optimal bit lengths (which may
   * overflow in the case of the bit length tree).
   */
  tree[s.heap[s.heap_max] * 2 + 1]/*.Len*/ = 0; /* root of the heap */

  for (h = s.heap_max + 1; h < HEAP_SIZE; h++) {
    n = s.heap[h];
    bits = tree[tree[n * 2 + 1]/*.Dad*/ * 2 + 1]/*.Len*/ + 1;
    if (bits > max_length) {
      bits = max_length;
      overflow++;
    }
    tree[n * 2 + 1]/*.Len*/ = bits;
    /* We overwrite tree[n].Dad which is no longer needed */

    if (n > max_code) { continue; } /* not a leaf node */

    s.bl_count[bits]++;
    xbits = 0;
    if (n >= base) {
      xbits = extra[n - base];
    }
    f = tree[n * 2]/*.Freq*/;
    s.opt_len += f * (bits + xbits);
    if (has_stree) {
      s.static_len += f * (stree[n * 2 + 1]/*.Len*/ + xbits);
    }
  }
  if (overflow === 0) { return; }

  // Trace((stderr,"\nbit length overflow\n"));
  /* This happens for example on obj2 and pic of the Calgary corpus */

  /* Find the first bit length which could increase: */
  do {
    bits = max_length - 1;
    while (s.bl_count[bits] === 0) { bits--; }
    s.bl_count[bits]--;      /* move one leaf down the tree */
    s.bl_count[bits + 1] += 2; /* move one overflow item as its brother */
    s.bl_count[max_length]--;
    /* The brother of the overflow item also moves one step up,
     * but this does not affect bl_count[max_length]
     */
    overflow -= 2;
  } while (overflow > 0);

  /* Now recompute all bit lengths, scanning in increasing frequency.
   * h is still equal to HEAP_SIZE. (It is simpler to reconstruct all
   * lengths instead of fixing only the wrong ones. This idea is taken
   * from 'ar' written by Haruhiko Okumura.)
   */
  for (bits = max_length; bits !== 0; bits--) {
    n = s.bl_count[bits];
    while (n !== 0) {
      m = s.heap[--h];
      if (m > max_code) { continue; }
      if (tree[m * 2 + 1]/*.Len*/ !== bits) {
        // Trace((stderr,"code %d bits %d->%d\n", m, tree[m].Len, bits));
        s.opt_len += (bits - tree[m * 2 + 1]/*.Len*/) * tree[m * 2]/*.Freq*/;
        tree[m * 2 + 1]/*.Len*/ = bits;
      }
      n--;
    }
  }
}


/* ===========================================================================
 * Generate the codes for a given tree and bit counts (which need not be
 * optimal).
 * IN assertion: the array bl_count contains the bit length statistics for
 * the given tree and the field len is set for all tree elements.
 * OUT assertion: the field code is set for all tree elements of non
 *     zero code length.
 */
function gen_codes(tree, max_code, bl_count)
//    ct_data *tree;             /* the tree to decorate */
//    int max_code;              /* largest code with non zero frequency */
//    ushf *bl_count;            /* number of codes at each bit length */
{
  var next_code = new Array(MAX_BITS + 1); /* next code value for each bit length */
  var code = 0;              /* running code value */
  var bits;                  /* bit index */
  var n;                     /* code index */

  /* The distribution counts are first used to generate the code values
   * without bit reversal.
   */
  for (bits = 1; bits <= MAX_BITS; bits++) {
    next_code[bits] = code = (code + bl_count[bits - 1]) << 1;
  }
  /* Check that the bit counts in bl_count are consistent. The last code
   * must be all ones.
   */
  //Assert (code + bl_count[MAX_BITS]-1 == (1<<MAX_BITS)-1,
  //        "inconsistent bit counts");
  //Tracev((stderr,"\ngen_codes: max_code %d ", max_code));

  for (n = 0;  n <= max_code; n++) {
    var len = tree[n * 2 + 1]/*.Len*/;
    if (len === 0) { continue; }
    /* Now reverse the bits */
    tree[n * 2]/*.Code*/ = bi_reverse(next_code[len]++, len);

    //Tracecv(tree != static_ltree, (stderr,"\nn %3d %c l %2d c %4x (%x) ",
    //     n, (isgraph(n) ? n : ' '), len, tree[n].Code, next_code[len]-1));
  }
}


/* ===========================================================================
 * Initialize the various 'constant' tables.
 */
function tr_static_init() {
  var n;        /* iterates over tree elements */
  var bits;     /* bit counter */
  var length;   /* length value */
  var code;     /* code value */
  var dist;     /* distance index */
  var bl_count = new Array(MAX_BITS + 1);
  /* number of codes at each bit length for an optimal tree */

  // do check in _tr_init()
  //if (static_init_done) return;

  /* For some embedded targets, global variables are not initialized: */
/*#ifdef NO_INIT_GLOBAL_POINTERS
  static_l_desc.static_tree = static_ltree;
  static_l_desc.extra_bits = extra_lbits;
  static_d_desc.static_tree = static_dtree;
  static_d_desc.extra_bits = extra_dbits;
  static_bl_desc.extra_bits = extra_blbits;
#endif*/

  /* Initialize the mapping length (0..255) -> length code (0..28) */
  length = 0;
  for (code = 0; code < LENGTH_CODES - 1; code++) {
    base_length[code] = length;
    for (n = 0; n < (1 << extra_lbits[code]); n++) {
      _length_code[length++] = code;
    }
  }
  //Assert (length == 256, "tr_static_init: length != 256");
  /* Note that the length 255 (match length 258) can be represented
   * in two different ways: code 284 + 5 bits or code 285, so we
   * overwrite length_code[255] to use the best encoding:
   */
  _length_code[length - 1] = code;

  /* Initialize the mapping dist (0..32K) -> dist code (0..29) */
  dist = 0;
  for (code = 0; code < 16; code++) {
    base_dist[code] = dist;
    for (n = 0; n < (1 << extra_dbits[code]); n++) {
      _dist_code[dist++] = code;
    }
  }
  //Assert (dist == 256, "tr_static_init: dist != 256");
  dist >>= 7; /* from now on, all distances are divided by 128 */
  for (; code < D_CODES; code++) {
    base_dist[code] = dist << 7;
    for (n = 0; n < (1 << (extra_dbits[code] - 7)); n++) {
      _dist_code[256 + dist++] = code;
    }
  }
  //Assert (dist == 256, "tr_static_init: 256+dist != 512");

  /* Construct the codes of the static literal tree */
  for (bits = 0; bits <= MAX_BITS; bits++) {
    bl_count[bits] = 0;
  }

  n = 0;
  while (n <= 143) {
    static_ltree[n * 2 + 1]/*.Len*/ = 8;
    n++;
    bl_count[8]++;
  }
  while (n <= 255) {
    static_ltree[n * 2 + 1]/*.Len*/ = 9;
    n++;
    bl_count[9]++;
  }
  while (n <= 279) {
    static_ltree[n * 2 + 1]/*.Len*/ = 7;
    n++;
    bl_count[7]++;
  }
  while (n <= 287) {
    static_ltree[n * 2 + 1]/*.Len*/ = 8;
    n++;
    bl_count[8]++;
  }
  /* Codes 286 and 287 do not exist, but we must include them in the
   * tree construction to get a canonical Huffman tree (longest code
   * all ones)
   */
  gen_codes(static_ltree, L_CODES + 1, bl_count);

  /* The static distance tree is trivial: */
  for (n = 0; n < D_CODES; n++) {
    static_dtree[n * 2 + 1]/*.Len*/ = 5;
    static_dtree[n * 2]/*.Code*/ = bi_reverse(n, 5);
  }

  // Now data ready and we can init static trees
  static_l_desc = new StaticTreeDesc(static_ltree, extra_lbits, LITERALS + 1, L_CODES, MAX_BITS);
  static_d_desc = new StaticTreeDesc(static_dtree, extra_dbits, 0,          D_CODES, MAX_BITS);
  static_bl_desc = new StaticTreeDesc(new Array(0), extra_blbits, 0,         BL_CODES, MAX_BL_BITS);

  //static_init_done = true;
}


/* ===========================================================================
 * Initialize a new block.
 */
function init_block(s) {
  var n; /* iterates over tree elements */

  /* Initialize the trees. */
  for (n = 0; n < L_CODES;  n++) { s.dyn_ltree[n * 2]/*.Freq*/ = 0; }
  for (n = 0; n < D_CODES;  n++) { s.dyn_dtree[n * 2]/*.Freq*/ = 0; }
  for (n = 0; n < BL_CODES; n++) { s.bl_tree[n * 2]/*.Freq*/ = 0; }

  s.dyn_ltree[END_BLOCK * 2]/*.Freq*/ = 1;
  s.opt_len = s.static_len = 0;
  s.last_lit = s.matches = 0;
}


/* ===========================================================================
 * Flush the bit buffer and align the output on a byte boundary
 */
function bi_windup(s)
{
  if (s.bi_valid > 8) {
    put_short(s, s.bi_buf);
  } else if (s.bi_valid > 0) {
    //put_byte(s, (Byte)s->bi_buf);
    s.pending_buf[s.pending++] = s.bi_buf;
  }
  s.bi_buf = 0;
  s.bi_valid = 0;
}

/* ===========================================================================
 * Copy a stored block, storing first the length and its
 * one's complement if requested.
 */
function copy_block(s, buf, len, header)
//DeflateState *s;
//charf    *buf;    /* the input data */
//unsigned len;     /* its length */
//int      header;  /* true if block header must be written */
{
  bi_windup(s);        /* align on byte boundary */

  if (header) {
    put_short(s, len);
    put_short(s, ~len);
  }
//  while (len--) {
//    put_byte(s, *buf++);
//  }
  utils.arraySet(s.pending_buf, s.window, buf, len, s.pending);
  s.pending += len;
}

/* ===========================================================================
 * Compares to subtrees, using the tree depth as tie breaker when
 * the subtrees have equal frequency. This minimizes the worst case length.
 */
function smaller(tree, n, m, depth) {
  var _n2 = n * 2;
  var _m2 = m * 2;
  return (tree[_n2]/*.Freq*/ < tree[_m2]/*.Freq*/ ||
         (tree[_n2]/*.Freq*/ === tree[_m2]/*.Freq*/ && depth[n] <= depth[m]));
}

/* ===========================================================================
 * Restore the heap property by moving down the tree starting at node k,
 * exchanging a node with the smallest of its two sons if necessary, stopping
 * when the heap property is re-established (each father smaller than its
 * two sons).
 */
function pqdownheap(s, tree, k)
//    deflate_state *s;
//    ct_data *tree;  /* the tree to restore */
//    int k;               /* node to move down */
{
  var v = s.heap[k];
  var j = k << 1;  /* left son of k */
  while (j <= s.heap_len) {
    /* Set j to the smallest of the two sons: */
    if (j < s.heap_len &&
      smaller(tree, s.heap[j + 1], s.heap[j], s.depth)) {
      j++;
    }
    /* Exit if v is smaller than both sons */
    if (smaller(tree, v, s.heap[j], s.depth)) { break; }

    /* Exchange v with the smallest son */
    s.heap[k] = s.heap[j];
    k = j;

    /* And continue down the tree, setting j to the left son of k */
    j <<= 1;
  }
  s.heap[k] = v;
}


// inlined manually
// var SMALLEST = 1;

/* ===========================================================================
 * Send the block data compressed using the given Huffman trees
 */
function compress_block(s, ltree, dtree)
//    deflate_state *s;
//    const ct_data *ltree; /* literal tree */
//    const ct_data *dtree; /* distance tree */
{
  var dist;           /* distance of matched string */
  var lc;             /* match length or unmatched char (if dist == 0) */
  var lx = 0;         /* running index in l_buf */
  var code;           /* the code to send */
  var extra;          /* number of extra bits to send */

  if (s.last_lit !== 0) {
    do {
      dist = (s.pending_buf[s.d_buf + lx * 2] << 8) | (s.pending_buf[s.d_buf + lx * 2 + 1]);
      lc = s.pending_buf[s.l_buf + lx];
      lx++;

      if (dist === 0) {
        send_code(s, lc, ltree); /* send a literal byte */
        //Tracecv(isgraph(lc), (stderr," '%c' ", lc));
      } else {
        /* Here, lc is the match length - MIN_MATCH */
        code = _length_code[lc];
        send_code(s, code + LITERALS + 1, ltree); /* send the length code */
        extra = extra_lbits[code];
        if (extra !== 0) {
          lc -= base_length[code];
          send_bits(s, lc, extra);       /* send the extra length bits */
        }
        dist--; /* dist is now the match distance - 1 */
        code = d_code(dist);
        //Assert (code < D_CODES, "bad d_code");

        send_code(s, code, dtree);       /* send the distance code */
        extra = extra_dbits[code];
        if (extra !== 0) {
          dist -= base_dist[code];
          send_bits(s, dist, extra);   /* send the extra distance bits */
        }
      } /* literal or match pair ? */

      /* Check that the overlay between pending_buf and d_buf+l_buf is ok: */
      //Assert((uInt)(s->pending) < s->lit_bufsize + 2*lx,
      //       "pendingBuf overflow");

    } while (lx < s.last_lit);
  }

  send_code(s, END_BLOCK, ltree);
}


/* ===========================================================================
 * Construct one Huffman tree and assigns the code bit strings and lengths.
 * Update the total bit length for the current block.
 * IN assertion: the field freq is set for all tree elements.
 * OUT assertions: the fields len and code are set to the optimal bit length
 *     and corresponding code. The length opt_len is updated; static_len is
 *     also updated if stree is not null. The field max_code is set.
 */
function build_tree(s, desc)
//    deflate_state *s;
//    tree_desc *desc; /* the tree descriptor */
{
  var tree     = desc.dyn_tree;
  var stree    = desc.stat_desc.static_tree;
  var has_stree = desc.stat_desc.has_stree;
  var elems    = desc.stat_desc.elems;
  var n, m;          /* iterate over heap elements */
  var max_code = -1; /* largest code with non zero frequency */
  var node;          /* new node being created */

  /* Construct the initial heap, with least frequent element in
   * heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].
   * heap[0] is not used.
   */
  s.heap_len = 0;
  s.heap_max = HEAP_SIZE;

  for (n = 0; n < elems; n++) {
    if (tree[n * 2]/*.Freq*/ !== 0) {
      s.heap[++s.heap_len] = max_code = n;
      s.depth[n] = 0;

    } else {
      tree[n * 2 + 1]/*.Len*/ = 0;
    }
  }

  /* The pkzip format requires that at least one distance code exists,
   * and that at least one bit should be sent even if there is only one
   * possible code. So to avoid special checks later on we force at least
   * two codes of non zero frequency.
   */
  while (s.heap_len < 2) {
    node = s.heap[++s.heap_len] = (max_code < 2 ? ++max_code : 0);
    tree[node * 2]/*.Freq*/ = 1;
    s.depth[node] = 0;
    s.opt_len--;

    if (has_stree) {
      s.static_len -= stree[node * 2 + 1]/*.Len*/;
    }
    /* node is 0 or 1 so it does not have extra bits */
  }
  desc.max_code = max_code;

  /* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,
   * establish sub-heaps of increasing lengths:
   */
  for (n = (s.heap_len >> 1/*int /2*/); n >= 1; n--) { pqdownheap(s, tree, n); }

  /* Construct the Huffman tree by repeatedly combining the least two
   * frequent nodes.
   */
  node = elems;              /* next internal node of the tree */
  do {
    //pqremove(s, tree, n);  /* n = node of least frequency */
    /*** pqremove ***/
    n = s.heap[1/*SMALLEST*/];
    s.heap[1/*SMALLEST*/] = s.heap[s.heap_len--];
    pqdownheap(s, tree, 1/*SMALLEST*/);
    /***/

    m = s.heap[1/*SMALLEST*/]; /* m = node of next least frequency */

    s.heap[--s.heap_max] = n; /* keep the nodes sorted by frequency */
    s.heap[--s.heap_max] = m;

    /* Create a new node father of n and m */
    tree[node * 2]/*.Freq*/ = tree[n * 2]/*.Freq*/ + tree[m * 2]/*.Freq*/;
    s.depth[node] = (s.depth[n] >= s.depth[m] ? s.depth[n] : s.depth[m]) + 1;
    tree[n * 2 + 1]/*.Dad*/ = tree[m * 2 + 1]/*.Dad*/ = node;

    /* and insert the new node in the heap */
    s.heap[1/*SMALLEST*/] = node++;
    pqdownheap(s, tree, 1/*SMALLEST*/);

  } while (s.heap_len >= 2);

  s.heap[--s.heap_max] = s.heap[1/*SMALLEST*/];

  /* At this point, the fields freq and dad are set. We can now
   * generate the bit lengths.
   */
  gen_bitlen(s, desc);

  /* The field len is now set, we can generate the bit codes */
  gen_codes(tree, max_code, s.bl_count);
}


/* ===========================================================================
 * Scan a literal or distance tree to determine the frequencies of the codes
 * in the bit length tree.
 */
function scan_tree(s, tree, max_code)
//    deflate_state *s;
//    ct_data *tree;   /* the tree to be scanned */
//    int max_code;    /* and its largest code of non zero frequency */
{
  var n;                     /* iterates over all tree elements */
  var prevlen = -1;          /* last emitted length */
  var curlen;                /* length of current code */

  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */

  var count = 0;             /* repeat count of the current code */
  var max_count = 7;         /* max repeat count */
  var min_count = 4;         /* min repeat count */

  if (nextlen === 0) {
    max_count = 138;
    min_count = 3;
  }
  tree[(max_code + 1) * 2 + 1]/*.Len*/ = 0xffff; /* guard */

  for (n = 0; n <= max_code; n++) {
    curlen = nextlen;
    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;

    if (++count < max_count && curlen === nextlen) {
      continue;

    } else if (count < min_count) {
      s.bl_tree[curlen * 2]/*.Freq*/ += count;

    } else if (curlen !== 0) {

      if (curlen !== prevlen) { s.bl_tree[curlen * 2]/*.Freq*/++; }
      s.bl_tree[REP_3_6 * 2]/*.Freq*/++;

    } else if (count <= 10) {
      s.bl_tree[REPZ_3_10 * 2]/*.Freq*/++;

    } else {
      s.bl_tree[REPZ_11_138 * 2]/*.Freq*/++;
    }

    count = 0;
    prevlen = curlen;

    if (nextlen === 0) {
      max_count = 138;
      min_count = 3;

    } else if (curlen === nextlen) {
      max_count = 6;
      min_count = 3;

    } else {
      max_count = 7;
      min_count = 4;
    }
  }
}


/* ===========================================================================
 * Send a literal or distance tree in compressed form, using the codes in
 * bl_tree.
 */
function send_tree(s, tree, max_code)
//    deflate_state *s;
//    ct_data *tree; /* the tree to be scanned */
//    int max_code;       /* and its largest code of non zero frequency */
{
  var n;                     /* iterates over all tree elements */
  var prevlen = -1;          /* last emitted length */
  var curlen;                /* length of current code */

  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */

  var count = 0;             /* repeat count of the current code */
  var max_count = 7;         /* max repeat count */
  var min_count = 4;         /* min repeat count */

  /* tree[max_code+1].Len = -1; */  /* guard already set */
  if (nextlen === 0) {
    max_count = 138;
    min_count = 3;
  }

  for (n = 0; n <= max_code; n++) {
    curlen = nextlen;
    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;

    if (++count < max_count && curlen === nextlen) {
      continue;

    } else if (count < min_count) {
      do { send_code(s, curlen, s.bl_tree); } while (--count !== 0);

    } else if (curlen !== 0) {
      if (curlen !== prevlen) {
        send_code(s, curlen, s.bl_tree);
        count--;
      }
      //Assert(count >= 3 && count <= 6, " 3_6?");
      send_code(s, REP_3_6, s.bl_tree);
      send_bits(s, count - 3, 2);

    } else if (count <= 10) {
      send_code(s, REPZ_3_10, s.bl_tree);
      send_bits(s, count - 3, 3);

    } else {
      send_code(s, REPZ_11_138, s.bl_tree);
      send_bits(s, count - 11, 7);
    }

    count = 0;
    prevlen = curlen;
    if (nextlen === 0) {
      max_count = 138;
      min_count = 3;

    } else if (curlen === nextlen) {
      max_count = 6;
      min_count = 3;

    } else {
      max_count = 7;
      min_count = 4;
    }
  }
}


/* ===========================================================================
 * Construct the Huffman tree for the bit lengths and return the index in
 * bl_order of the last bit length code to send.
 */
function build_bl_tree(s) {
  var max_blindex;  /* index of last bit length code of non zero freq */

  /* Determine the bit length frequencies for literal and distance trees */
  scan_tree(s, s.dyn_ltree, s.l_desc.max_code);
  scan_tree(s, s.dyn_dtree, s.d_desc.max_code);

  /* Build the bit length tree: */
  build_tree(s, s.bl_desc);
  /* opt_len now includes the length of the tree representations, except
   * the lengths of the bit lengths codes and the 5+5+4 bits for the counts.
   */

  /* Determine the number of bit length codes to send. The pkzip format
   * requires that at least 4 bit length codes be sent. (appnote.txt says
   * 3 but the actual value used is 4.)
   */
  for (max_blindex = BL_CODES - 1; max_blindex >= 3; max_blindex--) {
    if (s.bl_tree[bl_order[max_blindex] * 2 + 1]/*.Len*/ !== 0) {
      break;
    }
  }
  /* Update opt_len to include the bit length tree and counts */
  s.opt_len += 3 * (max_blindex + 1) + 5 + 5 + 4;
  //Tracev((stderr, "\ndyn trees: dyn %ld, stat %ld",
  //        s->opt_len, s->static_len));

  return max_blindex;
}


/* ===========================================================================
 * Send the header for a block using dynamic Huffman trees: the counts, the
 * lengths of the bit length codes, the literal tree and the distance tree.
 * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.
 */
function send_all_trees(s, lcodes, dcodes, blcodes)
//    deflate_state *s;
//    int lcodes, dcodes, blcodes; /* number of codes for each tree */
{
  var rank;                    /* index in bl_order */

  //Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, "not enough codes");
  //Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES,
  //        "too many codes");
  //Tracev((stderr, "\nbl counts: "));
  send_bits(s, lcodes - 257, 5); /* not +255 as stated in appnote.txt */
  send_bits(s, dcodes - 1,   5);
  send_bits(s, blcodes - 4,  4); /* not -3 as stated in appnote.txt */
  for (rank = 0; rank < blcodes; rank++) {
    //Tracev((stderr, "\nbl code %2d ", bl_order[rank]));
    send_bits(s, s.bl_tree[bl_order[rank] * 2 + 1]/*.Len*/, 3);
  }
  //Tracev((stderr, "\nbl tree: sent %ld", s->bits_sent));

  send_tree(s, s.dyn_ltree, lcodes - 1); /* literal tree */
  //Tracev((stderr, "\nlit tree: sent %ld", s->bits_sent));

  send_tree(s, s.dyn_dtree, dcodes - 1); /* distance tree */
  //Tracev((stderr, "\ndist tree: sent %ld", s->bits_sent));
}


/* ===========================================================================
 * Check if the data type is TEXT or BINARY, using the following algorithm:
 * - TEXT if the two conditions below are satisfied:
 *    a) There are no non-portable control characters belonging to the
 *       "black list" (0..6, 14..25, 28..31).
 *    b) There is at least one printable character belonging to the
 *       "white list" (9 {TAB}, 10 {LF}, 13 {CR}, 32..255).
 * - BINARY otherwise.
 * - The following partially-portable control characters form a
 *   "gray list" that is ignored in this detection algorithm:
 *   (7 {BEL}, 8 {BS}, 11 {VT}, 12 {FF}, 26 {SUB}, 27 {ESC}).
 * IN assertion: the fields Freq of dyn_ltree are set.
 */
function detect_data_type(s) {
  /* black_mask is the bit mask of black-listed bytes
   * set bits 0..6, 14..25, and 28..31
   * 0xf3ffc07f = binary 11110011111111111100000001111111
   */
  var black_mask = 0xf3ffc07f;
  var n;

  /* Check for non-textual ("black-listed") bytes. */
  for (n = 0; n <= 31; n++, black_mask >>>= 1) {
    if ((black_mask & 1) && (s.dyn_ltree[n * 2]/*.Freq*/ !== 0)) {
      return Z_BINARY;
    }
  }

  /* Check for textual ("white-listed") bytes. */
  if (s.dyn_ltree[9 * 2]/*.Freq*/ !== 0 || s.dyn_ltree[10 * 2]/*.Freq*/ !== 0 ||
      s.dyn_ltree[13 * 2]/*.Freq*/ !== 0) {
    return Z_TEXT;
  }
  for (n = 32; n < LITERALS; n++) {
    if (s.dyn_ltree[n * 2]/*.Freq*/ !== 0) {
      return Z_TEXT;
    }
  }

  /* There are no "black-listed" or "white-listed" bytes:
   * this stream either is empty or has tolerated ("gray-listed") bytes only.
   */
  return Z_BINARY;
}


var static_init_done = false;

/* ===========================================================================
 * Initialize the tree data structures for a new zlib stream.
 */
function _tr_init(s)
{

  if (!static_init_done) {
    tr_static_init();
    static_init_done = true;
  }

  s.l_desc  = new TreeDesc(s.dyn_ltree, static_l_desc);
  s.d_desc  = new TreeDesc(s.dyn_dtree, static_d_desc);
  s.bl_desc = new TreeDesc(s.bl_tree, static_bl_desc);

  s.bi_buf = 0;
  s.bi_valid = 0;

  /* Initialize the first block of the first file: */
  init_block(s);
}


/* ===========================================================================
 * Send a stored block
 */
function _tr_stored_block(s, buf, stored_len, last)
//DeflateState *s;
//charf *buf;       /* input block */
//ulg stored_len;   /* length of input block */
//int last;         /* one if this is the last block for a file */
{
  send_bits(s, (STORED_BLOCK << 1) + (last ? 1 : 0), 3);    /* send block type */
  copy_block(s, buf, stored_len, true); /* with header */
}


/* ===========================================================================
 * Send one empty static block to give enough lookahead for inflate.
 * This takes 10 bits, of which 7 may remain in the bit buffer.
 */
function _tr_align(s) {
  send_bits(s, STATIC_TREES << 1, 3);
  send_code(s, END_BLOCK, static_ltree);
  bi_flush(s);
}


/* ===========================================================================
 * Determine the best encoding for the current block: dynamic trees, static
 * trees or store, and output the encoded block to the zip file.
 */
function _tr_flush_block(s, buf, stored_len, last)
//DeflateState *s;
//charf *buf;       /* input block, or NULL if too old */
//ulg stored_len;   /* length of input block */
//int last;         /* one if this is the last block for a file */
{
  var opt_lenb, static_lenb;  /* opt_len and static_len in bytes */
  var max_blindex = 0;        /* index of last bit length code of non zero freq */

  /* Build the Huffman trees unless a stored block is forced */
  if (s.level > 0) {

    /* Check if the file is binary or text */
    if (s.strm.data_type === Z_UNKNOWN) {
      s.strm.data_type = detect_data_type(s);
    }

    /* Construct the literal and distance trees */
    build_tree(s, s.l_desc);
    // Tracev((stderr, "\nlit data: dyn %ld, stat %ld", s->opt_len,
    //        s->static_len));

    build_tree(s, s.d_desc);
    // Tracev((stderr, "\ndist data: dyn %ld, stat %ld", s->opt_len,
    //        s->static_len));
    /* At this point, opt_len and static_len are the total bit lengths of
     * the compressed block data, excluding the tree representations.
     */

    /* Build the bit length tree for the above two trees, and get the index
     * in bl_order of the last bit length code to send.
     */
    max_blindex = build_bl_tree(s);

    /* Determine the best encoding. Compute the block lengths in bytes. */
    opt_lenb = (s.opt_len + 3 + 7) >>> 3;
    static_lenb = (s.static_len + 3 + 7) >>> 3;

    // Tracev((stderr, "\nopt %lu(%lu) stat %lu(%lu) stored %lu lit %u ",
    //        opt_lenb, s->opt_len, static_lenb, s->static_len, stored_len,
    //        s->last_lit));

    if (static_lenb <= opt_lenb) { opt_lenb = static_lenb; }

  } else {
    // Assert(buf != (char*)0, "lost buf");
    opt_lenb = static_lenb = stored_len + 5; /* force a stored block */
  }

  if ((stored_len + 4 <= opt_lenb) && (buf !== -1)) {
    /* 4: two words for the lengths */

    /* The test buf != NULL is only necessary if LIT_BUFSIZE > WSIZE.
     * Otherwise we can't have processed more than WSIZE input bytes since
     * the last block flush, because compression would have been
     * successful. If LIT_BUFSIZE <= WSIZE, it is never too late to
     * transform a block into a stored block.
     */
    _tr_stored_block(s, buf, stored_len, last);

  } else if (s.strategy === Z_FIXED || static_lenb === opt_lenb) {

    send_bits(s, (STATIC_TREES << 1) + (last ? 1 : 0), 3);
    compress_block(s, static_ltree, static_dtree);

  } else {
    send_bits(s, (DYN_TREES << 1) + (last ? 1 : 0), 3);
    send_all_trees(s, s.l_desc.max_code + 1, s.d_desc.max_code + 1, max_blindex + 1);
    compress_block(s, s.dyn_ltree, s.dyn_dtree);
  }
  // Assert (s->compressed_len == s->bits_sent, "bad compressed size");
  /* The above check is made mod 2^32, for files larger than 512 MB
   * and uLong implemented on 32 bits.
   */
  init_block(s);

  if (last) {
    bi_windup(s);
  }
  // Tracev((stderr,"\ncomprlen %lu(%lu) ", s->compressed_len>>3,
  //       s->compressed_len-7*last));
}

/* ===========================================================================
 * Save the match info and tally the frequency counts. Return true if
 * the current block must be flushed.
 */
function _tr_tally(s, dist, lc)
//    deflate_state *s;
//    unsigned dist;  /* distance of matched string */
//    unsigned lc;    /* match length-MIN_MATCH or unmatched char (if dist==0) */
{
  //var out_length, in_length, dcode;

  s.pending_buf[s.d_buf + s.last_lit * 2]     = (dist >>> 8) & 0xff;
  s.pending_buf[s.d_buf + s.last_lit * 2 + 1] = dist & 0xff;

  s.pending_buf[s.l_buf + s.last_lit] = lc & 0xff;
  s.last_lit++;

  if (dist === 0) {
    /* lc is the unmatched char */
    s.dyn_ltree[lc * 2]/*.Freq*/++;
  } else {
    s.matches++;
    /* Here, lc is the match length - MIN_MATCH */
    dist--;             /* dist = match distance - 1 */
    //Assert((ush)dist < (ush)MAX_DIST(s) &&
    //       (ush)lc <= (ush)(MAX_MATCH-MIN_MATCH) &&
    //       (ush)d_code(dist) < (ush)D_CODES,  "_tr_tally: bad match");

    s.dyn_ltree[(_length_code[lc] + LITERALS + 1) * 2]/*.Freq*/++;
    s.dyn_dtree[d_code(dist) * 2]/*.Freq*/++;
  }

// (!) This block is disabled in zlib defaults,
// don't enable it for binary compatibility

//#ifdef TRUNCATE_BLOCK
//  /* Try to guess if it is profitable to stop the current block here */
//  if ((s.last_lit & 0x1fff) === 0 && s.level > 2) {
//    /* Compute an upper bound for the compressed length */
//    out_length = s.last_lit*8;
//    in_length = s.strstart - s.block_start;
//
//    for (dcode = 0; dcode < D_CODES; dcode++) {
//      out_length += s.dyn_dtree[dcode*2]/*.Freq*/ * (5 + extra_dbits[dcode]);
//    }
//    out_length >>>= 3;
//    //Tracev((stderr,"\nlast_lit %u, in %ld, out ~%ld(%ld%%) ",
//    //       s->last_lit, in_length, out_length,
//    //       100L - out_length*100L/in_length));
//    if (s.matches < (s.last_lit>>1)/*int /2*/ && out_length < (in_length>>1)/*int /2*/) {
//      return true;
//    }
//  }
//#endif

  return (s.last_lit === s.lit_bufsize - 1);
  /* We avoid equality with lit_bufsize because of wraparound at 64K
   * on 16 bit machines and because stored blocks are restricted to
   * 64K-1 bytes.
   */
}

exports._tr_init  = _tr_init;
exports._tr_stored_block = _tr_stored_block;
exports._tr_flush_block  = _tr_flush_block;
exports._tr_tally = _tr_tally;
exports._tr_align = _tr_align;


/***/ }),

/***/ "./node_modules/@gmod/cram/node_modules/pako/lib/zlib/zstream.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@gmod/cram/node_modules/pako/lib/zlib/zstream.js ***!
  \***********************************************************************/
/***/ (function(module) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

function ZStream() {
  /* next input byte */
  this.input = null; // JS specific, because we have no pointers
  this.next_in = 0;
  /* number of bytes available at input */
  this.avail_in = 0;
  /* total number of input bytes read so far */
  this.total_in = 0;
  /* next output byte should be put there */
  this.output = null; // JS specific, because we have no pointers
  this.next_out = 0;
  /* remaining free space at output */
  this.avail_out = 0;
  /* total number of bytes output so far */
  this.total_out = 0;
  /* last error message, NULL if no error */
  this.msg = ''/*Z_NULL*/;
  /* not visible by applications */
  this.state = null;
  /* best guess about the data type: binary or text */
  this.data_type = 2/*Z_UNKNOWN*/;
  /* adler32 value of the uncompressed data */
  this.adler = 0;
}

module.exports = ZStream;


/***/ }),

/***/ "./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramAdapter.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramAdapter.js ***!
  \********************************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CramAdapter; }
/* harmony export */ });
/* harmony import */ var _gmod_cram__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @gmod/cram */ "./node_modules/@gmod/cram/esm/index.js");
/* harmony import */ var _jbrowse_core_data_adapters_BaseAdapter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @jbrowse/core/data_adapters/BaseAdapter */ "./node_modules/@jbrowse/core/data_adapters/BaseAdapter.js");
/* harmony import */ var _jbrowse_core_data_adapters_BaseAdapter__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_jbrowse_core_data_adapters_BaseAdapter__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _jbrowse_core_util__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @jbrowse/core/util */ "./node_modules/@jbrowse/core/util/index.js");
/* harmony import */ var _jbrowse_core_util__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_jbrowse_core_util__WEBPACK_IMPORTED_MODULE_2__);
/* harmony import */ var _jbrowse_core_util_io__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @jbrowse/core/util/io */ "./node_modules/@jbrowse/core/util/io/index.js");
/* harmony import */ var _jbrowse_core_util_io__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_jbrowse_core_util_io__WEBPACK_IMPORTED_MODULE_3__);
/* harmony import */ var _jbrowse_core_util_rxjs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @jbrowse/core/util/rxjs */ "./node_modules/@jbrowse/core/util/rxjs.js");
/* harmony import */ var rxjs_operators__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! rxjs/operators */ "./node_modules/rxjs/_esm5/internal/operators/toArray.js");
/* harmony import */ var _CramSlightlyLazyFeature__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./CramSlightlyLazyFeature */ "./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramSlightlyLazyFeature.js");







class CramAdapter extends _jbrowse_core_data_adapters_BaseAdapter__WEBPACK_IMPORTED_MODULE_1__.BaseFeatureDataAdapter {
    constructor() {
        super(...arguments);
        this.samHeader = {};
        // maps a seqId to original refname, passed specially to render args, to a seqid
        this.seqIdToOriginalRefName = [];
    }
    async configure() {
        const cramLocation = this.getConf('cramLocation');
        const craiLocation = this.getConf('craiLocation');
        if (!cramLocation) {
            throw new Error('missing cramLocation argument');
        }
        if (!craiLocation) {
            throw new Error('missing craiLocation argument');
        }
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const cram = new _gmod_cram__WEBPACK_IMPORTED_MODULE_0__.IndexedCramFile({
            cramFilehandle: (0,_jbrowse_core_util_io__WEBPACK_IMPORTED_MODULE_3__.openLocation)(cramLocation, this.pluginManager),
            index: new _gmod_cram__WEBPACK_IMPORTED_MODULE_0__.CraiIndex({
                filehandle: (0,_jbrowse_core_util_io__WEBPACK_IMPORTED_MODULE_3__.openLocation)(craiLocation, this.pluginManager),
            }),
            seqFetch: this.seqFetch.bind(this),
            checkSequenceMD5: false,
            fetchSizeLimit: 200000000, // just make this a large size to avoid hitting it
        });
        // instantiate the sequence adapter
        const sequenceAdapterType = this.getConf(['sequenceAdapter', 'type']);
        if (!this.getSubAdapter) {
            throw new Error('Error getting subadapter');
        }
        const seqConf = this.getConf('sequenceAdapter');
        const { dataAdapter: sequenceAdapter } = await this.getSubAdapter(seqConf);
        if (!(sequenceAdapter instanceof _jbrowse_core_data_adapters_BaseAdapter__WEBPACK_IMPORTED_MODULE_1__.BaseFeatureDataAdapter)) {
            throw new Error(`CRAM feature adapters cannot use sequence adapters of type '${sequenceAdapterType}'`);
        }
        return { cram, sequenceAdapter };
    }
    async getHeader(opts) {
        const { cram } = await this.configure();
        return cram.cram.getHeaderText(opts);
    }
    async seqFetch(seqId, start, end) {
        start -= 1; // convert from 1-based closed to interbase
        const { sequenceAdapter } = await this.configure();
        const refName = this.refIdToOriginalName(seqId) || this.refIdToName(seqId);
        if (!refName) {
            return undefined;
        }
        const seqChunks = await sequenceAdapter
            .getFeatures({
            refName,
            start,
            end,
            assemblyName: '',
        })
            .pipe((0,rxjs_operators__WEBPACK_IMPORTED_MODULE_6__.toArray)())
            .toPromise();
        const sequence = seqChunks
            .sort((a, b) => a.get('start') - b.get('start'))
            .map(chunk => {
            const chunkStart = chunk.get('start');
            const chunkEnd = chunk.get('end');
            const trimStart = Math.max(start - chunkStart, 0);
            const trimEnd = Math.min(end - chunkStart, chunkEnd - chunkStart);
            const trimLength = trimEnd - trimStart;
            const chunkSeq = chunk.get('seq') || chunk.get('residues');
            return chunkSeq.substr(trimStart, trimLength);
        })
            .join('');
        if (sequence.length !== end - start) {
            throw new Error(`sequence fetch failed: fetching ${refName}:${(start - 1).toLocaleString()}-${end.toLocaleString()} returned ${sequence.length.toLocaleString()} bases, but should have returned ${(end - start).toLocaleString()}`);
        }
        return sequence;
    }
    async setupPre(opts) {
        const { statusCallback = () => { } } = opts || {};
        const configured = await this.configure();
        statusCallback('Downloading index');
        const { cram } = configured;
        const samHeader = await cram.cram.getSamHeader(opts === null || opts === void 0 ? void 0 : opts.signal);
        // use the @SQ lines in the header to figure out the
        // mapping between ref ID numbers and names
        const idToName = [];
        const nameToId = {};
        samHeader
            .filter(l => l.tag === 'SQ')
            .forEach((sqLine, refId) => {
            sqLine.data.forEach(item => {
                if (item.tag === 'SN') {
                    // this is the ref name
                    const refName = item.value;
                    nameToId[refName] = refId;
                    idToName[refId] = refName;
                }
            });
        });
        const readGroups = samHeader
            .filter(l => l.tag === 'RG')
            .map(rgLine => { var _a; return (_a = rgLine.data.find(item => item.tag === 'ID')) === null || _a === void 0 ? void 0 : _a.value; });
        const data = { idToName, nameToId, readGroups };
        statusCallback('');
        this.samHeader = data;
        return { samHeader: data, ...configured };
    }
    async setup(opts) {
        if (!this.setupP) {
            this.setupP = this.setupPre(opts).catch(e => {
                this.setupP = undefined;
                throw e;
            });
        }
        return this.setupP;
    }
    async getRefNames(opts) {
        const { samHeader } = await this.setup(opts);
        if (!samHeader.idToName) {
            throw new Error('CRAM file has no header lines');
        }
        return samHeader.idToName;
    }
    // use info from the SAM header if possible, but fall back to using
    // the ref seq order from when the browser's refseqs were loaded
    refNameToId(refName) {
        if (this.samHeader.nameToId) {
            return this.samHeader.nameToId[refName];
        }
        if (this.seqIdToRefName) {
            return this.seqIdToRefName.indexOf(refName);
        }
        return undefined;
    }
    // use info from the SAM header if possible, but fall back to using
    // the ref seq order from when the browser's refseqs were loaded
    refIdToName(refId) {
        if (this.samHeader.idToName) {
            return this.samHeader.idToName[refId];
        }
        if (this.seqIdToRefName) {
            return this.seqIdToRefName[refId];
        }
        return undefined;
    }
    refIdToOriginalName(refId) {
        return this.seqIdToOriginalRefName[refId];
    }
    getFeatures(region, opts) {
        const { signal, filterBy, statusCallback = () => { } } = opts || {};
        const { refName, start, end, originalRefName } = region;
        return (0,_jbrowse_core_util_rxjs__WEBPACK_IMPORTED_MODULE_4__.ObservableCreate)(async (observer) => {
            const { cram, sequenceAdapter } = await this.setup(opts);
            statusCallback('Downloading alignments');
            if (!this.seqIdToRefName) {
                this.seqIdToRefName = await sequenceAdapter.getRefNames(opts);
            }
            const refId = this.refNameToId(refName);
            if (refId !== undefined) {
                if (originalRefName) {
                    this.seqIdToOriginalRefName[refId] = originalRefName;
                }
                const records = await cram.getRecordsForRange(refId, start, end, opts);
                (0,_jbrowse_core_util__WEBPACK_IMPORTED_MODULE_2__.checkAbortSignal)(signal);
                const { flagInclude = 0, flagExclude = 0, tagFilter, readName, } = filterBy || {};
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                let filtered = records.filter((record) => {
                    const flags = record.flags;
                    return (flags & flagInclude) === flagInclude && !(flags & flagExclude);
                });
                if (tagFilter) {
                    // eslint-disable-next-line @typescript-eslint/no-explicit-any
                    filtered = filtered.filter((record) => {
                        const val = record[tagFilter.tag];
                        return val === '*' ? val !== undefined : val === tagFilter.value;
                    });
                }
                if (readName) {
                    filtered = filtered.filter(
                    // eslint-disable-next-line @typescript-eslint/no-explicit-any
                    (record) => record.readName === readName);
                }
                // eslint-disable-next-line @typescript-eslint/no-explicit-any
                filtered.forEach((record) => {
                    observer.next(this.cramRecordToFeature(record));
                });
            }
            else {
                console.warn('Unknown refName', refName);
            }
            statusCallback('');
            observer.complete();
        }, signal);
    }
    freeResources( /* { region } */) { }
    cramRecordToFeature(record) {
        return new _CramSlightlyLazyFeature__WEBPACK_IMPORTED_MODULE_5__["default"](record, this);
    }
    // we return the configured fetchSizeLimit, and the bytes for the region
    async estimateRegionsStats(regions, opts) {
        const bytes = await this.bytesForRegions(regions, opts);
        const fetchSizeLimit = this.getConf('fetchSizeLimit');
        return {
            bytes,
            fetchSizeLimit,
        };
    }
    /**
     * get the approximate number of bytes queried from the file for the given
     * query regions
     * @param regions - list of query regions
     */
    async bytesForRegions(regions, _opts) {
        const { cram } = await this.configure();
        const blockResults = await Promise.all(regions.map(region => {
            const { refName, start, end } = region;
            const chrId = this.refNameToId(refName);
            return cram.index.getEntriesForRange(chrId, start, end);
        }));
        return blockResults.flat().reduce((a, b) => a + b.sliceBytes, 0);
    }
}
//# sourceMappingURL=CramAdapter.js.map

/***/ }),

/***/ "./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramSlightlyLazyFeature.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@jbrowse/plugin-alignments/esm/CramAdapter/CramSlightlyLazyFeature.js ***!
  \********************************************************************************************/
/***/ (function(__unused_webpack_module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export */ __webpack_require__.d(__webpack_exports__, {
/* harmony export */   "default": function() { return /* binding */ CramSlightlyLazyFeature; }
/* harmony export */ });
class CramSlightlyLazyFeature {
    // uses parameter properties to automatically create fields on the class
    // https://www.typescriptlang.org/docs/handbook/classes.html#parameter-properties
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    constructor(record, _store) {
        this.record = record;
        this._store = _store;
    }
    _get_name() {
        return this.record.readName;
    }
    _get_start() {
        return this.record.alignmentStart - 1;
    }
    _get_end() {
        return this.record.alignmentStart + this.record.lengthOnRef - 1;
    }
    _get_cram_read_features() {
        return this.record.readFeatures;
    }
    _get_type() {
        return 'match';
    }
    _get_score() {
        return this.record.mappingQuality;
    }
    _get_flags() {
        return this.record.flags;
    }
    _get_strand() {
        return this.record.isReverseComplemented() ? -1 : 1;
    }
    _read_group_id() {
        const rg = this._store.samHeader.readGroups;
        return rg ? rg[this.record.readGroupId] : undefined;
    }
    _get_qual() {
        return (this.record.qualityScores || []).join(' ');
    }
    qualRaw() {
        return this.record.qualityScores;
    }
    _get_seq_id() {
        return this._store.refIdToName(this.record.sequenceId);
    }
    _get_refName() {
        return this._get_seq_id();
    }
    _get_is_paired() {
        return !!this.record.mate;
    }
    _get_pair_orientation() {
        return this.record.isPaired() ? this.record.getPairOrientation() : undefined;
    }
    _get_template_length() {
        return this.record.templateLength || this.record.templateSize;
    }
    _get_next_seq_id() {
        return this.record.mate
            ? this._store.refIdToName(this.record.mate.sequenceId)
            : undefined;
    }
    _get_next_pos() {
        return this.record.mate ? this.record.mate.alignmentStart : undefined;
    }
    _get_next_segment_position() {
        return this.record.mate
            ? `${this._store.refIdToName(this.record.mate.sequenceId)}:${this.record.mate.alignmentStart}`
            : undefined;
    }
    _get_tags() {
        const RG = this._read_group_id();
        const { tags } = this.record;
        // avoids a tag copy if no RG, but just copy if there is one
        return RG !== undefined ? { ...tags, RG } : tags;
    }
    _get_seq() {
        return this.record.getReadBases();
    }
    // generate a CIGAR, based on code from jkbonfield
    _get_CIGAR() {
        let seq = '';
        let cigar = '';
        let op = 'M';
        let oplen = 0;
        // not sure I should access these, but...
        const ref = this.record._refRegion.seq;
        const refStart = this.record._refRegion.start;
        let last_pos = this.record.alignmentStart;
        let sublen = 0;
        if (typeof this.record.readFeatures !== 'undefined') {
            // @ts-ignore
            for (let i = 0; i < this.record.readFeatures.length; i++) {
                const { code, refPos, sub, data } = this.record.readFeatures[i];
                sublen = refPos - last_pos;
                seq += ref.substring(last_pos - refStart, refPos - refStart);
                last_pos = refPos;
                if (oplen && op !== 'M') {
                    cigar += oplen + op;
                    oplen = 0;
                }
                if (sublen) {
                    op = 'M';
                    oplen += sublen;
                }
                if (code === 'b') {
                    // An array of bases stored verbatim
                    const ret = data.split(',');
                    const added = String.fromCharCode(...ret);
                    seq += added;
                    last_pos += added.length;
                    oplen += added.length;
                }
                else if (code === 'B') {
                    // Single base (+ qual score)
                    seq += sub;
                    last_pos++;
                    oplen++;
                }
                else if (code === 'X') {
                    // Substitution
                    seq += sub;
                    last_pos++;
                    oplen++;
                }
                else if (code === 'D' || code === 'N') {
                    // Deletion or Ref Skip
                    last_pos += data;
                    if (oplen) {
                        cigar += oplen + op;
                    }
                    cigar += data + code;
                    oplen = 0;
                }
                else if (code === 'I' || code === 'S') {
                    // Insertion or soft-clip
                    seq += data;
                    if (oplen) {
                        cigar += oplen + op;
                    }
                    cigar += data.length + code;
                    oplen = 0;
                }
                else if (code === 'i') {
                    // Single base insertion
                    seq += data;
                    if (oplen) {
                        cigar += oplen + op;
                    }
                    cigar += `${1}I`;
                    oplen = 0;
                }
                else if (code === 'P') {
                    // Padding
                    if (oplen) {
                        cigar += oplen + op;
                    }
                    cigar += `${data}P`;
                }
                else if (code === 'H') {
                    // Hard clip
                    if (oplen) {
                        cigar += oplen + op;
                    }
                    cigar += `${data}H`;
                    oplen = 0;
                } // else q or Q
            }
        }
        else {
            sublen = this.record.readLength - seq.length;
        }
        if (seq.length !== this.record.readLength) {
            sublen = this.record.readLength - seq.length;
            seq += ref.substring(last_pos - refStart, last_pos - refStart + sublen);
            if (oplen && op !== 'M') {
                cigar += oplen + op;
                oplen = 0;
            }
            op = 'M';
            oplen += sublen;
        }
        if (oplen) {
            cigar += oplen + op;
        }
        return cigar;
    }
    tags() {
        const properties = Object.getOwnPropertyNames(CramSlightlyLazyFeature.prototype);
        return properties
            .filter(prop => prop.startsWith('_get_') &&
            prop !== '_get_mismatches' &&
            prop !== '_get_cram_read_features')
            .map(methodName => methodName.replace('_get_', ''));
    }
    id() {
        return `${this._store.id}-${this.record.uniqueId}`;
    }
    get(field) {
        const methodName = `_get_${field}`;
        // @ts-ignore
        if (this[methodName]) {
            // @ts-ignore
            return this[methodName]();
        }
        return undefined;
    }
    parent() {
        return undefined;
    }
    children() {
        return undefined;
    }
    set() { }
    pairedFeature() {
        return false;
    }
    _get_clipPos() {
        const mismatches = this.get('mismatches');
        if (mismatches.length) {
            const record = this.get('strand') === -1
                ? mismatches[mismatches.length - 1]
                : mismatches[0];
            const { type, cliplen } = record;
            if (type === 'softclip' || type === 'hardclip') {
                return cliplen;
            }
        }
        return 0;
    }
    toJSON() {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const tags = {};
        this.tags().forEach((t) => {
            const val = this.get(t);
            if (val !== undefined) {
                tags[t] = val;
            }
        });
        return {
            ...tags,
            name: this.get('name'),
            type: this.get('type'),
            uniqueId: this.id(),
        };
    }
    _get_mismatches() {
        const readFeatures = this.get('cram_read_features');
        const qual = this.qualRaw();
        if (!readFeatures) {
            return [];
        }
        const start = this.get('start');
        const mismatches = new Array(readFeatures.length);
        let j = 0;
        for (let i = 0; i < readFeatures.length; i++) {
            const f = readFeatures[i];
            const { code, pos, data, sub, ref } = f;
            const refPos = f.refPos - 1 - start;
            if (code === 'X') {
                // substitution
                mismatches[j++] = {
                    start: refPos,
                    length: 1,
                    base: sub,
                    qual: qual === null || qual === void 0 ? void 0 : qual[pos],
                    altbase: ref,
                    type: 'mismatch',
                };
            }
            else if (code === 'I') {
                // insertion
                mismatches[j++] = {
                    start: refPos,
                    type: 'insertion',
                    base: `${data.length}`,
                    length: 0,
                };
            }
            else if (code === 'N') {
                // reference skip
                mismatches[j++] = {
                    type: 'skip',
                    length: data,
                    start: refPos,
                    base: 'N',
                };
            }
            else if (code === 'S') {
                // soft clip
                const len = data.length;
                mismatches[j++] = {
                    start: refPos,
                    type: 'softclip',
                    base: `S${len}`,
                    cliplen: len,
                    length: 1,
                };
            }
            else if (code === 'P') {
                // padding
            }
            else if (code === 'H') {
                // hard clip
                const len = data;
                mismatches[j++] = {
                    start: refPos,
                    type: 'hardclip',
                    base: `H${len}`,
                    cliplen: len,
                    length: 1,
                };
            }
            else if (code === 'D') {
                // deletion
                mismatches[j++] = {
                    type: 'deletion',
                    length: data,
                    start: refPos,
                    base: '*',
                };
            }
            else if (code === 'b') {
                // stretch of bases
            }
            else if (code === 'q') {
                // stretch of qual scores
            }
            else if (code === 'B') {
                // a pair of [base, qual]
            }
            else if (code === 'i') {
                // single-base insertion
                // insertion
                mismatches[j++] = {
                    start: refPos,
                    type: 'insertion',
                    base: data,
                    length: 1,
                };
            }
            else if (code === 'Q') {
                // single quality value
            }
        }
        return mismatches.slice(0, j);
    }
}
//# sourceMappingURL=CramSlightlyLazyFeature.js.map

/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/arith_gen.js":
/*!*********************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/arith_gen.js ***!
  \*********************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];
/*
 * Copyright (c) 2019 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

const RangeCoder = __webpack_require__(/*! ./arith_sh */ "./node_modules/@jkbonfield/htscodecs/arith_sh.js");
const IOStream = __webpack_require__(/*! ./iostream */ "./node_modules/@jkbonfield/htscodecs/iostream.js");
const ByteModel = __webpack_require__(/*! ./byte_model */ "./node_modules/@jkbonfield/htscodecs/byte_model.js");
const bzip2 = __webpack_require__(/*! bzip2 */ "./node_modules/bzip2/bzip2.js");

const ARITH_ORDER  = 1
const ARITH_EXT    = 4
const ARITH_STRIPE = 8
const ARITH_NOSIZE = 16
const ARITH_CAT    = 32
const ARITH_RLE    = 64
const ARITH_PACK   = 128

module.exports = class RangeCoderGen {
    decode(src) {
	this.stream = new IOStream(src);
	return this.decodeStream(this.stream)
    }

    decodeStream(stream, n_out=0) {
	var flags = this.stream.ReadByte();
	if (!(flags & ARITH_NOSIZE))
	    n_out = this.stream.ReadUint7();
	var e_len = n_out;

	var order = flags & ARITH_ORDER;

	// 4-way recursion
	if (flags & ARITH_STRIPE)
	    return this.decodeStripe(this.stream, n_out)

	// Meta data
	if (flags & ARITH_PACK) {
	    var P
	    [P, e_len] = this.decodePackMeta(this.stream)
	}

	// NOP, useful for tiny blocks
	if (flags & ARITH_CAT)
	    var data = this.decodeCat(this.stream, e_len)

	// Entropy decode
	else if (flags & ARITH_EXT) {
	    var data = this.decodeExt(this.stream, e_len)
	} else if (flags & ARITH_RLE) {
	    var data = order
		? this.decodeRLE1(this.stream, e_len)
		: this.decodeRLE0(this.stream, e_len)
	} else {
	    var data = order
		? this.decode1(this.stream, e_len)
		: this.decode0(this.stream, e_len)
	}

	// Transforms
	if (flags & ARITH_PACK)
	    data = this.decodePack(data, P, n_out)

	return data
    }

    encode(src, flags) {
	this.stream = new IOStream("", 0, src.length*1.1 + 100); // guestimate worst case!

	this.stream.WriteByte(flags);
	if (!(flags & ARITH_NOSIZE))
	    this.stream.WriteUint7(src.length);

	if (flags & ARITH_STRIPE)
	    return Buffer.concat([this.stream.buf.slice(0, this.stream.pos),
				  this.encodeStripe(this.stream, src, flags>>8)])

	var order = flags & ARITH_ORDER;
	var e_len = src.length;

	// step 1: Encode meta-data
	var pack_meta
	if (flags & ARITH_PACK)
	    [pack_meta, src, e_len] = this.encodePack(src)

	// step 2: Write any meta data
	if (flags & ARITH_PACK)
	    this.stream.WriteStream(pack_meta)

	// step 3: arith encoding below
	if (flags & ARITH_RLE) {
	    return order
		? this.encodeRLE1(src, e_len, this.stream)
		: this.encodeRLE0(src, e_len, this.stream);
	} else {
	    return order
		? this.encode1(src, e_len, this.stream)
		: this.encode0(src, e_len, this.stream);
	}
    }

    //----------------------------------------------------------------------
    // Order-0 codec
    decode0(stream, n_out) {
	var output = new Buffer.allocUnsafe(n_out);

	var max_sym = stream.ReadByte()
	if (max_sym == 0)
	    max_sym = 256

	var byte_model = new ByteModel(max_sym);

	var rc = new RangeCoder(stream);
	rc.RangeStartDecode(stream);

	for (var i = 0; i < n_out; i++)
	    output[i] = byte_model.ModelDecode(stream, rc);

	return output;
    }

    encode0(src, n_in, out) {
	// Count the maximum symbol present
	var max_sym = 0;
	for (var i = 0; i < n_in; i++)
	    if (max_sym < src[i])
		max_sym = src[i]
	max_sym++;  // FIXME not what spec states!?

	var byte_model = new ByteModel(max_sym);
	out.WriteByte(max_sym);
	var rc = new RangeCoder(out);

	for (var i = 0; i < n_in; i++)
	    byte_model.ModelEncode(out, rc, src[i])
	rc.RangeFinishEncode(out)

	return out.buf.slice(0, out.pos);
    }

    //----------------------------------------------------------------------
    // Order-1 codec

    decode1(stream, n_out) {
	var output = new Buffer.allocUnsafe(n_out);

	var max_sym = stream.ReadByte()
	if (max_sym == 0)
	    max_sym = 256

	var byte_model = new Array(max_sym);
	for (var i = 0; i < max_sym; i++)
	    byte_model[i] = new ByteModel(max_sym);

	var rc = new RangeCoder(stream);
	rc.RangeStartDecode(stream);

	var last = 0;
	for (var i = 0; i < n_out; i++) {
	    output[i] = byte_model[last].ModelDecode(stream, rc);
	    last = output[i];
	}

	return output;
    }

    encode1(src, n_in, out) {
	// Count the maximum symbol present
	var max_sym = 0;
	for (var i = 0; i < n_in; i++)
	    if (max_sym < src[i])
		max_sym = src[i]
	max_sym++;  // FIXME not what spec states!

	var byte_model = new Array(max_sym);
	for (var i = 0; i < max_sym; i++)
	    byte_model[i] = new ByteModel(max_sym);
	out.WriteByte(max_sym);
	var rc = new RangeCoder(out);

	var last = 0;
	for (var i = 0; i < n_in; i++) {
	    byte_model[last].ModelEncode(out, rc, src[i])
	    last = src[i]
	}
	rc.RangeFinishEncode(out)

	return out.buf.slice(0, out.pos);
    }

    //----------------------------------------------------------------------
    // External codec
    decodeExt(stream, n_out) {
	// Bzip2 only for now
	var output = new Buffer.allocUnsafe(n_out)
	var bits = bzip2.array(stream.buf.slice(stream.pos))
	var size = bzip2.header(bits)
	var j = 0
	do {
	    var chunk = bzip2.decompress(bits, size);
	    if (chunk != -1) {
	        Buffer.from(chunk).copy(output, j)
	        j += chunk.length
		size -= chunk.length
	    }
	} while(chunk != -1);

	return output
    }

    encodeExt(stream, n_out) {
	// We cannot compress using Bzip2 now as it's
	// absent from bzip2.js, but consider using
	// https://github.com/cscott/compressjs
    }

    //----------------------------------------------------------------------
    // Order-0 RLE codec
    decodeRLE0(stream, n_out) {
	var output = new Buffer.allocUnsafe(n_out);

	var max_sym = stream.ReadByte()
	if (max_sym == 0)
	    max_sym = 256

	var model_lit = new ByteModel(max_sym);
	var model_run = new Array(258);
	for (var i = 0; i <= 257; i++)
	    model_run[i] = new ByteModel(4)

	var rc = new RangeCoder(stream);
	rc.RangeStartDecode(stream);

	var i = 0;
	while (i < n_out) {
	    output[i] = model_lit.ModelDecode(stream, rc)
	    var part = model_run[output[i]].ModelDecode(stream, rc)
	    var run = part
	    var rctx = 256
	    while (part == 3) {
		part = model_run[rctx].ModelDecode(stream, rc)
		rctx = 257
		run += part
	    }
	    for (var j = 1; j <= run; j++)
		output[i+j] = output[i]
	    i += run+1
	}

	return output;
    }

    encodeRLE0(src, n_in, out) {
	// Count the maximum symbol present
	var max_sym = 0;
	for (var i = 0; i < n_in; i++)
	    if (max_sym < src[i])
		max_sym = src[i]
	max_sym++;  // FIXME not what spec states!

	var model_lit = new ByteModel(max_sym);
	var model_run = new Array(258);
	for (var i = 0; i <= 257; i++)
	    model_run[i] = new ByteModel(4)

	out.WriteByte(max_sym);
	var rc = new RangeCoder(out);

	var i = 0
	while (i < n_in) {
	    model_lit.ModelEncode(out, rc, src[i])
	    var run = 1
	    while (i+run < n_in && src[i+run] == src[i])
		run++
	    run--

	    var rctx = src[i]
	    var last = src[i]
	    i += run+1

	    var part = run >= 3 ? 3 : run
	    model_run[rctx].ModelEncode(out, rc, part)
	    run -= part
	    rctx = 256
	    while (part == 3) {
		part = run >= 3 ? 3 : run
		model_run[rctx].ModelEncode(out, rc, part)
		rctx = 257
		run -= part
	    }
	}
	rc.RangeFinishEncode(out)

	return out.buf.slice(0, out.pos);
    }

    //----------------------------------------------------------------------
    // Order-1 RLE codec

    decodeRLE1(stream, n_out) {
	var output = new Buffer.allocUnsafe(n_out);

	var max_sym = stream.ReadByte()
	if (max_sym == 0)
	    max_sym = 256

	var model_lit = new Array(max_sym);
	for (var i = 0; i < max_sym; i++)
	    model_lit[i] = new ByteModel(max_sym);

	var model_run = new Array(258);
	for (var i = 0; i <= 257; i++)
	    model_run[i] = new ByteModel(4)

	var rc = new RangeCoder(stream);
	rc.RangeStartDecode(stream);

	var last = 0;
	var i = 0;
	while (i < n_out) {
	    output[i] = model_lit[last].ModelDecode(stream, rc)
	    last = output[i]
	    var part = model_run[output[i]].ModelDecode(stream, rc)
	    var run = part
	    var rctx = 256
	    while (part == 3) {
		part = model_run[rctx].ModelDecode(stream, rc)
		rctx = 257
		run += part
	    }
	    for (var j = 1; j <= run; j++)
		output[i+j] = output[i]
	    i += run+1
	}

	return output;
    }

    encodeRLE1(src, n_in, out) {
	// Count the maximum symbol present
	var max_sym = 0;
	for (var i = 0; i < n_in; i++)
	    if (max_sym < src[i])
		max_sym = src[i]
	max_sym++;  // FIXME not what spec states!

	var model_lit = new Array(max_sym)
	for (var i = 0; i < max_sym; i++)
	    model_lit[i] = new ByteModel(max_sym);
	var model_run = new Array(258);
	for (var i = 0; i <= 257; i++)
	    model_run[i] = new ByteModel(4)

	out.WriteByte(max_sym);
	var rc = new RangeCoder(out);

	var i = 0
	var last = 0
	while (i < n_in) {
	    model_lit[last].ModelEncode(out, rc, src[i])
	    var run = 1
	    while (i+run < n_in && src[i+run] == src[i])
		run++
	    run--

	    var rctx = src[i]
	    last = src[i]
	    i += run+1

	    var part = run >= 3 ? 3 : run
	    model_run[rctx].ModelEncode(out, rc, part)
	    run -= part
	    rctx = 256
	    while (part == 3) {
		part = run >= 3 ? 3 : run
		model_run[rctx].ModelEncode(out, rc, part)
		rctx = 257
		run -= part
	    }
	}
	rc.RangeFinishEncode(out)

	return out.buf.slice(0, out.pos);
    }

    //----------------------------------------------------------------------
    // Pack method
    decodePackMeta(stream) {
	this.nsym  = stream.ReadByte()

	var M = new Array(this.nsym);
	for (var i = 0; i < this.nsym; i++)
	    M[i] = stream.ReadByte()

	var e_len = stream.ReadUint7(); // Could be derived data from nsym and n_out

	return [M, e_len]
    }

    decodePack(data, M, len) {
	var out = new Buffer.allocUnsafe(len);

	if (this.nsym <= 1) {
	    // Constant value
	    for (var i = 0; i < len; i++)
		out[i] = M[0]

	} else if (this.nsym <= 2) {
	    // 1 bit per value
	    for (var i = 0, j = 0; i < len; i++) {
		if (i % 8 == 0)
		    var v = data[j++]
		out[i] = M[v & 1]
		v >>= 1
	    }

	} else if (this.nsym <= 4) {
	    // 2 bits per value
	    for (var i = 0, j = 0; i < len; i++) {
		if (i % 4 == 0)
		    var v = data[j++]
		out[i] = M[v & 3]
		v >>= 2
	    }

	} else if (this.nsym <= 16) {
	    // 4 bits per value
	    for (var i = 0, j = 0; i < len; i++) {
		if (i % 2 == 0)
		    var v = data[j++]
		out[i] = M[v & 15]
		v >>= 4
	    }

	} else {
	    // 8 bits per value: NOP
	    return data
	}

	return out
    }

    // Compute M array and return meta-data stream
    packMeta(src) {
	var stream = new IOStream("", 0, 1024)

	// Count symbols
	var M = new Array(256)
	for (var i = 0; i < src.length; i++)
	    M[src[i]] = 1

	// Write Map
	for (var nsym = 0, i = 0; i < 256; i++)
	    if (M[i])
		M[i] = ++nsym; // map to 1..N
	stream.WriteByte(nsym);

	// FIXME: add check for nsym > 16?
	// Or just accept it as an inefficient waste of time.
	for (var i = 0; i < 256; i++) {
	    if (M[i]) {
		stream.WriteByte(i) // adjust to 0..N-1
		M[i]--;
	    }
	}

	return [stream, M, nsym]
    }

    encodePack(data) {
	var meta, M, nsym
	[meta, M, nsym] = this.packMeta(data)

	var len = data.length
	var i = 0;
	if (nsym <= 1) {
	    // Constant values
	    meta.WriteUint7(0)
	    return [meta, new Buffer.allocUnsafe(0), 0];
	}

	if (nsym <= 2) {
	    // 1 bit per value
	    var out = new Buffer.allocUnsafe(Math.floor((len+7)/8));
	    for (var i = 0, j = 0; i < (len & ~7); i+=8, j++)
		out[j] = (M[data[i+0]]<<0)
		       + (M[data[i+1]]<<1)
		       + (M[data[i+2]]<<2)
		       + (M[data[i+3]]<<3)
		       + (M[data[i+4]]<<4)
		       + (M[data[i+5]]<<5)
		       + (M[data[i+6]]<<6)
		       + (M[data[i+7]]<<7)
	    if (i < len) {
		out[j] = 0;
		var v = 0;
		while (i < len) {
		    out[j] |= M[data[i++]]<<v;
		    v++;
		}
		j++;
	    }

	    meta.WriteUint7(j)
	    return [meta, out, out.length]
	}

	if (nsym <= 4) {
	    // 2 bits per value
	    var out = new Buffer.allocUnsafe(Math.floor((len+3)/4));
	    for (var i = 0, j = 0; i < (len & ~3); i+=4, j++)
		out[j] = (M[data[i+0]]<<0)
		       + (M[data[i+1]]<<2)
		       + (M[data[i+2]]<<4)
		       + (M[data[i+3]]<<6)

	    if (i < len) {
		out[j] = 0;
		var v = 0;
		while (i < len) {
		    out[j] |= M[data[i++]]<<v;
		    v+=2;
		}
		j++;
	    }

	    meta.WriteUint7(j)
	    return [meta, out, out.length]
	}

	if (nsym <= 16) {
	    // 4 bits per value
	    var out = new Buffer.allocUnsafe(Math.floor((len+1)/2));
	    for (var i = 0, j = 0; i < (len & ~1); i+=2, j++)
		out[j] = (M[data[i+0]]<<0)
		       + (M[data[i+1]]<<4)
	    if (i < len)
		out[j++] = M[data[i++]];

	    meta.WriteUint7(j)
	    return [meta, out, out.length]
	}

	// Otherwise an expensive NOP
	meta.WriteUint7(data.length)
	return [meta, data, data.length]
    }

    //----------------------------------------------------------------------
    // STRIPE method
    encodeStripe(hdr, src, N) {
    if (N == 0)
	N = 4; // old default

	// Split into multiple streams
	var part = new Array(N)
	var ulen = new Array(N)
	for (var s = 0; s < N; s++) {
	    ulen[s] = Math.floor(src.length / N) + ((src.length % N) > s);
	    part[s] = new Array(ulen[s])
	}

	for (var x = 0, i = 0; i < src.length; i+=N, x++) {
	    for (var j = 0; j < N; j++)
		if (x < part[j].length)
		    part[j][x] = src[i+j]
	}

	// Compress each part
	var comp = new Array(N)
	var total = 0
	for (var s = 0; s < N; s++) {
	    // Example: try O0 and O1 and choose best
	    var comp0 = this.encode(part[s], 0)
	    var comp1 = this.encode(part[s], 1)
	    comp[s] = (comp1.length < comp0.length) ? comp1 : comp0
	    total += comp[s].length
	}

	// Serialise
	var out = new IOStream("", 0, total+5*N + 1)
	out.WriteByte(N)
	for (var s = 0; s < N; s++)
	    out.WriteUint7(comp[s].length)

	for (var s = 0; s < N; s++)
	    out.WriteData(comp[s], comp[s].length)

	return out.buf.slice(0, out.buf.pos)
    }

    decodeStripe(stream, len) {
	var N = stream.ReadByte()
	
	// Retrieve lengths
	var clen = new Array(N)
	var ulen = new Array(N)
	for (var j = 0; j < N; j++)
	    clen[j] = stream.ReadUint7()

	// Decode streams
	var T = new Array(N);
	for (var j = 0; j < N; j++) {
	    ulen[j] = Math.floor(len / N) + ((len % N) > j)
	    T[j] = this.decodeStream(stream, ulen[j])
	}

	// Transpose
	var out = new Buffer.allocUnsafe(len)
	for (var j = 0; j < N; j++) {
	    for (var i = 0; i < ulen[j]; i++) {
		out[i*N + j] = T[j][i];
	    }
	}

	return out
    }

    //----------------------------------------------------------------------
    // Cat method
    decodeCat(stream, len) {
	var out = new Buffer.allocUnsafe(len);
	for (var i = 0; i < len; i++)
	    out[i] = stream.ReadByte()

	return out
    }
}


/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/arith_sh.js":
/*!********************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/arith_sh.js ***!
  \********************************************************/
/***/ (function(module) {

/*
 * Copyright (c) 2019 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// An arithmetic coder, based on Eugene Shelwien's reimplementation of
// Michael Schindler range coder.
//
// Order-0 byte stream of ~/scratch/data/q40b
// C:              3.1s decode  (approx same vs 32-bit and 64-bit)
// Arith_sh.js     6.7s decode  (32-bit with carries)
// Arith.js      317.0s decode  (64-bit no carries); int64 crippling it.

//----------------------------------------------------------------------
// Arithmetic (range) coder
module.exports = class RangeCoder {
    constructor(src) {
	this.low   = 0;
	this.range = 0xffffffff;
	this.code  = 0;
	this.FFnum = 0;
	this.carry = 0;
	this.cache = 0;
    }

    RangeStartDecode(src) {
	for (var i = 0; i < 5; i++)
	    this.code = (this.code << 8) + src.ReadByte();
	this.code &= 0xffffffff;
	this.code >>>= 0; // force to be +ve int
    }

    RangeGetFrequency(tot_freq) {
	this.range = Math.floor(this.range / tot_freq);
	//return this.code / this.range;
	return Math.floor(this.code / this.range);

	// Conceptual scenario; return freq only and don't modify range yet
	//return Math.floor(this.code / (Math.floor(this.range / tot_freq)));
    }

    RangeDecode(src, sym_low, sym_freq, tot_freq) {
	// Conceptually we divide range here, but in practice we cached it earlier
	//this.range = Math.floor(this.range / tot_freq);

	this.code  -= sym_low * this.range;
	this.range *= sym_freq;

	while (this.range < (1<<24)) {
	    this.range *= 256;
	    this.code = (this.code*256 + src.ReadByte());
	}
    }

    RangeShiftLow(dst) {
	// We know range is < (1<<24) as we got here.  We already have a
	// cached copy of 8 bits from low.  Is this correct, or does it need
	// fixing?  Possible scenarios.
	// 1. Low < 0xff000000 thus low+range < 0xffffffff and cache
	//    cannot possibly change.  Output cache and as many ffs as needed.
	// 2. We already detected an overflow in RangeEncode, setting carry.
	//    In this case output cached byte + 1 and any 00s needed.
	// 3. Neither case - range is low but we haven't yet detected if we're
	//    XXffffff or XY000000 scenario.  Increase counter for ff/00s.

	if (this.low < 0xff000000 | this.carry) {
	    // cached byte if no overflow, byte+1 otherwise
	    dst.WriteByte(this.cache + this.carry);

	    // Flush any tracked FFs (no carry) or 00s (carry).
	    while (this.FFnum) {
		dst.WriteByte(this.carry-1);
		this.FFnum--;
	    }

	    // Take a copy of top byte ready for next flush
	    this.cache = this.low >>> 24;
	    this.carry = 0;
	} else {
	    this.FFnum++; // keep track of number of trailing ff/00 bytes to write
	}
	this.low <<= 8;
	this.low >>>= 0; // force to be +ve int
    }

    RangeEncode(dst, sym_low, sym_freq, tot_freq) {
	var old_low = this.low
	this.range  = Math.floor(this.range / tot_freq)
	this.low   += sym_low * this.range;
	this.low >>>= 0; // Truncate to +ve int so we can spot overflow
	this.range *= sym_freq;

	// "low + sym*range < old_low" means we overflow; set carry.
	// NB: can this.low < old_low occur twice before range < (1<<24)?
	// We claim not, but prove it!
	if (this.low < old_low) {
	    if (this.carry != 0) console.log("ERROR: Multiple carry")
	    this.carry = 1
	}

	// Renormalise if range gets too small
	while (this.range < (1<<24)) {
	    this.range *= 256;
	    this.RangeShiftLow(dst);
	}
    }

    RangeFinishEncode(dst) {
	for (var i = 0; i < 5; i++)
	    this.RangeShiftLow(dst)
    }
};


/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/byte_model.js":
/*!**********************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/byte_model.js ***!
  \**********************************************************/
/***/ (function(module) {

/*
 * Copyright (c) 2019 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// An adaptive probability model for encoding and decoding of symbols
// within a given alphabet, using the range coder to get/put the
// compressed data.

const MAX_FREQ = ((1<<16)-17)
const STEP     = 16

module.exports = class ByteModel {
    constructor(max_sym = 256) {
	this.total_freq = max_sym;
	this.max_sym = max_sym-1;
	this.S = new Array
	this.F = new Array

	for (var i = 0; i <= this.max_sym; i++) {
	    this.S[i] = i;
	    this.F[i] = 1;
	}
    }

    ModelDecode(src, rc) {
	// Find symbol
	var freq = rc.RangeGetFrequency(this.total_freq);

	// Linear scan to find cumulative frequency 'freq'
	var acc = 0;
	var x = 0;
	while (acc + this.F[x] <= freq)
	    acc += this.F[x++];

//	for (var acc = 0; (acc += this.F[x]) <= freq; x++)
//	    ;
//	acc -= this.F[x];

	// Update range coder
	rc.RangeDecode(src, acc, this.F[x], this.total_freq);

	// Update model
	this.F[x]       += STEP;
	this.total_freq += STEP;
	if (this.total_freq > MAX_FREQ)
	    this.ModelRenormalise();
	

	// Keep symbols approximately frequency sorted
	var sym = this.S[x];
	if (x > 0 && this.F[x] > this.F[x-1]) {
	    var tmp = this.F[x];
	    this.F[x] = this.F[x-1];
	    this.F[x-1] = tmp;

	    tmp = this.S[x];
	    this.S[x] = this.S[x-1];
	    this.S[x-1] = tmp;
	}

	return sym;
    }

    ModelRenormalise() {
	// Halve all the frequencies, being careful not to hit zero
	this.total_freq = 0;
	for (var i = 0; i <= this.max_sym; i++) {
	    this.F[i] -= Math.floor(this.F[i] / 2);
	    this.total_freq += this.F[i];
	}
    }

    ModelEncode(dst, rc, sym) {
	// Find cumulative frequency
	var acc = 0;
	for (var x = 0; this.S[x] != sym; x++)
	    acc += this.F[x];

	// Encode
	rc.RangeEncode(dst, acc, this.F[x], this.total_freq);

	// Update model
	this.F[x]       += STEP;
	this.total_freq += STEP;
	if (this.total_freq > MAX_FREQ) // FIXME x2
	    this.ModelRenormalise();

	// Keep symbols approximately frequency sorted
	var sym = this.S[x];
	if (x > 0 && this.F[x] > this.F[x-1]) {
	    var tmp = this.F[x];
	    this.F[x] = this.F[x-1];
	    this.F[x-1] = tmp;

	    tmp = this.S[x];
	    this.S[x] = this.S[x-1];
	    this.S[x-1] = tmp;
	}
    }
};


/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/fqzcomp.js":
/*!*******************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/fqzcomp.js ***!
  \*******************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];
/* provided dependency */ var process = __webpack_require__(/*! ./node_modules/process/browser.js */ "./node_modules/process/browser.js");
/*
 * Copyright (c) 2019 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

const IOStream = __webpack_require__(/*! ./iostream */ "./node_modules/@jkbonfield/htscodecs/iostream.js");
const ByteModel = __webpack_require__(/*! ./byte_model */ "./node_modules/@jkbonfield/htscodecs/byte_model.js");
const RangeCoder = __webpack_require__(/*! ./arith_sh */ "./node_modules/@jkbonfield/htscodecs/arith_sh.js");


//----------------------------------------------------------------------
// Main arithmetic entry function: decodes a compressed src and
// returns the uncompressed buffer.

function read_array(src, tab, size) {
    var j = 0; // array value
    var z = 0; // array index: tab[j]
    var last = -1;

    // Remove first level of run-length encoding
    var R = new Array(1024) // runs
    while (z < size) {
	var run = src.ReadByte()
	R[j++] = run
	z += run

	if (run == last) {
	    var copy = src.ReadByte()
	    z += run * copy
	    while (copy--)
		R[j++] = run
	}
	last = run
    }

    // Now expand runs in R to tab, noting 255 is max run
    var i = 0
    j = 0
    z = 0
    while (z < size) {
	var run_len = 0
	do {
	    var part = R[j++]
	    run_len += part
	} while (part == 255)
	
	while (run_len--)
	    tab[z++] = i;
	i++
    }
}

const QMAX = 256

const FLAG_DEDUP  = 2
const FLAG_FLEN   = 4
const FLAG_SEL    = 8    // whether selector is used in context
const FLAG_QMAP   = 16
const FLAG_PTAB   = 32
const FLAG_DTAB   = 64
const FLAG_QTAB   = 128

const GFLAG_MULTI_PARAM = 1
const GFLAG_HAVE_STAB   = 2
const GFLAG_DO_REV      = 4

// Compute a new context from our current state and qual q
function fqz_update_ctx(params, state, q) {
    var last = params.context
    state.qctx = ((state.qctx << params.qshift) + params.qtab[q]); // >>> 0
    last += ((state.qctx & ((1<<params.qbits)-1)) << params.qloc); // >>> 0

    if (params.do_pos)
	last += params.ptab[Math.min(state.p, 1023)] << params.ploc

    if (params.do_delta) {
	last += params.dtab[Math.min(state.delta, 255)] << params.dloc
	// Is it better to use q here or qtab[q]?
	// If qtab[q] we can map eg [a-z0-9A-Z]->0 ,->1 and have
	// delta being a token number count into comma separated lists?
	state.delta += (state.prevq != q) ? 1 : 0
	state.prevq = q
    }

    if (params.do_sel)
	last += state.s << params.sloc

    state.p--

    return last & 0xffff
}

function decode_fqz_single_param(src) {
    var p = {} // params
    
    // Load FQZ parameters
    p.context = src.ReadUint16()
    p.pflags  = src.ReadByte()

    p.do_dedup  = p.pflags & FLAG_DEDUP
    p.fixed_len = p.pflags & FLAG_FLEN
    p.do_sel    = p.pflags & FLAG_SEL
    p.do_qmap   = p.pflags & FLAG_QMAP
    p.do_pos    = p.pflags & FLAG_PTAB
    p.do_delta  = p.pflags & FLAG_DTAB
    p.do_qtab   = p.pflags & FLAG_QTAB

    p.max_sym = src.ReadByte()

    var x = src.ReadByte()
    p.qbits  = x>>4
    p.qshift = x&15
    x = src.ReadByte()
    p.qloc = x>>4
    p.sloc = x&15
    x = src.ReadByte()
    p.ploc = x>>4
    p.dloc = x&15

    // Qual map, eg to "unbin" Illumina qualities
    p.qmap = new Array(256);
    if (p.pflags & FLAG_QMAP) {
	for (var i = 0; i < p.max_sym; i++)
	    p.qmap[i] = src.ReadByte()
    } else {
	// Useful optimisation to speed up main loop
	for (var i = 0; i < 256; i++)
	    p.qmap[i] = i;  // NOP
    }

    // Read tables
    p.qtab = new Array(1024);
    if (p.qbits > 0 && (p.pflags & FLAG_QTAB)) {
	read_array(src, p.qtab, 256)
    } else {
	// Useful optimisation to speed up main loop
	for (var i = 0; i < 256; i++)
	    p.qtab[i] = i;  // NOP
    }

    p.ptab = new Array(1024);
    if (p.pflags & FLAG_PTAB)
	read_array(src, p.ptab, 1024);

    p.dtab = new Array(256);
    if (p.pflags & FLAG_DTAB)
	read_array(src, p.dtab, 256);

    return p
}

function decode_fqz_params(src) {
    var gparams = {
	max_sym: 0
    }

    // Check fqz format version
    var vers = src.ReadByte()
    if (vers != 5) {
	console.error("Invalid FQZComp version number");
	return;
    }

    var gflags = src.ReadByte()
    var nparam = (gflags & GFLAG_MULTI_PARAM) ? src.ReadByte() : 1
    var max_sel = gflags.nparam > 1 ? gflags.nparam-1 : 0 // Note max_sel, not num_sel

    var stab = new Array(256);
    if (gflags & GFLAG_HAVE_STAB) {
	max_sel = src.ReadByte()
	read_array(src, stab, 256);
    } else {
	for (var i = 0; i < nparam; i++)
	    stab[i] = i;
	for (; i < 256; i++)
	    stab[i] = nparam-1;
    }
    gparams.do_rev = (gflags & GFLAG_DO_REV)
    gparams.stab = stab
    gparams.max_sel = max_sel

    gparams.params = new Array(gparams.nparam)
    for (var p = 0; p < nparam; p++) {
	gparams.params[p] = decode_fqz_single_param(src)
	if (gparams.max_sym < gparams.params[p].max_sym)
	    gparams.max_sym = gparams.params[p].max_sym
    }

    return gparams
}

function fqz_create_models(gparams) {
    var model = {}

    model.qual = new Array(1<<16)
    for (var i = 0; i < (1<<16); i++)
	model.qual[i] = new ByteModel(gparams.max_sym+1) // +1 as max value not num. values

    model.len = new Array(4)
    for (var i = 0; i < 4; i++)
	model.len[i] = new ByteModel(256)

    model.rev   = new ByteModel(2)
    model.dup   = new ByteModel(2)

    if (gparams.max_sel > 0)
	model.sel = new ByteModel(gparams.max_sel+1) // +1 as max value not num. values

    return model
}

// Initialise a new record, updating state.
// Returns 1 if dup, otherwise 0
function decode_fqz_new_record(src, rc, gparams, model, state, rev) {
    // Parameter selector
    if (gparams.max_sel > 0) {
	state.s = model.sel.ModelDecode(src, rc)
    } else {
	state.s = 0;
    }
    state.x = gparams.stab[state.s]

    var params = gparams.params[state.x]

    // Reset contexts at the start of each new record
    if (params.fixed_len >= 0) {
	// Not fixed or fixed but first record
	var len = model.len[0].ModelDecode(src, rc)
	len |= model.len[1].ModelDecode(src, rc) << 8
	len |= model.len[2].ModelDecode(src, rc) << 16
	len |= model.len[3].ModelDecode(src, rc) << 24
	if (params.fixed_len > 0)
	    params.fixed_len = -len
    } else {
	len = -params.fixed_len
    }
    state.len = len

    if (gparams.do_rev)
	rev[state.rec] = model.rev.ModelDecode(src, rc)

    state.is_dup = 0
    if (params.pflags & FLAG_DEDUP) {
	if (model.dup.ModelDecode(src, rc))
	    state.is_dup = 1
    }

    state.p = len;  // number of remaining bytes in this record
    state.delta = 0
    state.qctx = 0
    state.prevq = 0
    state.rec++
}

function decode_fqz(src, q_lens) {
    // Decode parameter block
    var n_out = src.ReadUint7()
    var gparams = decode_fqz_params(src)
    if (!gparams) return
    var params = gparams.params
    var rev = new Array(q_lens.length)

    // Create initial models
    var model = fqz_create_models(gparams)

    // Create our entropy encoder and output buffers
    var rc = new RangeCoder(src)
    rc.RangeStartDecode(src)
    var output = new Buffer.allocUnsafe(n_out)

    // Internal FQZ state
    var state = {
	qctx:0,   // Qual-only sub-context
	prevq:0,  // Previous quality value
	delta:0,  // Running delta (q vs prevq)
	p:0,      // Number of bases left in current record
	s:0,      // Current parameter selector value (0 if unused)
	x:0,      // "stab" tabulated copy of s
	len:0,    // Length of current string
	is_dup:0, // This string is a duplicate of last
	rec:0     // Record number
    }

    // The main decode loop itself
    var i = 0     // position in output buffer
    while (i < n_out) {
	if (state.p == 0) {
	    decode_fqz_new_record(src, rc, gparams, model, state, rev)
	    if (state.is_dup > 0) {
		if (model.dup.ModelDecode(src, rc)) {
		    // Duplicate of last line
		    for (var x = 0; x < len; x++)
			output[i+x] = output[i+x-state.len]
		    i += state.len
		    state.p = 0
		    continue
		}
	    }
	    q_lens.push(state.len)

	    var params = gparams.params[state.x]
	    var last = params.context
	}

	// Decode the current quality (possibly mapped via qmap)
	var Q = model.qual[last].ModelDecode(src, rc)

	//if (params.do_qmap)
	//    output[i++] = params.qmap[Q];
	//else
	//    output[i++] = Q
	output[i++] = params.qmap[Q]; // optimised version of above
	last = fqz_update_ctx(params, state, Q)
    }

    if (gparams.do_rev)
	reverse_qualities(output, n_out, rev, q_lens)

    return output;
}

function reverse_qualities(qual, qual_len, rev, len) {
    var rec = 0
    var i = 0
    while (i < qual_len) {
	if (rev[rec]) {
	    var j = 0
	    var k = len[rec]-1
	    while (j < k) {
		var tmp   = qual[i+j]
		qual[i+j] = qual[i+k]
		qual[i+k] = tmp
		j++
		k--
	    }
	}

	i += len[rec++];
    }
}

function decode(src, q_lens) {
    var stream = new IOStream(src);

    //var n_out = stream.ReadUint32(); stream.ReadUint32(); // move to main

    return decode_fqz(stream, q_lens);
}
    
//----------------------------------------------------------------------
// FQZComp encoder.

function pick_fqz_params(src, q_lens, q_dirs, qhist) {
    // Find cardinality of q_dirs
    var qd_last = q_dirs[0];
    for (var i = 0; i < q_dirs.length; i++)
	if (q_dirs[i] != qd_last)
	    break;
    var qd_fixed = (i == q_dirs.length) ? 1 : 0

    // Scan input to find number of symbols and max symbol
    var nsym = 0
    var max_sym = 0

    // selector == 0: Assume one single input dataset
    for (var i = 0; i < 256; i++)
	qhist[0][i] = 0;

    var rec = 0;
    var len = 0
    for (var i = 0; i < src.length; i++) {
	if (len == 0) {
	    len = q_lens[rec < q_lens.length-1 ? rec++ : rec]
	}
	qhist[0][src[i]]++;
	len--;
    }
    for (var i = 0; i < 256; i++) {
	if (!qhist[0][i])
	    continue;
	if (max_sym < i)
	    max_sym = i;
	nsym++;
    }

    var qshift = 5
    var do_qmap = 0
    // Reduced symbol frequencies implies lower qshift and
    // a lookup table to go from qual to Q
    if (nsym <= 16) {
	do_qmap = 1 // based on qhist
	if (nsym <= 2)
	    qshift = 1
	else if (nsym <= 4)
	    qshift = 2
	else if (nsym <= 8)
	    qshift = 3
	else
	    qshift = 4
    }

//    // Two params and a 1-bit selector.
//    // This is 1% overhead vs two data sets compressed independently.
//    // It's 6.9% smaller than compressing both together with 1 param.
//    if (0) return [{
//	// q4
//	qbits:     8,
//	qshift:    2,
//	qloc:      7,
//
//	pbits:     7,
//	pshift:    1,
//	ploc:      0,
//
//	dbits:     0,
//	dshift:    0,
//	dloc:      0,
//
//      sbits:     0,
//      sloc:      0,
//
//	//sbits:     2,
//	//do_stab:   1,
//	sbits:     1,
//	do_stab:   0,
//	context:   (0<<15),
//
//	max_sym:   36,
//	nsym:      4,
//
//	do_qmap:   1,
//	do_dedup:  0,
//	fixed_len: 1,
//	do_sel:  0,
//	do_rev:    0,
//	do_pos:    1,
//	do_delta:  0,
//	do_qtab:   0
//    }, {
//	//q40
//	qbits:     9,
//	qshift:    5,
//	qloc:      7,
//
//	pbits:     7,
//	pshift:    0,
//	ploc:      0,
//
//	dbits:     0,
//	dshift:    0,
//	dloc:      0,
//
//      sbits:     0,
//      sloc:      0,
//
//	//sbits:     2,
//	//do_stab:   1,
//	sbits:     1,
//	do_stab:   0,
//	context:   (1<<15),
//
//	max_sym:   44,
//	nsym:      45,
//
//	do_qmap:   0,
//	do_dedup:  0,
//	fixed_len: 1,
//	do_sel:  0,
//	do_rev:    0,
//	do_pos:    1,
//	do_delta:  0,
//	do_qtab:   0
//    }]

    return [{qbits:     8+(qshift>4),
	     qshift:    qshift,
	     qloc:      7,

	     pbits:     7,
	     pshift:    q_lens[0] > 128 ? 1 : 0,
	     ploc:      0,

	     dbits:     qshift>4 ? 0 : 1,
	     dshift:    3,
	     dloc:      15,


	     // NB: Also useful as a way of embedding sel and doing sel
	     // specific contexts. Identical bar context. Eg 0<<15 or 1<<15.
	     sbits:     0,
	     sloc:      15,
	     do_stab:   0,
	     context:   (0<<15),

	     max_sym:   max_sym,
	     nsym:      nsym,

	     do_qmap:   do_qmap,
	     do_dedup:  0,
	     fixed_len: (q_lens.length == 1) ? 1 : 0,
	     do_sel:    0,
	     do_rev:    0,
	     do_pos:    1,
	     do_delta:  (qshift <= 4) ? 1 : 0,
	     do_qtab:   0,

	     // Override above with some attempt at using selectors
	     // when the q_dirs are specific and non-fixed.
	     qbits:     8+(qshift>4)-(qd_fixed==0),
	     sbits:     1,
	     sloc:      15-(qshift<=4), // read1 vs read2
	     do_stab:   1,
	     do_sel:    1,
	     
//	     // q4+dir: 7245769 with, 7353962 without. 1.5% saving
//	     qbits:     6,
//	     dbits:     2,
//	     dshift:    2,
//	     dloc:      13,
//	     sbits:     1,
//	     sloc:      15,
//	     do_stab:   1,
//	     do_sel:    1,

	     // with 20 bits of context, q40 = 31741545
	     // qbits 10, dbits 2, pbits 7, sbits 1
	    }]
}

function store_array(out, tab, size) {
    var i = 0; // index into tab
    var j = 0; // current value in tab[i]

    var tmp1 = new Array(size*2);
    var sz1 = 0;

    // First level of RLE.  Replace all runs of 'j' values
    // with run-lengths, including zeros for missing values.
    // Eg 0 1 2 2 2 3 3 3 4 4 4 5 5 5 5   7 7
    // to 1 1 3     3     3     4       0 2
    while (i < size) {
	// Length of j^{th} element
	var i_start = i
	while (i < size && tab[i] == j)
	    i++;
	var run_len = i - i_start

	// Encode run length to tmp array
	do {
	    var r = Math.min(255, run_len)
	    tmp1[sz1++] = r
	    run_len -= r
	} while (r == 255)
	j++;
    }

    // Second round of RLE on our tmp array, using a different
    // RLE algorithm.
    // Eg 1 1    3 3  3 4 0 2
    // to 1 1 +0 3 3 +1 4 0 2
    var last = -1
    var tmp2 = new Array(size*2)
    var sz2 = 0
    i = 0  // index into tmp1]
    // k is used size of tmp1[]
    while (i < sz1) {
	var curr = tmp1[i++];
	tmp2[sz2++] = curr
	if (curr == last) {
	    var i_start = i;
	    while (i < sz1 && tmp1[i] == last && i - i_start < 255)
		i++;
	    tmp2[sz2++] = i - i_start;
	} else {
	    last = curr
	}
    }

    // Append 2nd RLE, tmp2, to out.
    out.WriteData(tmp2, sz2)
}

				     

// q_lens is an array of quality lengths per record.
// (If they're all the same, just set one value.)
function encode_fqz_params(out, params, qhist, qtab, ptab, dtab, stab) {
    var dsqr = [
        0, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
        4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5,
        5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
        6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7
    ]

    for (var i = 0; i < params.length; i++)
	stab[i] = i; // 1 parameter set per selector value
    for (; i < 256; i++)
	stab[i] = params.length-1;

    // Store global meta-data
    out.WriteByte(5);            // FQZ format number
    var gflags = ((params.length > 1) ? GFLAG_MULTI_PARAM : 0)
	       | ((params[0].do_stab) ? GFLAG_HAVE_STAB   : 0)
    out.WriteByte(gflags)

    if (gflags & GFLAG_MULTI_PARAM)
	out.WriteByte(params.length) // Number of parameter blocks.

    if (gflags & GFLAG_HAVE_STAB) {
	var max_sel = 1<<params[0].sbits;
	if (max_sel > 0) max_sel--;
	out.WriteByte(max_sel)
	store_array(out, stab, 256)
    }

    // Store per-param meta-data
    for (var p = 0; p < params.length; p++) {
	out.WriteUint16(params[p].context)
	out.WriteByte((params[p].do_qtab  ? FLAG_QTAB  : 0) |  // FLAG
		      (params[p].do_delta ? FLAG_DTAB  : 0) |
		      (params[p].do_pos   ? FLAG_PTAB  : 0) |
		      (params[p].do_qmap  ? FLAG_QMAP  : 0) |
		      (params[p].do_sel   ? FLAG_SEL   : 0) |
		      (params[p].fixed_len? FLAG_FLEN  : 0) |
		      (params[p].do_dedup ? FLAG_DEDUP : 0))
	if (params[p].do_qmap)
	    out.WriteByte(params[p].nsym)
	else
	    out.WriteByte(params[p].max_sym)
	out.WriteByte((params[p].qbits << 4) | (params[p].qshift))
	out.WriteByte((params[p].qloc  << 4) | (params[p].sloc))
	out.WriteByte((params[p].ploc  << 4) | (params[p].dloc))

	if (params[p].do_qmap) {
	    params[p].max_sym = params[p].nsym
	    var n = 0;
	    for (var i = 0; i < 256; i++) {
		if (qhist[p][i]) {
		    out.WriteByte(i)
		    qhist[p][i] = n++;
		}
	    }
	    // Ensure we have all matched input params
	    for (; n < params[p].nsym; n++)
		out.WriteByte(0)
	} else {
	    //params[p].nsym = 255;
	    for (var i = 0; i < 256; i++)
		qhist[p][i] = i; // NOP
	}

	if (params[p].qbits > 0) {
	    //	// Eg map 0-44 to a smaller range, to improve context usage.
	    //	// Makes q40 test set go from 33596471 to 33450075 (-0.4%)
	    //	params[p].do_qtab = 1;
	    //	for (var j = i = 0; i < params[p].max_sym; i++) {
	    //	    qtab[i]=j;
	    //	    if ((i%3)!=0 | i >= 28) j++
	    //	    console.log("qtab[",i,"]=",qtab[i]);
	    //	}
	    //	for (; i < 256; i++)
	    //	    qtab[i] = qtab[params[p].max_sym-1]

	    for (var i = 0; i < 256; i++)
		qtab[p][i] = i; // NOP for now

	    if (params[p].do_qtab)
		store_array(out, qtab[p], 256)
	}

	if (params[p].pbits > 0) {
	    for (var i = 0; i < 1024; i++)
		ptab[p][i] = Math.min((1<<params[p].pbits)-1, i >> params[p].pshift)

	    store_array(out, ptab[p], 1024)
	}

	if (params[p].dbits > 0) {
	    for (var i = 0; i < 256; i++)
		if (dsqr[i] > (1<<params[p].dbits) - 1)
		    dsqr[i] = (1<<params[p].dbits) - 1
	    for (var i = 0; i < 256; i++)
		dtab[p][i] = dsqr[Math.min(dsqr.length-1, i >> params[p].dshift)]

	    store_array(out, dtab[p], 256)
	}
    }

    return out
}

function encode_fqz(out, src, q_lens, q_dirs, params, qhist, qtab, ptab, dtab, stab) {
    //console.error("0:",params[0])
    //console.error("1:",params[1])

    var max_sel = 1<<params[0].sbits
    if (max_sel > 0) max_sel--
    var n_in = src.length

    // Create the models
    var max_sym = 0;
    for (var p = 0; p < params.length; p++)
	if (max_sym < params[p].max_sym)
	    max_sym = params[p].max_sym;

    var model_qual = new Array(1<<16)
    for (var i = 0; i < (1<<16); i++)
	model_qual[i] = new ByteModel(max_sym+1)

    var model_len = new Array(4)
    for (var i = 0; i < 4; i++)
	model_len[i] = new ByteModel(256)

    var model_rev    = new ByteModel(2)
    var model_dup    = new ByteModel(2)
    var model_sel    = new ByteModel(max_sel+1)

    // Note: our JavaScript encoder doesn't have a way for reversing
    // some quality strings, so we ignore do_rev for now.
    var rc = new RangeCoder(src)

    // The main encoding loop
    var p = 0; // remaining position along current record
    var i = 0; // index in src data
    var rec = 0;

    while (i < n_in) {
	if (p == 0) {
	    //var s = 0 // single non-mixed sample
	    var s = q_dirs[rec]
	    if (params[0].sbits > 0) {// FIXME: check All params[].do_stab / sbits must be identical
		//console.log("Ssel", s)
	        model_sel.ModelEncode(out, rc, s)
	    }
	    var x = stab[s]

	    // Reset contexts at the statr of each new record
	    var len = q_lens[Math.min(q_lens.length-1, rec++)]
	    if (params[x].fixed_len) {
		if (params[x].fixed_len > 0) { // First length
		    //console.log("Len", len)
		    model_len[0].ModelEncode(out, rc, len       & 0xff)
		    model_len[1].ModelEncode(out, rc, (len>>8)  & 0xff)
		    model_len[2].ModelEncode(out, rc, (len>>16) & 0xff)
		    model_len[3].ModelEncode(out, rc, (len>>24) & 0xff)
		    params[x].fixed_len = -1; // indicate we've stored it once
		}
	    } else {
		//console.log("len", len)
		model_len[0].ModelEncode(out, rc, len       & 0xff)
		model_len[1].ModelEncode(out, rc, (len>>8)  & 0xff)
		model_len[2].ModelEncode(out, rc, (len>>16) & 0xff)
		model_len[3].ModelEncode(out, rc, (len>>24) & 0xff)
	    }

	    if (params[x].do_dedup)
		process.exit(1) // FIXME

	    p = len
	    var delta = 0
	    //var last  = 0
	    var last  = params[x].context
	    var qlast = 0
	    var q1    = 0
	}

	// Encode current quality
	var q = src[i++]
	var Q = qhist[x][q]
	model_qual[last].ModelEncode(out, rc, Q)
	//console.log("Ctx",last,qhist[x][q])

	// Update contexts for next quality
	qlast = (qlast << params[x].qshift) + qtab[x][Q]
	last  = params[x].context
	last += (qlast & ((1<<params[x].qbits)-1)) << params[x].qloc

	// 46.6-48.6 billion cycles with ifs + "<< params[x].?loc" shifts
	// 47.3-47.3 billion cycles with ifs
	// 47.1-47.9 billion cycles without ifs
	if (params[x].pbits > 0)
	    last += ptab[x][Math.min(p, 1023)] << params[x].ploc

	if (params[x].dbits > 0) {
	    last += dtab[x][Math.min(delta, 255)] << params[x].dloc
	    delta += (q1 != Q) ? 1 : 0
	    q1 = Q
	}

	if (params[x].do_sel)
	    last += s << params[x].sloc

	last = (last & 0xffff)
	p--
    }

    rc.RangeFinishEncode(out)
    return out.buf.slice(0, out.pos)
}

function encode(src, q_lens, q_dirs) {
    var qhist = new Array(2)
    var qtab  = new Array(2)
    var ptab  = new Array(2)
    var dtab  = new Array(2)
    var stab  = new Array(256)

    for (var s = 0; s < 2; s++) {
        qhist[s] = new Array(256)
        qtab[s]  = new Array(256)
        ptab[s]  = new Array(1024) 
        dtab[s]  = new Array(256)
    }

    var out = new IOStream("", 0, src.length*1.1 + 100); // FIXME: guestimate worst case

    out.WriteUint7(src.length);
    var params = pick_fqz_params(src, q_lens, q_dirs, qhist)
    var out = encode_fqz_params(out, params, qhist, qtab, ptab, dtab, stab)
    return encode_fqz(out, src, q_lens, q_dirs, params, qhist, qtab, ptab, dtab, stab)
}

module.exports = { decode, encode }


/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/index.js ***!
  \*****************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";
/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];
/*
 * Copyright (c) 2020 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// This is an interface to the htscodecs reference implementation of
// the CRAM 3.1 codecs.

// This JavaScript file is not part of the reference implementation
// and is simply and interface to get a consistent interface for cram-js.



var r4x8    = __webpack_require__(/*! ./rans */ "./node_modules/@jkbonfield/htscodecs/rans.js");
var r4x16   = __webpack_require__(/*! ./rans4x16 */ "./node_modules/@jkbonfield/htscodecs/rans4x16.js");
var arith   = __webpack_require__(/*! ./arith_gen */ "./node_modules/@jkbonfield/htscodecs/arith_gen.js");
var fqzcomp = __webpack_require__(/*! ./fqzcomp */ "./node_modules/@jkbonfield/htscodecs/fqzcomp.js");
var tok3    = __webpack_require__(/*! ./tok3 */ "./node_modules/@jkbonfield/htscodecs/tok3.js");

function r4x8_uncompress(inputBuffer, outputBuffer) {
    r4x8.decode(inputBuffer).copy(outputBuffer, 0, 0);
}

function r4x16_uncompress(inputBuffer, outputBuffer) {
    r4x16.decode(inputBuffer).copy(outputBuffer, 0, 0);
}

function arith_uncompress(inputBuffer, outputBuffer) {
    arith.decode(inputBuffer).copy(outputBuffer, 0, 0);
}

function fqzcomp_uncompress(inputBuffer, outputBuffer) {
    var q_lens = new Array
    fqzcomp.decode(inputBuffer, q_lens).copy(outputBuffer, 0, 0);
}

function tok3_uncompress(inputBuffer, outputBuffer) {
    // Returns in string form instead of buffer
    var out = tok3.decode(inputBuffer, 0, '\0');
    Buffer.from(out, 'binary').copy(outputBuffer, 0, 0);
}

module.exports = {
  r4x8_uncompress:    r4x8_uncompress,
  r4x16_uncompress:   r4x16_uncompress,
  arith_uncompress:   arith_uncompress,
  fqzcomp_uncompress: fqzcomp_uncompress,
  tok3_uncompress:    tok3_uncompress,
};


/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/iostream.js":
/*!********************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/iostream.js ***!
  \********************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];
/*
 * Copyright (c) 2019 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// Turn a buffer into a fake stream with get / put commands.
// This enables up to closely match the published pseudocode.
module.exports = class IOStream {
    constructor(buf, start_pos = 0, size = 0) {
	if (size != 0) {
	    this.buf = Buffer.allocUnsafe(size)
	    this.length = size
	} else {
	    this.buf = buf
	    this.length = buf.length
	}
	this.pos = start_pos
    }

    // ----------
    // Reading
    EOF() {
	return this.pos >= this.length
    }

    ReadData(len) {
	var A = this.buf.slice(this.pos, this.pos+len)
	this.pos += len;
	return A
    }

    ReadByte() {
	const b = this.buf[this.pos]
	this.pos++
	return b
    }

    ReadChar() {
	const b = this.buf[this.pos]
	this.pos++
	return String.fromCharCode(b)
    }

    ReadUint16() {
	var i = this.ReadByte()
	i |= this.ReadByte()<<8
	return i
    }

    ReadUint32() {
	const i = this.buf.readInt32LE(this.pos)
	this.pos += 4
	return i
    }

    // nul terminated string
    ReadString() {
	var s = ""
	do {
	    var b = this.buf[this.pos++]
	    if (b)
		s += String.fromCharCode(b)
	} while (b)
	return s
    }

//    ReadUint7() {
//	// Variable sized unsigned integers
//	var i = 0;
//	var s = 0;
//	do {
//	    var c = this.ReadByte();
//	    i = i | ((c & 0x7f)<<s);
//	    s += 7;
//	} while ((c & 0x80))
//
//	return i;
//    }

    ReadUint7() {
	// Variable sized unsigned integers
	var i = 0;
	do {
	    var c = this.ReadByte();
	    i = (i<<7) | (c & 0x7f)
	} while ((c & 0x80))

	return i;
    }

    ReadITF8() {
	var i = this.buf[this.pos];
	this.pos++;

	//process.stderr.write("i="+i+"\n");

	if (i >= 0xf0) {
	    // 1111xxxx => +4 bytes
	    i = (i & 0x0f) << 28;
	    i += (this.buf[this.pos+0] << 20)
	      +  (this.buf[this.pos+1] << 12)
	      +  (this.buf[this.pos+2] <<  4)
	      +  (this.buf[this.pos+3] >>  4);
	    this.pos += 4;
	    //process.stderr.write("  4i="+i+"\n");
	} else if (i >= 0xe0) {
	    // 1110xxxx => +3 bytes
	    i = (i & 0x0f) << 24;
	    i += (this.buf[this.pos+0] << 16)
	      +  (this.buf[this.pos+1] <<  8)
	      +  (this.buf[this.pos+2] <<  0);
	    this.pos += 3;
	    //process.stderr.write("  3i="+i+"\n");
	} else if (i >= 0xc0) {
	    // 110xxxxx => +2 bytes
	    i = (i & 0x1f) << 16;
	    i += (this.buf[this.pos+0] << 8)
	      +  (this.buf[this.pos+1] << 0);
	    this.pos += 2;
	    //process.stderr.write("  2i="+i+"\n");
	} else if (i >= 0x80) {
	    // 10xxxxxx => +1 bytes
	    i = (i & 0x3f) << 8;
	    i += this.buf[this.pos];
	    this.pos++;;
	    //process.stderr.write("  1i="+i+"\n");
	} else {
	    // 0xxxxxxx => +0 bytes
	}

	return i;
    }

    // ----------
    // Writing
    WriteByte(b) {
	this.buf[this.pos++] = b
    }

    WriteChar(b) {
	this.buf[this.pos++] = b.charCodeAt(0)
    }

    WriteString(str) {
	for (var i = 0; i < str.length; i++)
	    this.buf[this.pos++] = str.charCodeAt(i)
	this.buf[this.pos++] = 0
    }

    WriteData(buf, len) {
	for (var i = 0; i < len; i++)
	    this.buf[this.pos++] = buf[i]
    }

    WriteStream(stream) {
	this.WriteData(stream.buf, stream.pos)
    }

    WriteUint16(u) {
	//this.buf.writeInt16LE(u, this.pos);
	this.WriteByte(u&0xff)
	this.WriteByte((u>>8)&0xff)
    }

    WriteUint32(u) {
	this.buf.writeInt32LE(u, this.pos);
	this.pos += 4;
    }

//    WriteUint7(i) {
//	do {
//	    this.WriteByte((i & 0x7f) | ((i > 0x80) << 7));
//	    i >>= 7;
//	} while (i > 0);
//    }

    WriteUint7(i) {
	var s = 0;
	var X = i;
	do {
	    s += 7;
	    X >>= 7;
	} while (X > 0);

	do {
	    s -= 7;
	    this.WriteByte(((i >> s) & 0x7f) + ((s > 0) << 7))
	} while (s > 0);
    }

    WriteITF8(i) {
	// Horrid, ITF8 is unsigned, but we still write signed into it
	if (i < 0)
	    i = (1<<32) + i

	if (i <= 0x0000007f) {
	    // 1 byte
	    this.buf[this.pos++] = i
	} else if (i <= 0x00003fff) {
	    // 2 bytes
	    this.buf[this.pos++] = 0x80 | Math.floor(i / 256)
	    this.buf[this.pos++] = i & 0xff;
	} else if (i < 0x0001ffff) {
	    // 3 bytes
	    this.buf[this.pos++] = 0xc0 | Math.floor(i / 65536)
	    this.buf[this.pos++] = Math.floor(i / 256) & 0xff
	    this.buf[this.pos++] = i & 0xff;
	} else if (i < 0x0fffffff) {
	    // 4 bytes
	    this.buf[this.pos++] = 0xe0 | Math.floor(i / 16777216)
	    this.buf[this.pos++] = Math.floor(i / 65536) & 0xff
	    this.buf[this.pos++] = Math.floor(i /   256) & 0xff
	    this.buf[this.pos++] = i & 0xff;
	} else {
	    // 5 bytes; oddly using 4.5 bytes
	    this.buf[this.pos++] = 0xf0 | Math.floor(i / 268435456)
	    this.buf[this.pos++] = Math.floor(i / 1048576) & 0xff
	    this.buf[this.pos++] = Math.floor(i /    4096) & 0xff
	    this.buf[this.pos++] = Math.floor(i /       4) & 0xff
	    this.buf[this.pos++] = i & 0x0f;
	}
    }

    // ----------
    // Writing from end of buffer going backwards.
    // Needed by rANS codec.
    WriteByteNeg(b) {
	this.buf[--this.pos] = b;
    }
};


/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/rans.js":
/*!****************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/rans.js ***!
  \****************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];
/*
 * Copyright (c) 2019-2020 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

const IOStream = __webpack_require__(/*! ./iostream */ "./node_modules/@jkbonfield/htscodecs/iostream.js");

//----------------------------------------------------------------------
// rANS primitives itself
//
// RansGet* is decoder side

function RansGetCumulativeFreq(R) {
    return R & 0xfff;
}

function RansGetSymbolFromFreq(C, f) {
    // NOTE: Inefficient.
    // In practice we would implement this via a precomputed
    // lookup table C2S[f]; see RansBuildC2S below.
    var s = 0;
    while (f >= C[s+1])
	s++;

    return s;
}

function RansBuildC2S(C) {
    var C2S = new Array(0x1000);
    var s = 0;
    for (var f = 0; f < 0x1000; f++) {
	while (f >= C[s+1])
	    s++;
	C2S[f] = s;
    }
    return C2S;
}

function RansAdvanceStep(R, c, f) {
    return f * (R >> 12) + (R & 0xfff) - c;
}

function RansRenorm(src, R) {
    while (R < (1<<23))
	R = (R << 8) + src.ReadByte();

    return R;
}


// RanEnc* is for encoder
function RansEncInit() {
    return 1<<23;
}

function RansEncFlush(R, dst) {
    dst.WriteByteNeg((R >> 24) & 0xff);
    dst.WriteByteNeg((R >> 16) & 0xff);
    dst.WriteByteNeg((R >>  8) & 0xff);
    dst.WriteByteNeg((R >>  0) & 0xff);
}

function RansEncRenorm(R, dst, freq, scale_bits) {
    var R_max = (((1 << 23) >> scale_bits) << 8) * freq;

    while (R >= R_max) {
	dst.WriteByteNeg(R & 0xff);
	R >>= 8;
    }
    return R;
}

// Puts a symbol with frequency freq, cumulative freq start
// and total freq 1<<scale_bits.
//
// Note with static probabilities, /freq and %freq could be
// precomputed via multiplies and shifts.
function RansEncPut(R, dst, start, freq, scale_bits) {
    var scale = 1<<scale_bits;
    R = RansEncRenorm(R, dst, freq, scale_bits);
    R = (Math.floor(R / freq) << scale_bits) + (R % freq) + start;
    return R;
}

//----------------------------------------------------------------------
// Main rANS entry function: decodes a compressed src and
// returns the uncompressed buffer.
function decode(src) {
    var stream = new IOStream(src);
    var order = stream.ReadByte();
    var n_in  = stream.ReadUint32();
    var n_out = stream.ReadUint32();

    if (order == 0) {
	return RansDecode0(stream, n_out)
    } else {
	return RansDecode1(stream, n_out)
    }
}

function encode(src, order) {
    //var stream = new IOStream(src);
    //var n_in  = stream.ReadUint32();
    //var n_out = stream.ReadUint32();

    if (order == 0) {
	return RansEncode0(src)
    } else {
	return RansEncode1(src)
    }
}

//----------------------------------------------------------------------
// Order-0 decoder

// Decode a single table of order-0 frequences,
// filling out the F and C arrays.
function ReadFrequencies0(src, F, C) {
    // Initialise; not in the specification - implicit?
    for (var i = 0; i < 256; i++)
	F[i] = 0;

    var sym = src.ReadByte();
    var last_sym = sym;
    var rle = 0;

    // Read F[]
    do {
	var f = src.ReadITF8();
	F[sym] = f;
	if (rle > 0) {
	    rle--;
	    sym++;
	} else {
	    sym = src.ReadByte();
	    if (sym == last_sym+1)
		rle = src.ReadByte();
	}
	last_sym = sym;
    } while (sym != 0);

    // Compute C[] from F[]
    C[0] = 0;
    for (var i = 0; i <= 255; i++)
	C[i+1] = C[i] + F[i];
}

function RansDecode0(src, nbytes) {
    // Decode frequencies
    var F = new Array(256);
    var C = new Array(256);
    ReadFrequencies0(src, F, C);

    // Fast lookup to avoid slow RansGetSymbolFromFreq
    var C2S = RansBuildC2S(C);

    // Initialise rANS state
    var R = new Array(4);
    for (var i = 0; i < 4; i++)
	R[i] = src.ReadUint32();

    // Main decode loop
    var output = new Buffer.allocUnsafe(nbytes);
    for (var i = 0; i < nbytes; i++) {
	var i4 = i%4;
	var f = RansGetCumulativeFreq(R[i4]);
	var s = C2S[f]; // Equiv to RansGetSymbolFromFreq(C, f);

	output[i] = s;
	R[i4] = RansAdvanceStep(R[i4], C[s], F[s]);
	R[i4] = RansRenorm(src, R[i4]);
    }

    return output;
}

//----------------------------------------------------------------------
// Order-0 encoder

function BuildFrequencies0(src, F) {
    for (var i = 0; i < 256; i++)
	F[i] = 0;

    for (var i = 0; i < src.length; i++)
	F[src[i]]++;
}

function NormaliseFrequencies0(F) {
    // Compute total
    var tot = 0;
    for (var i = 0; i < 256; i++)
	tot += F[i];

    // Scale total of frequencies to max
    const max = (1<<12);
    var scale = max / tot;
    do {
	var max_val = 0;
	var max_idx = 0;
	var renorm = 0;
	tot = 0;
	for (var i = 0; i < 256; i++) {
	    if (F[i] == 0)
		continue

	    if (max_val < F[i]) {
		max_val = F[i]
		max_idx = i
	    }

	    F[i] = Math.floor(F[i] * scale);
	    if (F[i] == 0)
		F[i] = 1;

	    tot += F[i];
	}

	// Adjust new tot to ensure it matches.
	if (tot < max) {
	    // Too low, boost the most common symbol
	    F[max_idx] += max-tot;
	} else if (tot-max < F[max_idx]/2 && F[max_idx] > 2) {
	    // Too high, reduce the common symbol
	    F[max_idx] -= tot-max;
	} else if (tot != max) {
	    // Much too high, fudge scale and try again.
	    scale = scale * 0.99
	    renorm = 1;
	}
    } while (renorm)
}

function WriteFrequencies0(out, F) {
    var rle = 0;
    for (var i = 0; i < 256; i++) {
	if (!F[i])
	    continue

	// Output Symbol if needed and Frequency
	if (rle > 0)
	    rle--
	else {
	    out.WriteByte(i)

	    if (i > 0 && F[i-1] > 0) {
		// We've encoded two symbol frequencies in a row.
		// How many more are there?  Store that count so
		// we can avoid writing consecutive symbols.
		for (rle = i+1; rle<256 && F[rle]; rle++)
		    ;
		rle -= i+1;

		out.WriteByte(rle);
	    }
	}

	out.WriteITF8(F[i])
    }
    out.WriteByte(0);
}

function RansEncode0(src) {
    const nbytes = src.length
    var output = new IOStream("", 0, 257*3+9);

    output.WriteByte(0);   // Order 0
    output.WriteUint32(0); // compressed size: correct later
    output.WriteUint32(0); // uncompressed size: correct later

    // Compute frequencies
    var F = new Array(256)
    BuildFrequencies0(src, F)
    NormaliseFrequencies0(F);
    WriteFrequencies0(output, F);

    // Compute cumulative frequencies
    var C = new Array(256)
    C[0] = 0;
    for (var i = 1; i < 256; i++)
	C[i] = C[i-1] + F[i-1];

    // Initialise rANS state
    var R = new Array(4);
    for (var i = 0; i < 4; i++)
	R[i] = RansEncInit();

    var alloc = Math.floor(nbytes*1.05+100)
    var rans_out = new IOStream("", alloc, alloc)

    // Main encode loop
    for (var i = nbytes-1; i >= 0; i--)
	R[i%4] = RansEncPut(R[i%4], rans_out, C[src[i]], F[src[i]], 12);

    for (var i = 3; i >= 0; i--)
	RansEncFlush(R[i], rans_out);

    // Stitch blocks together into final output buffer
    var freq_tab = output.pos
    output.buf.writeInt32LE(freq_tab-9 + (rans_out.length - rans_out.pos), 1);
    output.buf.writeInt32LE(nbytes, 5);

    return Buffer.concat([output.buf.slice(0, output.pos),
			  rans_out.buf.slice(rans_out.pos, rans_out.length)],
			 output.pos + rans_out.length - rans_out.pos);
}

//----------------------------------------------------------------------
// Order-1 decoder

// Decode a table of order-1 frequences,
// filling out the F and C arrays.
function ReadFrequencies1(src, F, C) {
    // Initialise; not in the specification - implicit?
    for (var i = 0; i < 256; i++) {
	F[i] = new Array(256);
	C[i] = new Array(256);
	for (var j = 0; j < 256; j++)
	    F[i][j] = 0;
    }

    var sym = src.ReadByte();
    var last_sym = sym;
    var rle = 0;

    // Read F[]
    do {
	ReadFrequencies0(src, F[sym], C[sym]);

	if (rle > 0) {
	    rle--;
	    sym++;
	} else {
	    sym = src.ReadByte();
	    if (sym == last_sym+1)
		rle = src.ReadByte();
	}
	last_sym = sym;
    } while (sym != 0);
}

function RansDecode1(src, nbytes) {
    // Decode frequencies
    var F = new Array(256);
    var C = new Array(256);
    ReadFrequencies1(src, F, C);

    // Fast lookup to avoid slow RansGetSymbolFromFreq
    var C2S = new Array(256);
    for (var i = 0; i < 256; i++)
	C2S[i] = RansBuildC2S(C[i]);

    // Initialise rANS state
    var R = new Array(4);
    var L = new Array(4);
    for (var j = 0; j < 4; j++) {
	R[j] = src.ReadUint32();
	L[j] = 0;
    }

    // Main decode loop
    var output = new Buffer.allocUnsafe(nbytes);
    var nbytes4 = Math.floor(nbytes/4);
    for (var i = 0; i < nbytes4; i++) {
	for (var j = 0; j < 4; j++) {
	    var f = RansGetCumulativeFreq(R[j]);

	    //var s = RansGetSymbolFromFreq(C[L[j]], f);
	    var s = C2S[L[j]][f]; // Precomputed version of above

	    output[i+j*nbytes4] = s;
	    R[j] = RansAdvanceStep(R[j], C[L[j]][s], F[L[j]][s]);
	    R[j] = RansRenorm(src, R[j]);
	    L[j] = s;
	}
    }

    // Now deal with the remainder if buffer size is not a multiple of 4,
    // using rANS state 3 exclusively.  (It'd have been nice to have
    // designed this to just act as if we kept going with a bail out.)
    i = 4*i;
    while (i < nbytes) {
	var f = RansGetCumulativeFreq(R[3]);
	var s = RansGetSymbolFromFreq(C[L[3]], f);
	output[i++] = s;
	R[3] = RansAdvanceStep(R[3], C[L[3]][s], F[L[3]][s]);
	R[3] = RansRenorm(src, R[3]);
	L[3] = s;
    }

    return output;
}

//----------------------------------------------------------------------
// Order-1 encoder

function BuildFrequencies1(src, F, F0) {
    for (var i = 0; i < 256; i++) {
	F0[i] = 0;
	for (var j = 0; j < 256; j++)
	    F[i][j] = 0;
    }

    var last = 0;
    for (var i = 0; i < src.length; i++) {
	F0[src[i]]++;
	F[last][src[i]]++;
	//F[last][src[i]]++;
	last = src[i];
    }

    // Also accept we'll be starting at 4 points, not just byte 0
    F[0][src[1*(src.length >> 2)]]++;
    F[0][src[2*(src.length >> 2)]]++;
    F[0][src[3*(src.length >> 2)]]++;
    F0[0] += 3;
}

function NormaliseFrequencies1(F, F0) {
    for (var i = 0; i < 256; i++)
	if (F0[i])
	    NormaliseFrequencies0(F[i])
}

function WriteFrequencies1(out, F, F0) {
    var rle = 0;
    var last_sym = 0;

    for (var i = 0; i < 256; i++) {
	if (!F0[i])
	    continue

	// Output Symbol if needed and Frequency
	if (rle > 0)
	    rle--
	else {
	    out.WriteByte(i)

	    if (i > 0 && F0[i-1] > 0) {
		for (rle = i+1; rle<256 && F0[rle]; rle++)
		    ;
		rle -= i+1;
		out.WriteByte(rle);
	    }
	}

	WriteFrequencies0(out, F[i]);
    }
    out.WriteByte(0);
}

function RansEncode1(src) {
    const nbytes = src.length;
    var output = new IOStream("", 0, 257*257*3+9);

    output.WriteByte(1);   // Order 0
    output.WriteUint32(0); // compressed size: correct later
    output.WriteUint32(0); // uncompressed size: correct later

    // Compute frequencies
    var F0 = new Array(256)
    var F = new Array(256)
    var C = new Array(256)
    for (var i = 0; i < 256; i++) {
	F[i] = new Array(256);
	C[i] = new Array(256);
    }

    BuildFrequencies1(src, F, F0)
    NormaliseFrequencies1(F, F0);
    WriteFrequencies1(output, F, F0);

    // Compute cumulative frequencies
    for (var i = 0; i < 256; i++) {
	if (!F0[i])
	    continue;

	C[i][0] = 0;
	for (var j = 1; j < 256; j++)
	    C[i][j] = C[i][j-1] + F[i][j-1];
    }

    // Initialise rANS state
    var R = new Array(4);
    var L = new Array(4);
    for (var j = 0; j < 4; j++) {
	R[j] = RansEncInit();
	L[j] = 0;
    }
    var rans_out = new IOStream("", nbytes, nbytes);

    // We have 4 rans codecs running in parallel on its own 1/4tr of buffer
    var nbytes4 = Math.floor(nbytes/4);
    var idx = new Array(4);
    var last = new Array(4)
    for (var j = 0; j < 4; j++) {
	idx[j] = (j+1)*nbytes4 - 2;
	last[j] = src[idx[j]+1]
    }

    // Deal with the remainder if not a multiple of 4
    last[3] = src[nbytes-1];
    for (var i = nbytes-2; i > 4*nbytes4-2; i--) {
	R[3] = RansEncPut(R[3], rans_out, C[src[i]][last[3]], F[src[i]][last[3]], 12);
	last[3] = src[i];
    }

    // Main encode loop
    while (idx[0] >= 0) {
	for (var j = 3; j >= 0; j--) {
	    var s = src[idx[j]]
	    R[j] = RansEncPut(R[j], rans_out, C[s][last[j]], F[s][last[j]], 12);
	    last[j] = s;
	    idx[j]--;
	}
    }

    for (var j = 3; j >= 0; j--) {
        R[j] = RansEncPut(R[j], rans_out, C[0][last[j]], F[0][last[j]], 12)
    }

    for (var i = 3; i >= 0; i--)
	RansEncFlush(R[i], rans_out);

    // Stitch blocks together into final output buffer
    var freq_tab = output.pos;
    output.buf.writeInt32LE(freq_tab-9 + (rans_out.length - rans_out.pos), 1);
    output.buf.writeInt32LE(nbytes, 5);

    return Buffer.concat([output.buf.slice(0, output.pos),
			  rans_out.buf.slice(rans_out.pos, rans_out.length)],
			 output.pos + rans_out.length - rans_out.pos);
}

module.exports = { decode, encode }


/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/rans4x16.js":
/*!********************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/rans4x16.js ***!
  \********************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];
/*
 * Copyright (c) 2019 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

const IOStream = __webpack_require__(/*! ./iostream */ "./node_modules/@jkbonfield/htscodecs/iostream.js");

//----------------------------------------------------------------------
// rANS primitives itself
//
// RansGet* is decoder side

function RansGetCumulativeFreq(R, bits) {
    return R & ((1<<bits)-1)
}

function RansGetSymbolFromFreq(C, f) {
    // NOTE: Inefficient.
    // In practice we would implement this via a precomputed
    // lookup table C2S[f]; see RansBuildC2S below.
    var s = 0;
    while (f >= C[s+1])
	s++;

    //console.error(f, C, s)

    return s;
}

function RansBuildC2S(C, bits) {
    var max = 1<<bits
    var C2S = new Array(max);
    var s = 0;
    for (var f = 0; f < max; f++) {
	while (f >= C[s+1])
	    s++;
	C2S[f] = s;
    }
    return C2S;
}

function RansAdvanceStep(R, c, f, bits) {
    return f * (R >> bits) + (R & ((1<<bits)-1)) - c;
}

function RansRenorm(src, R) {
    if (R < (1<<15))
	R = (R << 16) + src.ReadUint16();

    return R;
}


// RanEnc* is for encoder
function RansEncInit() {
    return 1<<15;
}

function RansEncFlush(R, dst) {
    dst.WriteByteNeg((R >> 24) & 0xff);
    dst.WriteByteNeg((R >> 16) & 0xff);
    dst.WriteByteNeg((R >>  8) & 0xff);
    dst.WriteByteNeg((R >>  0) & 0xff);
}

function RansEncRenorm(R, dst, freq, scale_bits) {
    //var R_max = (((1 << 15) >> scale_bits) << 16) * freq;
    var R_max = (1 << (31-scale_bits)) * freq

    while (R >= R_max) {
	dst.WriteByteNeg((R>>8) & 0xff);
	dst.WriteByteNeg(R & 0xff);
	R >>= 16;
    }
    return R;
}

// Puts a symbol with frequency freq, cumulative freq start
// and total freq 1<<scale_bits.
//
// Note with static probabilities, /freq and %freq could be
// precomputed via multiplies and shifts.
function RansEncPut(R, dst, start, freq, scale_bits) {
    var scale = 1<<scale_bits;
    R = RansEncRenorm(R, dst, freq, scale_bits);
    R = (Math.floor(R / freq) << scale_bits) + (R % freq) + start;
    return R;
}


//----------------------------------------------------------------------
// Run length encoding
function EncodeRLE(src) {
    // Step 1: find which symbols benefit from RLE
    var L = new Array(256)
    for (var i = 0; i < 256; i++)
	L[i] = 0

    var last = -1
    for (var i = 0; i < src.length; i++) {
	L[src[i]] += src[i] == last ? 1 : -1
	last = src[i]
    }

    var nrle = 0;
    for (var i = 0; i < 256; i++)
	if (L[i] > 0)
	    nrle++

    if (!nrle) {
	// Format cannot cope with zero RLE symbols, so pick one!
	nrle = 1;
	L[0] = 1;
    }

    // Start meta-data as list of symbols to RLE
    var meta = new IOStream("", 0, nrle+1 + src.length)
    meta.WriteByte(nrle)
    for (var i = 0; i < 256; i++)
	if (L[i] > 0)
	    meta.WriteByte(i)

    // Step 2: Now apply RLE itself
    var data = new Buffer.allocUnsafe(src.length)
    var dpos = 0
    for (var i = 0; i < src.length; i++) {
	data[dpos++] = src[i]
	if (L[src[i]] > 0) {
	    last = src[i];
	    var run = 0;
	    while (i+run+1 < src.length && src[i+run+1] == last)
		run++;
	    meta.WriteUint7(run)
	    i += run
	}
    }

    // Compress the meta-data
    var cmeta = RansEncode0(meta.buf.slice(0, meta.pos))
    var hdr = new IOStream("", 0, 16)
    hdr.WriteUint7(meta.pos*2)   // Uncompressed meta-data length + compressed-bit-flag(0)
    hdr.WriteUint7(dpos)         // Length of RLE encoded data
    hdr.WriteUint7(cmeta.length) // Compressed meta-data length
    var meta = Buffer.concat([hdr.buf.slice(0,hdr.pos), cmeta])

    return [meta, data.slice(0, dpos)]
}

function DecodeRLEMeta(src) {
    var u_meta_len = src.ReadUint7()
    var rle_len = src.ReadUint7()

    // Decode RLE lengths
    if (u_meta_len & 1) {
	var rle_meta = src.ReadData((u_meta_len-1)/2)
    } else {
	var comp_meta_len = src.ReadUint7()
	var rle_meta = src.ReadData(comp_meta_len)
	rle_meta = RansDecode0(new IOStream(rle_meta), u_meta_len/2)
    }

    // Decode list of symbols for which RLE lengths are applied
    var rle_meta = new IOStream(rle_meta)
    var L = new Array(256)
    var n = rle_meta.ReadByte()
    if (n == 0)
	n = 256;
    for (var i = 0; i < n; i++)
	L[rle_meta.ReadByte()] = 1

    return [L, rle_meta, rle_len]
}

function DecodeRLE(buf, L, rle_meta, len) {
    var src = new IOStream(buf);

    var out = new Buffer.allocUnsafe(len)

    // Expand up buf+meta to out; i = buf index, j = out index
    var j = 0;
    for (var i = 0; j < len; i++) {
	var sym = buf[i];
	if (L[sym]) {
	    var run = rle_meta.ReadUint7()
	    for (var r = 0; r <= run; r++)
		out[j++] = sym
	} else {
	    out[j++] = sym
	}
    }

    return out
}

//----------------------------------------------------------------------
// Bit packing

function EncodePack(src) {
    // Step 1: identify number of distinct symbols
    var F = new Array(256)
    for (var i = 0; i < 256; i++)
	F[i] = 0

    for (var i = 0; i < src.length; i++)
	F[src[i]]++

    var P = new Array(256)
    var nsym = 0;
    for (var i = 0; i < 256; i++)
	if (F[i] > 0)
	    P[i] = nsym++

    if (nsym > 16) {
	//console.error("Too many symbols to pack:",nsym)
	return
    }


    // Pack data
    if (nsym <= 1) {
	// Constant
	var data = new Buffer.allocUnsafe(0)
    }

    else if (nsym <= 2) {
	// 1 bit per value
	var data = new Buffer.allocUnsafe(Math.ceil(src.length/8))
	var j = -1
	for (i = 0; i < src.length; i++) {
	    if (i % 8 == 0)
		data[++j] = 0
	    data[j] += P[src[i]] << (i % 8)
	}
    }

    else if (nsym <= 4) {
	// 2 bits per value
	var data = new Buffer.allocUnsafe(Math.ceil(src.length/4))
	var j = -1
	for (i = 0; i < src.length; i++) {
	    if (i % 4 == 0)
		data[++j] = 0
	    data[j] += P[src[i]] << ((i % 4) * 2)
	}
    }

    else {
	// 4 bits per value
	var data = new Buffer.allocUnsafe(Math.ceil(src.length/2))
	var j = -1
	for (i = 0; i < src.length; i++) {
	    if (i % 2 == 0)
		data[++j] = 0
	    data[j] += P[src[i]] << ((i % 2) * 4)
	}
    }


    // Produce pack meta-data
    var meta = new IOStream("", 0, nsym+5)
    meta.WriteByte(nsym)
    var j = 0
    for (var i = 0; i < 256; i++) {
	if (F[i] > 0) {
	    F[i] = j++;
	    meta.WriteByte(i)
	}
    }
    meta.WriteUint7(data.length)

    return [meta.buf.slice(0, meta.pos), data]
}


// Pack meta data is the number and value of distinct symbols plus
// the length of the packed byte stream.
function DecodePackMeta(src) {
    var nsym = src.ReadByte()
    var P = new Array(nsym)

    for (var i = 0; i < nsym; i++)
	P[i] = src.ReadByte()

    var len = src.ReadUint7()

    return [P, nsym, len]
}

// Extract bits from src producing output of length len.
// Nsym is number of distinct symbols used.
function DecodePack(data, P, nsym, len) {
    var out = new Buffer.allocUnsafe(len)
    var j = 0;

    // Constant value
    if (nsym <= 1) {
	for (var i = 0; i < len; i++)
	    out[i] = P[0]
    }

    // 1 bit per value
    else if (nsym <= 2) {
	for (i = 0; i < len; i++) {
	    if (i % 8 == 0)
		var v = data[j++];

	    out[i] = P[v & 1]
	    v >>= 1
	}
    }

    // 2 bits per value
    else if (nsym <= 4) {
	for (i = 0; i < len; i++) {
	    if (i % 4 == 0)
		var v = data[j++];

	    out[i] = P[v & 3]
	    v >>= 2
	}
    }

    // 4 bits per value
    else if (nsym <= 16) {
	for (i = 0; i < len; i++) {
	    if (i % 2 == 0)
		var v = data[j++];

	    out[i] = P[v & 15]
	    v >>= 4
	}
    }

    return out
}


//----------------------------------------------------------------------
// 4 way interleaving.
// This is simply 4 rANS streams interleaved to form bytes 0,4,8...,
// 1,5,9..., 2,6,10... and 3,7,11...
//
// It works well when the distributions differ for each of the 4 bytes,
// for example when compressing a series of 32-bit integers.
//
// Maybe make this more general purpose of X* where we specify the stripe
// size instead of fixing it at 4?
function RansEncodeStripe(hdr, src, N) {
    if (N == 0)
	N = 4; // old default

    // Split into multiple streams
    var part = new Array(N)
    var ulen = new Array(N)
    for (var s = 0; s < N; s++) {
	ulen[s] = Math.floor(src.length / N) + ((src.length % N) > s);
	part[s] = new Array(ulen[s])
    }

    for (var x = 0, i = 0; i < src.length; i+=N, x++) {
	for (var j = 0; j < N; j++)
	    if (x < part[j].length)
		part[j][x] = src[i+j]
    }

    // Compress each part
    var comp = new Array(N)
    var total = 0
    for (var s = 0; s < N; s++) {
	// Example: try O0 and O1 and choose best
	var comp0 = encode(part[s], 0)
	var comp1 = encode(part[s], 1)
	comp[s] = (comp1.length < comp0.length) ? comp1 : comp0
	total += comp[s].length
    }

    // Serialise
    var out = new IOStream("", 0, total+5*N+1)
    out.WriteByte(N)
    for (var s = 0; s < N; s++)
	out.WriteUint7(comp[s].length)

    for (var s = 0; s < N; s++)
	out.WriteData(comp[s], comp[s].length)

    return out.buf.slice(0, out.buf.pos)
}

function RansDecodeStripe(src, len) {
    var N = src.ReadByte()

    // Retrieve lengths
    var clen = new Array(N)
    var ulen = new Array(N)
    for (var j = 0; j < N; j++)
	clen[j] = src.ReadUint7()

    // Decode streams
    var T = new Array(N);
    for (var j = 0; j < N; j++) {
	ulen[j] = Math.floor(len / N) + ((len % N) > j)
	T[j] = RansDecodeStream(src, ulen[j])
    }

    // Transpose
    var out = new Buffer.allocUnsafe(len)
    for (var j = 0; j < N; j++) {
	for (var i = 0; i < ulen[j]; i++) {
	    out[i*N + j] = T[j][i];
	}
    }

    return out;
}


//----------------------------------------------------------------------
// Main rANS entry function: decodes a compressed src and
// returns the uncompressed buffer.
function decode(src) {
    var stream = new IOStream(src)
    return RansDecodeStream(stream, 0)
}

function RansDecodeStream(stream, n_out) {
    var format = stream.ReadByte();
    var order  = format & 1
    var stripe = format & 8
    var nosz   = format & 16
    var cat    = format & 32
    var rle    = format & 64
    var pack   = format & 128

    if (!nosz)
	n_out = stream.ReadUint7();

    // N-way interleaving
    if (stripe)
	return RansDecodeStripe(stream, n_out)

    // Bit packing
    if (pack) {
	var pack_len = n_out
	var [P, nsym, n_out] = DecodePackMeta(stream)
    }

    // Run length encoding
    if (rle) {
	var rle_len = n_out
	var [L, rle_meta, n_out] = DecodeRLEMeta(stream)
    }

    // Uncompress data (all, packed or run literals)
    if (cat)
	var buf = stream.ReadData(n_out)
    else if (order == 0)
	var buf = RansDecode0(stream, n_out)
    else
	var buf = RansDecode1(stream, n_out)

    // Apply expansion transforms
    if (rle)
	buf = DecodeRLE(buf, L, rle_meta, rle_len)

    if (pack)
	buf = DecodePack(buf, P, nsym, pack_len)

    return buf
}

function encode(src, format) {
    var hdr = new IOStream("", 0, 10);
    hdr.WriteByte(format);

    var order = format & 1
    var stripe= format & 8
    var nosz  = format & 16
    var cat   = format & 32
    var rle   = format & 64
    var pack  = format & 128

    var N     = format>>8

    if (!nosz)
	hdr.WriteUint7(src.length);

    if (stripe)
	return Buffer.concat([hdr.buf.slice(0, hdr.pos), RansEncodeStripe(hdr, src, N)])

    var pack_meta = new Buffer.alloc(0)
    if (pack)
	[pack_meta, src] = EncodePack(src)

    var rle_meta = new Buffer.alloc(0)
    if (rle)
	[rle_meta, src] = EncodeRLE(src)

    if (src.length < 4 && order == 1) {
	// Protect against short order-1 data due to RLE/Pack
	order = 0
	hdr.buf[0] &= ~1
    }

    if (cat)
	var comp = src
    else if (order == 0)
	var comp = RansEncode0(src)
    else
	var comp = RansEncode1(src)

    return Buffer.concat([hdr.buf.slice(0,hdr.pos), pack_meta, rle_meta, comp])
}

//----------------------------------------------------------------------
// Order-0 decoder

function ReadAlphabet(src) {
    var A = new Array(256)
    for (var i = 0; i < 256; i++)
	A[i] = 0;

    var rle = 0
    var sym = src.ReadByte()
    var last_sym = sym

    do {
	A[sym] = 1;
	if (rle > 0) {
	    rle--
	    sym++
	} else {
	    sym = src.ReadByte()
	    if (sym == last_sym+1)
		rle = src.ReadByte()
	}
	last_sym = sym
    } while (sym != 0)

    return A
}

// Decode a single table of order-0 frequences,
// filling out the F and C arrays.
function ReadFrequencies0(src, F, C) {
    // Initialise; not in the specification - implicit?
    for (var i = 0; i < 256; i++)
	F[i] = 0;

    // Fetch alphabet
    var A = ReadAlphabet(src);

    // Fetch frequencies for the symbols listed in our alphabet
    for (var i = 0; i < 256; i++) {
	if (A[i] > 0)
	    F[i] = src.ReadUint7()
    }

    NormaliseFrequencies0_Shift(F, 12)

    // Compute C[] from F[]
    C[0] = 0;
    for (var i = 0; i <= 255; i++)
	C[i+1] = C[i] + F[i];
}

function RansDecode0(src, nbytes) {
    // Decode frequencies
    var F = new Array(256);
    var C = new Array(256);
    ReadFrequencies0(src, F, C);

    // Fast lookup to avoid slow RansGetSymbolFromFreq
    var C2S = RansBuildC2S(C, 12);

    // Initialise rANS state
    var R = new Array(4);
    for (var i = 0; i < 4; i++)
	R[i] = src.ReadUint32();

    // Main decode loop
    var output = new Buffer.allocUnsafe(nbytes);
    for (var i = 0; i < nbytes; i++) {
	var i4 = i%4;
	var f = RansGetCumulativeFreq(R[i4], 12);
	var s = C2S[f]; // Equiv to RansGetSymbolFromFreq(C, f);

	output[i] = s;
	R[i4] = RansAdvanceStep(R[i4], C[s], F[s], 12);
	R[i4] = RansRenorm(src, R[i4]);
    }

    return output;
}

//----------------------------------------------------------------------
// Order-0 encoder

function BuildFrequencies0(src, F) {
    for (var i = 0; i < 256; i++)
	F[i] = 0;

    for (var i = 0; i < src.length; i++)
	F[src[i]]++;
}

function NormaliseFrequencies0(F, bits) {
    // Compute total
    var tot = 0;
    for (var i = 0; i < 256; i++)
	tot += F[i];

    // Scale total of frequencies to max
    const max = (1<<bits);
    var scale = max / tot;
    do {
	var max_val = 0;
	var max_idx = 0;
	var renorm = 0;
	tot = 0;
	for (var i = 0; i < 256; i++) {
	    if (F[i] == 0)
		continue

	    if (max_val < F[i]) {
		max_val = F[i]
		max_idx = i
	    }

	    F[i] = Math.floor(F[i] * scale);
	    if (F[i] == 0)
		F[i] = 1;

	    tot += F[i];
	}

	// Adjust new tot to ensure it matches.
	if (tot < max) {
	    // Too low, boost the most common symbol
	    F[max_idx] += max-tot;
	} else if (tot-max < F[max_idx]/2 && F[max_idx] > 2) {
	    // Too high, reduce the common symbol
	    F[max_idx] -= tot-max;
	} else if (tot != max) {
	    // Much too high, fudge scale and try again.
	    scale = max / tot;
	    renorm = 1;
	}
    } while (renorm)
}

function NormaliseFrequencies0_Shift(F, bits) {
    // Compute total and number of bits to shift by
    var tot = 0;
    for (var i = 0; i < 256; i++)
	tot += F[i];

    if (tot == 0 || tot == (1<<bits))
	return

    var shift = 0;
    while (tot < (1<<bits)) {
	tot *= 2;
	shift++;
    }

    // Scale total of frequencies to (1<<bits)
    for (var i = 0; i < 256; i++)
	F[i] <<= shift;
}

function WriteAlphabet(out, F) {
    var rle = 0;
    for (var i = 0; i < 256; i++) {
	if (!F[i])
	    continue

	if (rle > 0)
	    rle--
	else {
	    out.WriteByte(i)

	    if (i > 0 && F[i-1] > 0) {
		// We've encoded two symbol frequencies in a row.
		// How many more are there?  Store that count so
		// we can avoid writing consecutive symbols.
		for (rle = i+1; rle<256 && F[rle]; rle++)
		    ;
		rle -= i+1;

		out.WriteByte(rle);
	    }
	}
    }
    out.WriteByte(0)
}

function WriteFrequencies0(out, F) {
    WriteAlphabet(out, F)

    for (var i = 0; i < 256; i++) {
	if (F[i])
	    out.WriteUint7(F[i])
    }
}

function RansEncode0(src) {
    const nbytes = src.length;
    var output = new IOStream("", 0, 257*3+9);

    // Compute frequencies
    var F = new Array(256)
    BuildFrequencies0(src, F)
    var bit_size = Math.ceil(Math.log2(nbytes));
    if (bit_size > 12)
	bit_size = 12;
    NormaliseFrequencies0(F, bit_size);
    WriteFrequencies0(output, F);
    NormaliseFrequencies0(F, 12);

    // Compute cumulative frequencies
    var C = new Array(256)
    C[0] = 0;
    for (var i = 1; i < 256; i++)
	C[i] = C[i-1] + F[i-1];

    // Initialise rANS state
    var R = new Array(4);
    for (var i = 0; i < 4; i++)
	R[i] = RansEncInit();

    // Allow expansion room if trying to compress random data.
    var rans_out = new IOStream("", (nbytes*1.05+100)>>0, (nbytes*1.05+100)>>0);

    // Main encode loop
    for (var i = nbytes-1; i >= 0; i--)
	R[i%4] = RansEncPut(R[i%4], rans_out, C[src[i]], F[src[i]], 12);

    for (var i = 3; i >= 0; i--)
	RansEncFlush(R[i], rans_out);

    // Stitch blocks together into final output buffer
    //console.error("pos=",rans_out.pos, " len=",rans_out.length)
    //console.error(rans_out.buf.slice(rans_out.pos, rans_out.length))
    return Buffer.concat([output.buf.slice(0, output.pos),
			  rans_out.buf.slice(rans_out.pos, rans_out.length)],
			 output.pos + rans_out.length - rans_out.pos);
}

//----------------------------------------------------------------------
// Order-1 decoder

// Decode a table of order-1 frequences,
// filling out the F and C arrays.
function ReadFrequencies1(src, F, C, shift) {
    // Initialise; not in the specification - implicit?
    for (var i = 0; i < 256; i++) {
	F[i] = new Array(256);
	C[i] = new Array(256);
	for (var j = 0; j < 256; j++)
	    F[i][j] = 0;
    }

    // Fetch alphabet
    var A = ReadAlphabet(src);

    // Read F[]
    for (var i = 0; i < 256; i++) {
	if (!A[i])
	    continue

	var run = 0;
	for (var j = 0; j < 256; j++) {
	    if (!A[j])
		continue

	    if (run > 0) {
		run--
	    } else {
		F[i][j] = src.ReadUint7();
		if (F[i][j] == 0)
		    run = src.ReadByte();
	    }
	}

	NormaliseFrequencies0_Shift(F[i], shift)

	// Compute C[] from F[]
	C[i][0] = 0;
	for (var j = 0; j < 256; j++)
	    C[i][j+1] = C[i][j] + F[i][j];
    }
}

function RansDecode1(src, nbytes) {
    // FIXME: this bit is missing from the RansDecode0 pseudocode.

    var comp = src.ReadByte();
    var shift = comp >> 4;

    var freq_src = src
    if (comp & 1) {
	var ulen = src.ReadUint7()
	var clen = src.ReadUint7()
	var comp = new IOStream(src.ReadData(clen))
	var freq_src = new IOStream(RansDecode0(comp, ulen));
    }

    // Decode frequencies
    var F = new Array(256);
    var C = new Array(256);
    ReadFrequencies1(freq_src, F, C, shift);

    // Fast lookup to avoid slow RansGetSymbolFromFreq
    var C2S = new Array(256);
    for (var i = 0; i < 256; i++)
	// Could do only for symbols in alphabet?
	C2S[i] = RansBuildC2S(C[i], shift);

    // Initialise rANS state
    var R = new Array(4);
    var L = new Array(4);
    for (var j = 0; j < 4; j++) {
	R[j] = src.ReadUint32();
	L[j] = 0;
    }

    // Main decode loop
    var output = new Buffer.allocUnsafe(nbytes);
    var nbytes4 = Math.floor(nbytes/4);
    for (var i = 0; i < nbytes4; i++) {
	for (var j = 0; j < 4; j++) {
	    var f = RansGetCumulativeFreq(R[j], shift);

	    //var s = RansGetSymbolFromFreq(C[L[j]], f);
	    var s = C2S[L[j]][f]; // Precomputed version of above

	    output[i+j*nbytes4] = s;
	    R[j] = RansAdvanceStep(R[j], C[L[j]][s], F[L[j]][s], shift);
	    R[j] = RansRenorm(src, R[j]);
	    L[j] = s;
	}
    }

    // Now deal with the remainder if buffer size is not a multiple of 4,
    // using rANS state 3 exclusively.  (It'd have been nice to have
    // designed this to just act as if we kept going with a bail out.)
    i = 4*i;
    while (i < nbytes) {
	var f = RansGetCumulativeFreq(R[3], shift);
	var s = RansGetSymbolFromFreq(C[L[3]], f);
	output[i++] = s;
	R[3] = RansAdvanceStep(R[3], C[L[3]][s], F[L[3]][s], shift);
	R[3] = RansRenorm(src, R[3]);
	L[3] = s;
    }

    return output;
}

//----------------------------------------------------------------------
// Order-1 encoder

function BuildFrequencies1(src, F, F0) {
    for (var i = 0; i < 256; i++) {
	F0[i] = 0;
	for (var j = 0; j < 256; j++)
	    F[i][j] = 0;
    }

    var last = 0;
    for (var i = 0; i < src.length; i++) {
	F0[last]++;
	F[last][src[i]]++;
	last = src[i];
    }
    F0[last]++;

    // Also accept we'll be starting at 4 points, not just byte 0
    F[0][src[1*(src.length >> 2)]]++;
    F[0][src[2*(src.length >> 2)]]++;
    F[0][src[3*(src.length >> 2)]]++;
    F0[0] += 3;
}

function NormaliseFrequencies1(F, F0, shift) {

    for (var i = 0; i < 256; i++) {
	if (!F0[i])
	    continue;

	var bit_size = Math.ceil(Math.log2(F0[i]));
	if (bit_size > shift)
	    bit_size = shift;

	NormaliseFrequencies0(F[i], bit_size)
    }
}

function NormaliseFrequencies1_Shift(F, F0, shift) {
    for (var i = 0; i < 256; i++)
	if (F0[i])
	    NormaliseFrequencies0_Shift(F[i], shift)
}

function WriteFrequencies1(out, F, F0) {
    WriteAlphabet(out, F0)

    for (var i = 0; i < 256; i++) {
	if (!F0[i])
	    continue

	var run = 0
	for (var j = 0; j < 256; j++) {
	    if (!F0[j])
		continue

	    if (run) {
		run--
	    } else {
		out.WriteUint7(F[i][j])

		if (!F[i][j]) {
		    // Count how many more zero-freqs we have
		    for (var k = j+1; k < 256; k++) {
			if (!F0[k])
			    continue

			if (F[i][k] == 0)
			    run++
			else
			    break
		    }
		    out.WriteByte(run)
		}
	    }
	}
    }
}

function RansEncode1(src) {
    const nbytes = src.length;
    var output = new IOStream("", 0, 257*257*3+9);

    // Compute frequencies
    var F0 = new Array(256)
    var F = new Array(256)
    var C = new Array(256)
    for (var i = 0; i < 256; i++) {
	F[i] = new Array(256);
	C[i] = new Array(256);
    }

    // Frequency precision
    var shift = 12;

    BuildFrequencies1(src, F, F0)
    NormaliseFrequencies1(F, F0, shift);

    // Store frequencies, possibly compressed
    var freq = new IOStream("", 0, 257*257*3+9);

    WriteFrequencies1(freq, F, F0);

    var cfreq = RansEncode0(freq.buf.slice(0, freq.pos))
    if (cfreq.length < freq.pos) {
	output.WriteByte(1 | (shift<<4));
	output.WriteUint7(freq.pos)
	output.WriteUint7(cfreq.length)
	output.WriteData(cfreq, cfreq.length);
    } else {
	output.WriteByte(0 | (shift<<4));
	output.WriteData(freq.buf, freq.pos);
    }

    // Normalise and compute cumulative frequencies
    NormaliseFrequencies1_Shift(F, F0, shift);
    for (var i = 0; i < 256; i++) {
	if (!F0[i])
	    continue;

	C[i][0] = 0;
	for (var j = 1; j < 256; j++)
	    C[i][j] = C[i][j-1] + F[i][j-1];
    }

    // Initialise rANS state
    var R = new Array(4);
    var L = new Array(4);
    for (var j = 0; j < 4; j++) {
	R[j] = RansEncInit();
	L[j] = 0;
    }
    var rans_out = new IOStream("", (nbytes*1.05+100)>>0, (nbytes*1.05+100)>>0);

    // We have 4 rans codecs running in parallel on its own 1/4tr of buffer
    var nbytes4 = Math.floor(nbytes/4);
    var idx = new Array(4);
    var last = new Array(4)
    for (var j = 0; j < 4; j++) {
	idx[j] = (j+1)*nbytes4 - 2;
	last[j] = src[idx[j]+1]
    }

    // Deal with the remainder if not a multiple of 4
    last[3] = src[nbytes-1];
    for (var i = nbytes-2; i > 4*nbytes4-2; i--) {
	R[3] = RansEncPut(R[3], rans_out, C[src[i]][last[3]], F[src[i]][last[3]], shift);
	last[3] = src[i];
    }

    // Main encode loop
    while (idx[0] >= 0) {
	for (var j = 3; j >= 0; j--) {
	    var s = src[idx[j]]
	    R[j] = RansEncPut(R[j], rans_out, C[s][last[j]], F[s][last[j]], shift);
	    last[j] = s;
	    idx[j]--;
	}
    }

    for (var j = 3; j >= 0; j--) {
        R[j] = RansEncPut(R[j], rans_out, C[0][last[j]], F[0][last[j]], shift)
    }

    for (var i = 3; i >= 0; i--)
	RansEncFlush(R[i], rans_out);

    // Stitch blocks together into final output buffer
    return Buffer.concat([output.buf.slice(0, output.pos),
			  rans_out.buf.slice(rans_out.pos, rans_out.length)],
			 output.pos + rans_out.length - rans_out.pos);
}

module.exports = { decode, encode }


/***/ }),

/***/ "./node_modules/@jkbonfield/htscodecs/tok3.js":
/*!****************************************************!*\
  !*** ./node_modules/@jkbonfield/htscodecs/tok3.js ***!
  \****************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/buffer/index.js */ "./node_modules/buffer/index.js")["Buffer"];
/*
 * Copyright (c) 2019 Genome Research Ltd.
 * Author(s): James Bonfield
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice,
 *       this list of conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above
 *       copyright notice, this list of conditions and the following
 *       disclaimer in the documentation and/or other materials provided
 *       with the distribution.
 *
 *    3. Neither the names Genome Research Ltd and Wellcome Trust Sanger
 *       Institute nor the names of its contributors may be used to endorse
 *       or promote products derived from this software without specific
 *       prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY GENOME RESEARCH LTD AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GENOME RESEARCH
 * LTD OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// Name tokeniser
//
// This is a reference implementation designed to match the
// written specification as closely as possible.  It is *NOT*
// an efficient implementation, but see comments below.

const IOStream  = __webpack_require__(/*! ./iostream */ "./node_modules/@jkbonfield/htscodecs/iostream.js");
const rans      = __webpack_require__(/*! ./rans4x16 */ "./node_modules/@jkbonfield/htscodecs/rans4x16.js");
const arith_gen = __webpack_require__(/*! ./arith_gen */ "./node_modules/@jkbonfield/htscodecs/arith_gen.js");

var arith = new arith_gen()

const TOK_TYPE    = 0
const TOK_STRING  = 1
const TOK_CHAR    = 2
const TOK_DIGITS0 = 3
const TOK_DZLEN   = 4
const TOK_DUP     = 5
const TOK_DIFF    = 6
const TOK_DIGITS  = 7
const TOK_DELTA   = 8
const TOK_DELTA0  = 9
const TOK_MATCH   = 10
const TOK_NOP     = 11
const TOK_END     = 12

//----------------------------------------------------------------------
// Token byte streams
function DecodeTokenByteStreams(src, in_size, use_arith, nnames) {
    var t = -1

    var B = new Array(256)

    while (!src.EOF()) {
	var ttype = src.ReadByte()
	var tok_new = ttype & 128
	var tok_dup = ttype & 64
	var type    = ttype & 63

	if (tok_new) {
	    t++
	    B[t] = new Array(13)
	}

	if (type != TOK_TYPE && tok_new) {
	    var M = new Array(nnames-1).fill(TOK_MATCH)
	    B[t][TOK_TYPE] = new IOStream(Buffer.from([type].concat(M)))
        }

	if (tok_dup) {
	    var dup_pos  = src.ReadByte()
	    var dup_type = src.ReadByte()
	    B[t][type] = new IOStream(B[dup_pos][dup_type].buf)
	} else {
	    var clen = src.ReadUint7()
	    var data = src.ReadData(clen)

	    if (use_arith)
		B[t][type] = arith.decode(data)
	    else
		B[t][type] = rans.decode(data)
	    B[t][type] = new IOStream(B[t][type])
	}
    }

    return B
}

//----------------------------------------------------------------------
// Token decode
function LeftPadNumber(val, len) {
    var str = val+""
    while (str.length < len)
	str = "0" + str

    return str
}

function DecodeSingleName(B, N, T, n) {
    var type = B[0][TOK_TYPE].ReadByte()
    var dist = B[0][type].ReadUint32()
    var m = n - dist

    if (type == TOK_DUP) {
	N[n] = N[m]
	T[n] = T[m]
	return N[n]
    }
    
    var t = 1
    N[n] = ""
    T[n] = new Array(256)
    do {
	type = B[t][TOK_TYPE].ReadByte()

	switch(type) {
	case TOK_CHAR:
	    T[n][t] = B[t][TOK_CHAR].ReadChar()
	    break

	case TOK_STRING:
	    T[n][t] = B[t][TOK_STRING].ReadString()
	    break
	
	case TOK_DIGITS:
	    T[n][t] = B[t][TOK_DIGITS].ReadUint32()
	    break

	case TOK_DIGITS0:
	    var d = B[t][TOK_DIGITS0].ReadUint32()
	    var l = B[t][TOK_DZLEN].ReadByte()
	    T[n][t] = LeftPadNumber(d, l)
	    break

	case TOK_DELTA:
	    T[n][t] = (T[m][t]>>0) + B[t][TOK_DELTA].ReadByte()
	    break

	case TOK_DELTA0:
	    var d = (T[m][t]>>0) + B[t][TOK_DELTA0].ReadByte()
	    var l = T[m][t].length
	    T[n][t] = LeftPadNumber(d, l)
	    break

	case TOK_MATCH:
	    T[n][t] = T[m][t]
	    break

	default:
	    T[n][t] = ""
	    break
	}

	N[n] += T[n][t++]
    } while (type != TOK_END)

    return N[n]
}

//----------------------------------------------------------------------
// Main tokeniser decode entry function: decodes a compressed src and
// returns the uncompressed buffer.
function decode(src, len, separator) {
    var src = new IOStream(src)
    var ulen = src.ReadUint32()
    var nnames = src.ReadUint32()
    var use_arith = src.ReadByte()

    var B = DecodeTokenByteStreams(src, len, use_arith, nnames)
    var N = new Array(nnames)
    var T = new Array(nnames)

    var str = ""
    if (typeof separator === 'undefined')
	separator = '\n'
    for (var i = 0; i < nnames; i++)
	str += DecodeSingleName(B, N, T, i) + separator

    return str
}

//----------------------------------------------------------------------
// Main tokeniser encode function

// Encoder is trickier than decode as we have a lot of decisions to make.
// However here we just make a simple guess without anything complex,
// to demonstrate the basic idea.  See the C implementation for further
// expansion on this.
function encode(src, use_arith) {
    // Convert buffer to array of names
    var str = src.toString()
    if (str[str.length-1] == '\n')
	str = str.substring(0,str.length-1)
    var names = str.split("\n")

    var out = new IOStream("", 0, str.length*2 + 10000) // guess max size
    out.WriteUint32(str.length)
    out.WriteUint32(names.length)
    out.WriteByte(use_arith)

    // Tokenise names
    var T = new Array(names.length)
    var H = {}
    var F = new Array(256).fill(0) // DELTA vs DIGIT frequency
    var max_tok = 0
    var max_len = 0
    for (var i = 0; i < names.length; i++) {
	var [ntok,len] = TokeniseName(T, H, F, names[i], i)
	if (max_tok < ntok)
	    max_tok = ntok
	if (max_len < len)
	    max_len = len
    }

    // Convert tokens to byte streams and serialise
    for (var tnum = 0; tnum < max_tok; tnum++) {
	var B = new Array(TOK_END+1)
	for (var type = 0; type <= TOK_END; type++)
	    B[type] = new IOStream("", 0, names.length * max_len)

	FillByteStreams(B, T, tnum, names, max_tok, max_len)
	SerialiseByteStreams(B, tnum, use_arith, out)
    }

    return out.buf.slice(0, out.pos)
}

function FillByteStreams(B, T, tnum, names, max_tok, max_len) {
    // Create byte streams B[]
    for (var n = 0; n < names.length; n++) {
	if (tnum > 0 && T[n][0].type == TOK_DUP)
	    continue

	if (!T[n][tnum])
	    continue

	B[TOK_TYPE].WriteByte(T[n][tnum].type)

	switch (T[n][tnum].type) {
	case TOK_DIFF:
	    B[TOK_DIFF].WriteUint32(T[n][tnum].val)
	    break

	case TOK_DUP:
	    B[TOK_DUP].WriteUint32(T[n][tnum].val)
	    break

	case TOK_STRING:
	    B[TOK_STRING].WriteString(T[n][tnum].val)
	    break

	case TOK_CHAR:
	    B[TOK_CHAR].WriteChar(T[n][tnum].val)
	    break

	case TOK_DIGITS:
	    B[TOK_DIGITS].WriteUint32(T[n][tnum].val)
	    break

	case TOK_DIGITS0:
	    B[TOK_DIGITS0].WriteUint32(T[n][tnum].val)
	    B[TOK_DZLEN].WriteByte(T[n][tnum].val.length)
	    break

	case TOK_DELTA:
	    B[T[n][tnum].type].WriteByte(T[n][tnum].val)
	    break

	case TOK_DELTA0:
	    B[T[n][tnum].type].WriteByte(T[n][tnum].val)
	    break
	}
    }
}

function SerialiseByteStreams(B, tnum, use_arith, out) {
    // Compress and serialise byte streams B[]
    for (var type = 0; type <= TOK_END; type++) {
	if (B[type].pos <= 0)
	    continue

	out.WriteByte(type + ((type == 0) ? 128 : 0))

	// IOStream to sized buffer
	B[type] = B[type].buf.slice(0, B[type].pos)
	var comp = try_compress(B[type], use_arith)

	out.WriteUint7(comp.length)
	out.WriteData(comp, comp.length)
    }
}

function try_compress(src, use_arith) {
    var best = 1<<30
    var comp

    var methods = [0, 1, 64, 65, 128, 129, 193+8]
    for (var i in methods) {
	var lvl = methods[i]
	if ((lvl & 1) && src.length < 100)
	    continue

	if ((lvl & 8) && (src.length % 4) != 0)
	    continue

	try {
	    var tmp = use_arith
		? arith.encode(src, lvl)
		: rans.encode(src, lvl)
	} catch (e) {
	    var tmp = 0
	}
	if (tmp && best > tmp.length) {
	    best = tmp.length
	    comp = tmp
	}
    }

    return comp
}

function TokeniseName(T, H, F, name, n) {
    var max_len = 0

    // Always compare against last name only
    var p = n-1
    T[n] = new Array(256)

    if (H[name]) {
	//console.error(name,H[name],n)
	T[n][0] = {
	    type: TOK_DUP,
	    val:  n - H[name]
	}
    } else {
	T[n][0] = {
	    type: TOK_DIFF,
	    val:  n == 0 ? 0 : 1
	}
    }

    H[name] = n

    // Splits on alphanumerics, punctuation
    var tok = name.match(/([a-zA-Z0-9]{1,9})|([^a-zA-Z0-9]+)/g)
    for (var i = 0; i < tok.length; i++) {
	var t = i+1 // token 0 = DIFF vs DUP
	var type = TOK_STRING
	var val = tok[i]
	if (tok[i].match(/^0+[0-9]*$/g))
	    type = TOK_DIGITS0
	else if (tok[i].match(/^[0-9]+$/g))
	    type = TOK_DIGITS
	else if (tok[i].length == 1)
	    type = TOK_CHAR

	if (p >= 0 && T[p][t]) {
	    if (T[p][t].str == tok[i]) {
		type = TOK_MATCH
		val = ""
	    } else if (T[p][t].type == TOK_DIGITS || T[p][t].type == TOK_DELTA) {
		var d = val - T[p][t].str;
		F[t]++
		if (d >= 0 && d < 256 && F[t] > n/2) {
		    type = TOK_DELTA
		    val = d
		}
	    } else if ((T[p][t].type == TOK_DIGITS0 || T[p][t].type == TOK_DELTA0)
		       && T[p][t].str.length == val.length) {
		var d = val - T[p][t].str;
		F[t]++
		if (d >= 0 && d < 256 && F[t] > n/2) {
		    type = TOK_DELTA0
		    val = d
		}
	    }
	}

	T[n][t] = {
	    str:  tok[i],
	    val:  val,
	    type: type
	}

	if (max_len < T[n][t].val.length+3)  // +3 for integers; 5 -> (Uint32)5
	    max_len = T[n][t].val.length+3

	//console.error(t,T[n][t])
    }
    T[n][++t] = {
	type: TOK_END
    }

    return [t+1, max_len]
}

module.exports = { encode, decode }


/***/ }),

/***/ "./node_modules/bzip2/bzip2.js":
/*!*************************************!*\
  !*** ./node_modules/bzip2/bzip2.js ***!
  \*************************************/
/***/ (function(module) {

/*
bzip2.js - a small bzip2 decompression implementation

Copyright 2011 by antimatter15 (antimatter15@gmail.com)

Based on micro-bunzip by Rob Landley (rob@landley.net).

Based on bzip2 decompression code by Julian R Seward (jseward@acm.org),
which also acknowledges contributions by Mike Burrows, David Wheeler,
Peter Fenwick, Alistair Moffat, Radford Neal, Ian H. Witten,
Robert Sedgewick, and Jon L. Bentley.

I hereby release this code under the GNU Library General Public License
(LGPL) version 2, available at http://www.gnu.org/copyleft/lgpl.html
*/

var bzip2 = {};

bzip2.array = function (bytes) {
    var bit = 0,
        byte = 0;
    var BITMASK = [0, 0x01, 0x03, 0x07, 0x0F, 0x1F, 0x3F, 0x7F, 0xFF];
    return function (n) {
        var result = 0;
        while (n > 0) {
            var left = 8 - bit;
            if (n >= left) {
                result <<= left;
                result |= (BITMASK[left] & bytes[byte++]);
                bit = 0;
                n -= left;
            } else {
                result <<= n;
                result |= ((bytes[byte] & (BITMASK[n] << (8 - n - bit))) >> (8 - n - bit));
                bit += n;
                n = 0;
            }
        }
        return result
    }
}

bzip2.simple = function (bits) {
    var size = bzip2.header(bits);
    var all, chunk, chunks = [];
    var index = 0;
    do {
        //all += chunk;
        chunk = bzip2.decompress(bits, size);
        //all.set(chunk, index);
        if (chunk != -1) {
            chunks.push(chunk);
            index += chunk.byteLength;
        }
    } while (chunk != -1);
    all = new Uint8Array(index);
    index = 0;
    for (var i = 0; i < chunks.length; ++i) {
        chunk = chunks[i];
        all.set(chunk, index);
        index += chunk.byteLength;
    }
    return all;
}

bzip2.header = function (bits) {
    if (bits(8 * 3) != 4348520)
        throw "No magic number found";
    var i = bits(8) - 48;
    if (i < 1 || i > 9)
        throw "Not a BZIP archive";
    return i;
};

//takes a function for reading the block data (starting with 0x314159265359)
//a block size (0-9) (optional, defaults to 9)
//a length at which to stop decompressing and return the output
bzip2.decompress = function (bits, size, len) {
    var MAX_HUFCODE_BITS = 20;
    var MAX_SYMBOLS = 258;
    var SYMBOL_RUNA = 0;
    var SYMBOL_RUNB = 1;
    var GROUP_SIZE = 50;

    var bufsize = 100000 * 9;
    for (var h = '', i = 0; i < 6; i++)
        h += bits(8).toString(16);
    if (h == "177245385090")
        return -1; //last block
    if (h != "314159265359")
        throw "eek not valid bzip data";
    bits(32); //ignore CRC codes
    if (bits(1))
        throw "unsupported obsolete version";
    var origPtr = bits(24);
    if (origPtr > bufsize)
        throw "Initial position larger than buffer size";
    var t = bits(16);
    var symToByte = new Uint8Array(256),
        symTotal = 0;
    for (i = 0; i < 16; i++) {
        if (t & (1 << (15 - i))) {
            var k = bits(16);
            for (j = 0; j < 16; j++) {
                if (k & (1 << (15 - j))) {
                    symToByte[symTotal++] = (16 * i) + j;
                }
            }
        }
    }

    var groupCount = bits(3);
    if (groupCount < 2 || groupCount > 6)
        throw "another error";
    var nSelectors = bits(15);
    if (nSelectors == 0)
        throw "meh";
    var mtfSymbol = []; //TODO: possibly replace JS array with typed arrays
    for (var i = 0; i < groupCount; i++)
        mtfSymbol[i] = i;
    var selectors = new Uint8Array(32768);

    for (var i = 0; i < nSelectors; i++) {
        for (var j = 0; bits(1); j++)
            if (j >= groupCount)
                throw "whoops another error";
        var uc = mtfSymbol[j];
        mtfSymbol.splice(j, 1); //this is a probably inefficient MTF transform
        mtfSymbol.splice(0, 0, uc);
        selectors[i] = uc;
    }

    var symCount = symTotal + 2;
    var groups = [];
    for (var j = 0; j < groupCount; j++) {
        var length = new Uint8Array(MAX_SYMBOLS),
            temp = new Uint8Array(MAX_HUFCODE_BITS + 1);
        t = bits(5); //lengths
        for (var i = 0; i < symCount; i++) {
            while (true) {
                if (t < 1 || t > MAX_HUFCODE_BITS)
                    throw "I gave up a while ago on writing error messages";
                if (!bits(1))
                    break;
                if (!bits(1))
                    t++;
                else
                    t--;
            }
            length[i] = t;
        }
        var minLen, maxLen;
        minLen = maxLen = length[0];
        for (var i = 1; i < symCount; i++) {
            if (length[i] > maxLen)
                maxLen = length[i];
            else if (length[i] < minLen)
                minLen = length[i];
        }
        var hufGroup;
        hufGroup = groups[j] = {};
        hufGroup.permute = new Uint32Array(MAX_SYMBOLS);
        hufGroup.limit = new Uint32Array(MAX_HUFCODE_BITS + 1);
        hufGroup.base = new Uint32Array(MAX_HUFCODE_BITS + 1);
        hufGroup.minLen = minLen;
        hufGroup.maxLen = maxLen;
        var base = hufGroup.base.subarray(1);
        var limit = hufGroup.limit.subarray(1);
        var pp = 0;
        for (var i = minLen; i <= maxLen; i++)
            for (var t = 0; t < symCount; t++)
                if (length[t] == i)
                    hufGroup.permute[pp++] = t;
        for (i = minLen; i <= maxLen; i++)
            temp[i] = limit[i] = 0;
        for (i = 0; i < symCount; i++)
            temp[length[i]]++;
        pp = t = 0;
        for (i = minLen; i < maxLen; i++) {
            pp += temp[i];
            limit[i] = pp - 1;
            pp <<= 1;
            base[i + 1] = pp - (t += temp[i]);
        }
        limit[maxLen] = pp + temp[maxLen] - 1;
        base[minLen] = 0;
    }
    var byteCount = new Uint32Array(256);
    for (var i = 0; i < 256; i++)
        mtfSymbol[i] = i;
    var runPos, count, symCount, selector;
    runPos = count = symCount = selector = 0;
    var buf = new Uint32Array(bufsize);
    while (true) {
        if (!(symCount--)) {
            symCount = GROUP_SIZE - 1;
            if (selector >= nSelectors)
                throw "meow i'm a kitty, that's an error";
            hufGroup = groups[selectors[selector++]];
            base = hufGroup.base.subarray(1);
            limit = hufGroup.limit.subarray(1);
        }
        i = hufGroup.minLen;
        j = bits(i);
        while (true) {
            if (i > hufGroup.maxLen)
                throw "rawr i'm a dinosaur";
            if (j <= limit[i])
                break;
            i++;
            j = (j << 1) | bits(1);
        }
        j -= base[i];
        if (j < 0 || j >= MAX_SYMBOLS)
            throw "moo i'm a cow";
        var nextSym = hufGroup.permute[j];
        if (nextSym == SYMBOL_RUNA || nextSym == SYMBOL_RUNB) {
            if (!runPos) {
                runPos = 1;
                t = 0;
            }
            if (nextSym == SYMBOL_RUNA)
                t += runPos;
            else
                t += 2 * runPos;
            runPos <<= 1;
            continue;
        }
        if (runPos) {
            runPos = 0;
            if (count + t >= bufsize)
                throw "Boom.";
            uc = symToByte[mtfSymbol[0]];
            byteCount[uc] += t;
            while (t--)
                buf[count++] = uc;
        }
        if (nextSym > symTotal)
            break;
        if (count >= bufsize)
            throw "I can't think of anything. Error";
        i = nextSym - 1;
        uc = mtfSymbol[i];
        mtfSymbol.splice(i, 1);
        mtfSymbol.splice(0, 0, uc);
        uc = symToByte[uc];
        byteCount[uc]++;
        buf[count++] = uc;
    }
    if (origPtr < 0 || origPtr >= count)
        throw "I'm a monkey and I'm throwing something at someone, namely you";
    var j = 0;
    for (var i = 0; i < 256; i++) {
        k = j + byteCount[i];
        byteCount[i] = j;
        j = k;
    }
    for (var i = 0; i < count; i++) {
        uc = buf[i] & 0xff;
        buf[byteCount[uc]] |= (i << 8);
        byteCount[uc]++;
    }
    var pos = 0,
        current = 0,
        run = 0;
    if (count) {
        pos = buf[origPtr];
        current = (pos & 0xff);
        pos >>= 8;
        run = -1;
    }
    count = count;
    var output = new Uint8Array(bufsize);
    var copies, previous, outbyte;
    var index = 0;
    if (!len)
        len = Infinity;
    while (count) {
        count--;
        previous = current;
        pos = buf[pos];
        current = pos & 0xff;
        pos >>= 8;
        if (run++ == 3) {
            copies = current;
            outbyte = previous;
            current = -1;
        } else {
            copies = 1;
            outbyte = current;
        }
        while (copies--) {
            //output += (String.fromCharCode(outbyte));
            output[index++] = outbyte;
            //index++;
            if (!--len)
                return output;
        }
        if (current != previous)
            run = 0;
    }
    //return output;
    //return output.subarray(0,index-1);
    return output.subarray(0, index);
}

module.exports = bzip2;


/***/ }),

/***/ "./node_modules/charenc/charenc.js":
/*!*****************************************!*\
  !*** ./node_modules/charenc/charenc.js ***!
  \*****************************************/
/***/ (function(module) {

var charenc = {
  // UTF-8 encoding
  utf8: {
    // Convert a string to a byte array
    stringToBytes: function(str) {
      return charenc.bin.stringToBytes(unescape(encodeURIComponent(str)));
    },

    // Convert a byte array to a string
    bytesToString: function(bytes) {
      return decodeURIComponent(escape(charenc.bin.bytesToString(bytes)));
    }
  },

  // Binary encoding
  bin: {
    // Convert a string to a byte array
    stringToBytes: function(str) {
      for (var bytes = [], i = 0; i < str.length; i++)
        bytes.push(str.charCodeAt(i) & 0xFF);
      return bytes;
    },

    // Convert a byte array to a string
    bytesToString: function(bytes) {
      for (var str = [], i = 0; i < bytes.length; i++)
        str.push(String.fromCharCode(bytes[i]));
      return str.join('');
    }
  }
};

module.exports = charenc;


/***/ }),

/***/ "./node_modules/cross-fetch/dist/browser-ponyfill.js":
/*!***********************************************************!*\
  !*** ./node_modules/cross-fetch/dist/browser-ponyfill.js ***!
  \***********************************************************/
/***/ (function(module, exports) {

var global = typeof self !== 'undefined' ? self : this;
var __self__ = (function () {
function F() {
this.fetch = false;
this.DOMException = global.DOMException
}
F.prototype = global;
return new F();
})();
(function(self) {

var irrelevant = (function (exports) {

  var support = {
    searchParams: 'URLSearchParams' in self,
    iterable: 'Symbol' in self && 'iterator' in Symbol,
    blob:
      'FileReader' in self &&
      'Blob' in self &&
      (function() {
        try {
          new Blob();
          return true
        } catch (e) {
          return false
        }
      })(),
    formData: 'FormData' in self,
    arrayBuffer: 'ArrayBuffer' in self
  };

  function isDataView(obj) {
    return obj && DataView.prototype.isPrototypeOf(obj)
  }

  if (support.arrayBuffer) {
    var viewClasses = [
      '[object Int8Array]',
      '[object Uint8Array]',
      '[object Uint8ClampedArray]',
      '[object Int16Array]',
      '[object Uint16Array]',
      '[object Int32Array]',
      '[object Uint32Array]',
      '[object Float32Array]',
      '[object Float64Array]'
    ];

    var isArrayBufferView =
      ArrayBuffer.isView ||
      function(obj) {
        return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1
      };
  }

  function normalizeName(name) {
    if (typeof name !== 'string') {
      name = String(name);
    }
    if (/[^a-z0-9\-#$%&'*+.^_`|~]/i.test(name)) {
      throw new TypeError('Invalid character in header field name')
    }
    return name.toLowerCase()
  }

  function normalizeValue(value) {
    if (typeof value !== 'string') {
      value = String(value);
    }
    return value
  }

  // Build a destructive iterator for the value list
  function iteratorFor(items) {
    var iterator = {
      next: function() {
        var value = items.shift();
        return {done: value === undefined, value: value}
      }
    };

    if (support.iterable) {
      iterator[Symbol.iterator] = function() {
        return iterator
      };
    }

    return iterator
  }

  function Headers(headers) {
    this.map = {};

    if (headers instanceof Headers) {
      headers.forEach(function(value, name) {
        this.append(name, value);
      }, this);
    } else if (Array.isArray(headers)) {
      headers.forEach(function(header) {
        this.append(header[0], header[1]);
      }, this);
    } else if (headers) {
      Object.getOwnPropertyNames(headers).forEach(function(name) {
        this.append(name, headers[name]);
      }, this);
    }
  }

  Headers.prototype.append = function(name, value) {
    name = normalizeName(name);
    value = normalizeValue(value);
    var oldValue = this.map[name];
    this.map[name] = oldValue ? oldValue + ', ' + value : value;
  };

  Headers.prototype['delete'] = function(name) {
    delete this.map[normalizeName(name)];
  };

  Headers.prototype.get = function(name) {
    name = normalizeName(name);
    return this.has(name) ? this.map[name] : null
  };

  Headers.prototype.has = function(name) {
    return this.map.hasOwnProperty(normalizeName(name))
  };

  Headers.prototype.set = function(name, value) {
    this.map[normalizeName(name)] = normalizeValue(value);
  };

  Headers.prototype.forEach = function(callback, thisArg) {
    for (var name in this.map) {
      if (this.map.hasOwnProperty(name)) {
        callback.call(thisArg, this.map[name], name, this);
      }
    }
  };

  Headers.prototype.keys = function() {
    var items = [];
    this.forEach(function(value, name) {
      items.push(name);
    });
    return iteratorFor(items)
  };

  Headers.prototype.values = function() {
    var items = [];
    this.forEach(function(value) {
      items.push(value);
    });
    return iteratorFor(items)
  };

  Headers.prototype.entries = function() {
    var items = [];
    this.forEach(function(value, name) {
      items.push([name, value]);
    });
    return iteratorFor(items)
  };

  if (support.iterable) {
    Headers.prototype[Symbol.iterator] = Headers.prototype.entries;
  }

  function consumed(body) {
    if (body.bodyUsed) {
      return Promise.reject(new TypeError('Already read'))
    }
    body.bodyUsed = true;
  }

  function fileReaderReady(reader) {
    return new Promise(function(resolve, reject) {
      reader.onload = function() {
        resolve(reader.result);
      };
      reader.onerror = function() {
        reject(reader.error);
      };
    })
  }

  function readBlobAsArrayBuffer(blob) {
    var reader = new FileReader();
    var promise = fileReaderReady(reader);
    reader.readAsArrayBuffer(blob);
    return promise
  }

  function readBlobAsText(blob) {
    var reader = new FileReader();
    var promise = fileReaderReady(reader);
    reader.readAsText(blob);
    return promise
  }

  function readArrayBufferAsText(buf) {
    var view = new Uint8Array(buf);
    var chars = new Array(view.length);

    for (var i = 0; i < view.length; i++) {
      chars[i] = String.fromCharCode(view[i]);
    }
    return chars.join('')
  }

  function bufferClone(buf) {
    if (buf.slice) {
      return buf.slice(0)
    } else {
      var view = new Uint8Array(buf.byteLength);
      view.set(new Uint8Array(buf));
      return view.buffer
    }
  }

  function Body() {
    this.bodyUsed = false;

    this._initBody = function(body) {
      this._bodyInit = body;
      if (!body) {
        this._bodyText = '';
      } else if (typeof body === 'string') {
        this._bodyText = body;
      } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {
        this._bodyBlob = body;
      } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {
        this._bodyFormData = body;
      } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {
        this._bodyText = body.toString();
      } else if (support.arrayBuffer && support.blob && isDataView(body)) {
        this._bodyArrayBuffer = bufferClone(body.buffer);
        // IE 10-11 can't handle a DataView body.
        this._bodyInit = new Blob([this._bodyArrayBuffer]);
      } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {
        this._bodyArrayBuffer = bufferClone(body);
      } else {
        this._bodyText = body = Object.prototype.toString.call(body);
      }

      if (!this.headers.get('content-type')) {
        if (typeof body === 'string') {
          this.headers.set('content-type', 'text/plain;charset=UTF-8');
        } else if (this._bodyBlob && this._bodyBlob.type) {
          this.headers.set('content-type', this._bodyBlob.type);
        } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {
          this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8');
        }
      }
    };

    if (support.blob) {
      this.blob = function() {
        var rejected = consumed(this);
        if (rejected) {
          return rejected
        }

        if (this._bodyBlob) {
          return Promise.resolve(this._bodyBlob)
        } else if (this._bodyArrayBuffer) {
          return Promise.resolve(new Blob([this._bodyArrayBuffer]))
        } else if (this._bodyFormData) {
          throw new Error('could not read FormData body as blob')
        } else {
          return Promise.resolve(new Blob([this._bodyText]))
        }
      };

      this.arrayBuffer = function() {
        if (this._bodyArrayBuffer) {
          return consumed(this) || Promise.resolve(this._bodyArrayBuffer)
        } else {
          return this.blob().then(readBlobAsArrayBuffer)
        }
      };
    }

    this.text = function() {
      var rejected = consumed(this);
      if (rejected) {
        return rejected
      }

      if (this._bodyBlob) {
        return readBlobAsText(this._bodyBlob)
      } else if (this._bodyArrayBuffer) {
        return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer))
      } else if (this._bodyFormData) {
        throw new Error('could not read FormData body as text')
      } else {
        return Promise.resolve(this._bodyText)
      }
    };

    if (support.formData) {
      this.formData = function() {
        return this.text().then(decode)
      };
    }

    this.json = function() {
      return this.text().then(JSON.parse)
    };

    return this
  }

  // HTTP methods whose capitalization should be normalized
  var methods = ['DELETE', 'GET', 'HEAD', 'OPTIONS', 'POST', 'PUT'];

  function normalizeMethod(method) {
    var upcased = method.toUpperCase();
    return methods.indexOf(upcased) > -1 ? upcased : method
  }

  function Request(input, options) {
    options = options || {};
    var body = options.body;

    if (input instanceof Request) {
      if (input.bodyUsed) {
        throw new TypeError('Already read')
      }
      this.url = input.url;
      this.credentials = input.credentials;
      if (!options.headers) {
        this.headers = new Headers(input.headers);
      }
      this.method = input.method;
      this.mode = input.mode;
      this.signal = input.signal;
      if (!body && input._bodyInit != null) {
        body = input._bodyInit;
        input.bodyUsed = true;
      }
    } else {
      this.url = String(input);
    }

    this.credentials = options.credentials || this.credentials || 'same-origin';
    if (options.headers || !this.headers) {
      this.headers = new Headers(options.headers);
    }
    this.method = normalizeMethod(options.method || this.method || 'GET');
    this.mode = options.mode || this.mode || null;
    this.signal = options.signal || this.signal;
    this.referrer = null;

    if ((this.method === 'GET' || this.method === 'HEAD') && body) {
      throw new TypeError('Body not allowed for GET or HEAD requests')
    }
    this._initBody(body);
  }

  Request.prototype.clone = function() {
    return new Request(this, {body: this._bodyInit})
  };

  function decode(body) {
    var form = new FormData();
    body
      .trim()
      .split('&')
      .forEach(function(bytes) {
        if (bytes) {
          var split = bytes.split('=');
          var name = split.shift().replace(/\+/g, ' ');
          var value = split.join('=').replace(/\+/g, ' ');
          form.append(decodeURIComponent(name), decodeURIComponent(value));
        }
      });
    return form
  }

  function parseHeaders(rawHeaders) {
    var headers = new Headers();
    // Replace instances of \r\n and \n followed by at least one space or horizontal tab with a space
    // https://tools.ietf.org/html/rfc7230#section-3.2
    var preProcessedHeaders = rawHeaders.replace(/\r?\n[\t ]+/g, ' ');
    preProcessedHeaders.split(/\r?\n/).forEach(function(line) {
      var parts = line.split(':');
      var key = parts.shift().trim();
      if (key) {
        var value = parts.join(':').trim();
        headers.append(key, value);
      }
    });
    return headers
  }

  Body.call(Request.prototype);

  function Response(bodyInit, options) {
    if (!options) {
      options = {};
    }

    this.type = 'default';
    this.status = options.status === undefined ? 200 : options.status;
    this.ok = this.status >= 200 && this.status < 300;
    this.statusText = 'statusText' in options ? options.statusText : 'OK';
    this.headers = new Headers(options.headers);
    this.url = options.url || '';
    this._initBody(bodyInit);
  }

  Body.call(Response.prototype);

  Response.prototype.clone = function() {
    return new Response(this._bodyInit, {
      status: this.status,
      statusText: this.statusText,
      headers: new Headers(this.headers),
      url: this.url
    })
  };

  Response.error = function() {
    var response = new Response(null, {status: 0, statusText: ''});
    response.type = 'error';
    return response
  };

  var redirectStatuses = [301, 302, 303, 307, 308];

  Response.redirect = function(url, status) {
    if (redirectStatuses.indexOf(status) === -1) {
      throw new RangeError('Invalid status code')
    }

    return new Response(null, {status: status, headers: {location: url}})
  };

  exports.DOMException = self.DOMException;
  try {
    new exports.DOMException();
  } catch (err) {
    exports.DOMException = function(message, name) {
      this.message = message;
      this.name = name;
      var error = Error(message);
      this.stack = error.stack;
    };
    exports.DOMException.prototype = Object.create(Error.prototype);
    exports.DOMException.prototype.constructor = exports.DOMException;
  }

  function fetch(input, init) {
    return new Promise(function(resolve, reject) {
      var request = new Request(input, init);

      if (request.signal && request.signal.aborted) {
        return reject(new exports.DOMException('Aborted', 'AbortError'))
      }

      var xhr = new XMLHttpRequest();

      function abortXhr() {
        xhr.abort();
      }

      xhr.onload = function() {
        var options = {
          status: xhr.status,
          statusText: xhr.statusText,
          headers: parseHeaders(xhr.getAllResponseHeaders() || '')
        };
        options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL');
        var body = 'response' in xhr ? xhr.response : xhr.responseText;
        resolve(new Response(body, options));
      };

      xhr.onerror = function() {
        reject(new TypeError('Network request failed'));
      };

      xhr.ontimeout = function() {
        reject(new TypeError('Network request failed'));
      };

      xhr.onabort = function() {
        reject(new exports.DOMException('Aborted', 'AbortError'));
      };

      xhr.open(request.method, request.url, true);

      if (request.credentials === 'include') {
        xhr.withCredentials = true;
      } else if (request.credentials === 'omit') {
        xhr.withCredentials = false;
      }

      if ('responseType' in xhr && support.blob) {
        xhr.responseType = 'blob';
      }

      request.headers.forEach(function(value, name) {
        xhr.setRequestHeader(name, value);
      });

      if (request.signal) {
        request.signal.addEventListener('abort', abortXhr);

        xhr.onreadystatechange = function() {
          // DONE (success or failure)
          if (xhr.readyState === 4) {
            request.signal.removeEventListener('abort', abortXhr);
          }
        };
      }

      xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit);
    })
  }

  fetch.polyfill = true;

  if (!self.fetch) {
    self.fetch = fetch;
    self.Headers = Headers;
    self.Request = Request;
    self.Response = Response;
  }

  exports.Headers = Headers;
  exports.Request = Request;
  exports.Response = Response;
  exports.fetch = fetch;

  Object.defineProperty(exports, '__esModule', { value: true });

  return exports;

})({});
})(__self__);
__self__.fetch.ponyfill = true;
// Remove "polyfill" property added by whatwg-fetch
delete __self__.fetch.polyfill;
// Choose between native implementation (global) or custom implementation (__self__)
// var ctx = global.fetch ? global : __self__;
var ctx = __self__; // this line disable service worker support temporarily
exports = ctx.fetch // To enable: import fetch from 'cross-fetch'
exports["default"] = ctx.fetch // For TypeScript consumers without esModuleInterop.
exports.fetch = ctx.fetch // To enable: import {fetch} from 'cross-fetch'
exports.Headers = ctx.Headers
exports.Request = ctx.Request
exports.Response = ctx.Response
module.exports = exports


/***/ }),

/***/ "./node_modules/crypt/crypt.js":
/*!*************************************!*\
  !*** ./node_modules/crypt/crypt.js ***!
  \*************************************/
/***/ (function(module) {

(function() {
  var base64map
      = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',

  crypt = {
    // Bit-wise rotation left
    rotl: function(n, b) {
      return (n << b) | (n >>> (32 - b));
    },

    // Bit-wise rotation right
    rotr: function(n, b) {
      return (n << (32 - b)) | (n >>> b);
    },

    // Swap big-endian to little-endian and vice versa
    endian: function(n) {
      // If number given, swap endian
      if (n.constructor == Number) {
        return crypt.rotl(n, 8) & 0x00FF00FF | crypt.rotl(n, 24) & 0xFF00FF00;
      }

      // Else, assume array and swap all items
      for (var i = 0; i < n.length; i++)
        n[i] = crypt.endian(n[i]);
      return n;
    },

    // Generate an array of any length of random bytes
    randomBytes: function(n) {
      for (var bytes = []; n > 0; n--)
        bytes.push(Math.floor(Math.random() * 256));
      return bytes;
    },

    // Convert a byte array to big-endian 32-bit words
    bytesToWords: function(bytes) {
      for (var words = [], i = 0, b = 0; i < bytes.length; i++, b += 8)
        words[b >>> 5] |= bytes[i] << (24 - b % 32);
      return words;
    },

    // Convert big-endian 32-bit words to a byte array
    wordsToBytes: function(words) {
      for (var bytes = [], b = 0; b < words.length * 32; b += 8)
        bytes.push((words[b >>> 5] >>> (24 - b % 32)) & 0xFF);
      return bytes;
    },

    // Convert a byte array to a hex string
    bytesToHex: function(bytes) {
      for (var hex = [], i = 0; i < bytes.length; i++) {
        hex.push((bytes[i] >>> 4).toString(16));
        hex.push((bytes[i] & 0xF).toString(16));
      }
      return hex.join('');
    },

    // Convert a hex string to a byte array
    hexToBytes: function(hex) {
      for (var bytes = [], c = 0; c < hex.length; c += 2)
        bytes.push(parseInt(hex.substr(c, 2), 16));
      return bytes;
    },

    // Convert a byte array to a base-64 string
    bytesToBase64: function(bytes) {
      for (var base64 = [], i = 0; i < bytes.length; i += 3) {
        var triplet = (bytes[i] << 16) | (bytes[i + 1] << 8) | bytes[i + 2];
        for (var j = 0; j < 4; j++)
          if (i * 8 + j * 6 <= bytes.length * 8)
            base64.push(base64map.charAt((triplet >>> 6 * (3 - j)) & 0x3F));
          else
            base64.push('=');
      }
      return base64.join('');
    },

    // Convert a base-64 string to a byte array
    base64ToBytes: function(base64) {
      // Remove non-base-64 characters
      base64 = base64.replace(/[^A-Z0-9+\/]/ig, '');

      for (var bytes = [], i = 0, imod4 = 0; i < base64.length;
          imod4 = ++i % 4) {
        if (imod4 == 0) continue;
        bytes.push(((base64map.indexOf(base64.charAt(i - 1))
            & (Math.pow(2, -2 * imod4 + 8) - 1)) << (imod4 * 2))
            | (base64map.indexOf(base64.charAt(i)) >>> (6 - imod4 * 2)));
      }
      return bytes;
    }
  };

  module.exports = crypt;
})();


/***/ }),

/***/ "./node_modules/is-buffer/index.js":
/*!*****************************************!*\
  !*** ./node_modules/is-buffer/index.js ***!
  \*****************************************/
/***/ (function(module) {

/*!
 * Determine if an object is a Buffer
 *
 * @author   Feross Aboukhadijeh <https://feross.org>
 * @license  MIT
 */

// The _isBuffer check is for Safari 5-7 support, because it's missing
// Object.prototype.constructor. Remove this eventually
module.exports = function (obj) {
  return obj != null && (isBuffer(obj) || isSlowBuffer(obj) || !!obj._isBuffer)
}

function isBuffer (obj) {
  return !!obj.constructor && typeof obj.constructor.isBuffer === 'function' && obj.constructor.isBuffer(obj)
}

// For Node v0.10 support. Remove this eventually.
function isSlowBuffer (obj) {
  return typeof obj.readFloatLE === 'function' && typeof obj.slice === 'function' && isBuffer(obj.slice(0, 0))
}


/***/ }),

/***/ "./node_modules/md5/md5.js":
/*!*********************************!*\
  !*** ./node_modules/md5/md5.js ***!
  \*********************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

(function(){
  var crypt = __webpack_require__(/*! crypt */ "./node_modules/crypt/crypt.js"),
      utf8 = (__webpack_require__(/*! charenc */ "./node_modules/charenc/charenc.js").utf8),
      isBuffer = __webpack_require__(/*! is-buffer */ "./node_modules/is-buffer/index.js"),
      bin = (__webpack_require__(/*! charenc */ "./node_modules/charenc/charenc.js").bin),

  // The core
  md5 = function (message, options) {
    // Convert to byte array
    if (message.constructor == String)
      if (options && options.encoding === 'binary')
        message = bin.stringToBytes(message);
      else
        message = utf8.stringToBytes(message);
    else if (isBuffer(message))
      message = Array.prototype.slice.call(message, 0);
    else if (!Array.isArray(message) && message.constructor !== Uint8Array)
      message = message.toString();
    // else, assume byte array already

    var m = crypt.bytesToWords(message),
        l = message.length * 8,
        a =  1732584193,
        b = -271733879,
        c = -1732584194,
        d =  271733878;

    // Swap endian
    for (var i = 0; i < m.length; i++) {
      m[i] = ((m[i] <<  8) | (m[i] >>> 24)) & 0x00FF00FF |
             ((m[i] << 24) | (m[i] >>>  8)) & 0xFF00FF00;
    }

    // Padding
    m[l >>> 5] |= 0x80 << (l % 32);
    m[(((l + 64) >>> 9) << 4) + 14] = l;

    // Method shortcuts
    var FF = md5._ff,
        GG = md5._gg,
        HH = md5._hh,
        II = md5._ii;

    for (var i = 0; i < m.length; i += 16) {

      var aa = a,
          bb = b,
          cc = c,
          dd = d;

      a = FF(a, b, c, d, m[i+ 0],  7, -680876936);
      d = FF(d, a, b, c, m[i+ 1], 12, -389564586);
      c = FF(c, d, a, b, m[i+ 2], 17,  606105819);
      b = FF(b, c, d, a, m[i+ 3], 22, -1044525330);
      a = FF(a, b, c, d, m[i+ 4],  7, -176418897);
      d = FF(d, a, b, c, m[i+ 5], 12,  1200080426);
      c = FF(c, d, a, b, m[i+ 6], 17, -1473231341);
      b = FF(b, c, d, a, m[i+ 7], 22, -45705983);
      a = FF(a, b, c, d, m[i+ 8],  7,  1770035416);
      d = FF(d, a, b, c, m[i+ 9], 12, -1958414417);
      c = FF(c, d, a, b, m[i+10], 17, -42063);
      b = FF(b, c, d, a, m[i+11], 22, -1990404162);
      a = FF(a, b, c, d, m[i+12],  7,  1804603682);
      d = FF(d, a, b, c, m[i+13], 12, -40341101);
      c = FF(c, d, a, b, m[i+14], 17, -1502002290);
      b = FF(b, c, d, a, m[i+15], 22,  1236535329);

      a = GG(a, b, c, d, m[i+ 1],  5, -165796510);
      d = GG(d, a, b, c, m[i+ 6],  9, -1069501632);
      c = GG(c, d, a, b, m[i+11], 14,  643717713);
      b = GG(b, c, d, a, m[i+ 0], 20, -373897302);
      a = GG(a, b, c, d, m[i+ 5],  5, -701558691);
      d = GG(d, a, b, c, m[i+10],  9,  38016083);
      c = GG(c, d, a, b, m[i+15], 14, -660478335);
      b = GG(b, c, d, a, m[i+ 4], 20, -405537848);
      a = GG(a, b, c, d, m[i+ 9],  5,  568446438);
      d = GG(d, a, b, c, m[i+14],  9, -1019803690);
      c = GG(c, d, a, b, m[i+ 3], 14, -187363961);
      b = GG(b, c, d, a, m[i+ 8], 20,  1163531501);
      a = GG(a, b, c, d, m[i+13],  5, -1444681467);
      d = GG(d, a, b, c, m[i+ 2],  9, -51403784);
      c = GG(c, d, a, b, m[i+ 7], 14,  1735328473);
      b = GG(b, c, d, a, m[i+12], 20, -1926607734);

      a = HH(a, b, c, d, m[i+ 5],  4, -378558);
      d = HH(d, a, b, c, m[i+ 8], 11, -2022574463);
      c = HH(c, d, a, b, m[i+11], 16,  1839030562);
      b = HH(b, c, d, a, m[i+14], 23, -35309556);
      a = HH(a, b, c, d, m[i+ 1],  4, -1530992060);
      d = HH(d, a, b, c, m[i+ 4], 11,  1272893353);
      c = HH(c, d, a, b, m[i+ 7], 16, -155497632);
      b = HH(b, c, d, a, m[i+10], 23, -1094730640);
      a = HH(a, b, c, d, m[i+13],  4,  681279174);
      d = HH(d, a, b, c, m[i+ 0], 11, -358537222);
      c = HH(c, d, a, b, m[i+ 3], 16, -722521979);
      b = HH(b, c, d, a, m[i+ 6], 23,  76029189);
      a = HH(a, b, c, d, m[i+ 9],  4, -640364487);
      d = HH(d, a, b, c, m[i+12], 11, -421815835);
      c = HH(c, d, a, b, m[i+15], 16,  530742520);
      b = HH(b, c, d, a, m[i+ 2], 23, -995338651);

      a = II(a, b, c, d, m[i+ 0],  6, -198630844);
      d = II(d, a, b, c, m[i+ 7], 10,  1126891415);
      c = II(c, d, a, b, m[i+14], 15, -1416354905);
      b = II(b, c, d, a, m[i+ 5], 21, -57434055);
      a = II(a, b, c, d, m[i+12],  6,  1700485571);
      d = II(d, a, b, c, m[i+ 3], 10, -1894986606);
      c = II(c, d, a, b, m[i+10], 15, -1051523);
      b = II(b, c, d, a, m[i+ 1], 21, -2054922799);
      a = II(a, b, c, d, m[i+ 8],  6,  1873313359);
      d = II(d, a, b, c, m[i+15], 10, -30611744);
      c = II(c, d, a, b, m[i+ 6], 15, -1560198380);
      b = II(b, c, d, a, m[i+13], 21,  1309151649);
      a = II(a, b, c, d, m[i+ 4],  6, -145523070);
      d = II(d, a, b, c, m[i+11], 10, -1120210379);
      c = II(c, d, a, b, m[i+ 2], 15,  718787259);
      b = II(b, c, d, a, m[i+ 9], 21, -343485551);

      a = (a + aa) >>> 0;
      b = (b + bb) >>> 0;
      c = (c + cc) >>> 0;
      d = (d + dd) >>> 0;
    }

    return crypt.endian([a, b, c, d]);
  };

  // Auxiliary functions
  md5._ff  = function (a, b, c, d, x, s, t) {
    var n = a + (b & c | ~b & d) + (x >>> 0) + t;
    return ((n << s) | (n >>> (32 - s))) + b;
  };
  md5._gg  = function (a, b, c, d, x, s, t) {
    var n = a + (b & d | c & ~d) + (x >>> 0) + t;
    return ((n << s) | (n >>> (32 - s))) + b;
  };
  md5._hh  = function (a, b, c, d, x, s, t) {
    var n = a + (b ^ c ^ d) + (x >>> 0) + t;
    return ((n << s) | (n >>> (32 - s))) + b;
  };
  md5._ii  = function (a, b, c, d, x, s, t) {
    var n = a + (c ^ (b | ~d)) + (x >>> 0) + t;
    return ((n << s) | (n >>> (32 - s))) + b;
  };

  // Package private blocksize
  md5._blocksize = 16;
  md5._digestsize = 16;

  module.exports = function (message, options) {
    if (message === undefined || message === null)
      throw new Error('Illegal argument ' + message);

    var digestbytes = crypt.wordsToBytes(md5(message, options));
    return options && options.asBytes ? digestbytes :
        options && options.asString ? bin.bytesToString(digestbytes) :
        crypt.bytesToHex(digestbytes);
  };

})();


/***/ })

}]);
//# sourceMappingURL=vendors-node_modules_jbrowse_plugin-alignments_esm_CramAdapter_CramAdapter_js.bundle.js.map